{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "import h5py\n",
    "import shutil\n",
    "import tempfile\n",
    "import sys\n",
    "import caffe\n",
    "import os\n",
    "import sys\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import pickle\n",
    "import subprocess as sub\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "import pickle\n",
    "import time\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "# Take care with the paths -defaults ones from protobuf are not correct. Need to change snapshot and train / test data paths \n",
    "\n",
    "caffe_root = '/home/nikhil/caffe/'  # this file should be run from {caffe_root}/examples (otherwise change this line)\n",
    "sys.path.insert(0, caffe_root + 'python')\n",
    "\n",
    "baseline_dir = '/projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/'\n",
    "os.chdir(baseline_dir)\n",
    "\n",
    "caffe.set_device(1)\n",
    "caffe.set_mode_gpu()\n",
    "\n",
    "#Useful resources:\n",
    "#http://stackoverflow.com/questions/33140000/how-to-feed-caffe-multi-label-data-in-hdf5-format\n",
    "#http://nbviewer.jupyter.org/github/BVLC/caffe/blob/master/examples/00-classification.ipynb\n",
    "#http://nbviewer.jupyter.org/github/BVLC/caffe/blob/master/examples/01-learning-lenet.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tables as tb\n",
    "from sklearn import preprocessing\n",
    "def load_data(data_path, input_node, preproc):\n",
    "    data = tb.open_file(data_path, 'r')\n",
    "    X_raw = data.get_node('/' + input_node)[:]\n",
    "    if preproc == 'scale':\n",
    "        X = preprocessing.scale(X_raw)\n",
    "    elif preproc == 'norm_max':\n",
    "        X = preprocessing.normalize(X_raw, norm='max')\n",
    "    elif preproc == 'norm_l2':\n",
    "        X = preprocessing.normalize(X_raw, norm='l2')\n",
    "    else:\n",
    "        X = X_raw\n",
    "    data.close()\n",
    "    return X\n",
    "\n",
    "# Some defs to load data and extract encodings from trained net\n",
    "import collections\n",
    "def extract_features(net_file, model_file, data_path, input_nodes, batch_size, encoding_layer, weight_layers, multi_task):\n",
    "    os.chdir(os.path.dirname(net_file))\n",
    "    net = caffe.Net(net_file, model_file, caffe.TEST)        \n",
    "    \n",
    "    #print net.blobs.items()[0]\n",
    "    #print net.blobs.items()[1]\n",
    "    \n",
    "    #Get weights    \n",
    "    layer_list = weight_layers\n",
    "    wt_dict = collections.OrderedDict()\n",
    "    for l, name in enumerate(net._layer_names):            \n",
    "        if name in layer_list:\n",
    "            wt_dict[name] = net.layers[l].blobs[0].data\n",
    "    \n",
    "    BATCH_SIZE = batch_size        \n",
    "    N = load_data(data_path, input_nodes[0],'no_preproc').shape[0]\n",
    "    iters = int(np.ceil(N / float(BATCH_SIZE)))\n",
    "\n",
    "    if not multi_task:\n",
    "        code_layer = net.blobs[encoding_layer]\n",
    "        out_shape = code_layer.data.shape    \n",
    "        X_out = np.zeros(shape=(N, out_shape[1]))        \n",
    "        #print 'X_out.shape: {}'.format(X_out.shape)\n",
    "        \n",
    "    else:\n",
    "        code_layer_adas13 = net.blobs[encoding_layer + '_ADAS13']\n",
    "        code_layer_mmse = net.blobs[encoding_layer + '_MMSE']\n",
    "        out_shape = code_layer_adas13.data.shape \n",
    "        X_out_adas13 = np.zeros(shape=(N, out_shape[1]))\n",
    "        X_out_mmse = np.zeros(shape=(N, out_shape[1]))\n",
    "        #print 'X_out.shape: {},{}'.format(X_out_adas13.shape,X_out_mmse.shape)\n",
    "    \n",
    "    X_list = []\n",
    "    data_layers = []\n",
    "    for i, input_node in enumerate(input_nodes):\n",
    "        X_list.append(load_data(data_path, input_node,'no_preproc'))\n",
    "        #print net.blobs[input_node].shape\n",
    "        \n",
    "        data_layers.append(net.blobs[input_node])    \n",
    "        #print 'X_list shape: {}'.format(X_list[i].shape)\n",
    "        #print 'data_layers shape: {}'.format(data_layers[i].data.shape)\n",
    "        data_layers[i].reshape(BATCH_SIZE, X_list[i].shape[1]) # TODO: only works for 2-D inputs\n",
    "        #print 'data_layers shape: {}'.format(data_layers[i].data.shape)\n",
    "    \n",
    "     \n",
    "    net.reshape()            \n",
    "    #print 'Extracting features from data...'\n",
    "    \n",
    "    for i in xrange(iters):\n",
    "        #print '.',\n",
    "        for m, X in enumerate(X_list):\n",
    "            X_b = X[i * BATCH_SIZE: (i+1) * BATCH_SIZE,:]\n",
    "            batch_sampx = X_b.shape[0]\n",
    "            # Pad last batch with zeros\n",
    "            if X_b.shape[0] < BATCH_SIZE:\n",
    "                #print 'Zero-padding last batch with {} rows'.format(BATCH_SIZE-X_b.shape[0])\n",
    "                X_b = np.vstack((X_b,np.zeros((BATCH_SIZE-X_b.shape[0],X_b.shape[1]))))                       \n",
    "            \n",
    "            data_layers[m].data[...] = X_b\n",
    "            \n",
    "        net.forward()\n",
    "        \n",
    "        if not multi_task:\n",
    "            X_out[i * BATCH_SIZE: min((i+1) * BATCH_SIZE, N)] = code_layer.data[0:batch_sampx,:].copy()\n",
    "        else:\n",
    "            X_out_adas13[i * BATCH_SIZE: min((i+1) * BATCH_SIZE, N)] = code_layer_adas13.data[0:batch_sampx,:].copy()\n",
    "            X_out_mmse[i * BATCH_SIZE: min((i+1) * BATCH_SIZE, N)] = code_layer_mmse.data[0:batch_sampx,:].copy()\n",
    "            X_out = {'adas13':X_out_adas13,'mmse':X_out_mmse}\n",
    "    return {'X_out':X_out, 'wt_dict':wt_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from caffe import layers as L\n",
    "from caffe import params as P\n",
    "\n",
    "def adninet_ff_HC(hdf5, batch_size, node_sizes, dr, lr, tr, Clinical_Scale):\n",
    "    n = caffe.NetSpec()\n",
    "    \n",
    "    #------- Input -----------------#\n",
    "    if Clinical_Scale == 'ADAS13':\n",
    "        n.X_L_HC,n.X_R_HC,n.adas  = L.HDF5Data(name='data',batch_size=batch_size, source=hdf5,ntop=3) #orig\n",
    "    elif Clinical_Scale == 'MMSE':\n",
    "        n.X_L_HC,n.X_R_HC,n.mmse  = L.HDF5Data(name='data',batch_size=batch_size, source=hdf5,ntop=3) #orig\n",
    "    elif Clinical_Scale == 'BOTH':\n",
    "        n.X_L_HC,n.X_R_HC,n.adas,n.mmse  = L.HDF5Data(name='data',batch_size=batch_size, source=hdf5,ntop=4) #orig\n",
    "    else:\n",
    "        print 'Unknow Clinical Scale: {}'.format(Clinical_Scale)\n",
    "        \n",
    "    #-------Hidden Layers-----------#\n",
    "    #ff layers Left HC\n",
    "    #n.L_ff1 = L.InnerProduct(n.X_L_HC, num_output=node_sizes['L_ff1'], param=dict(lr_mult=2), weight_filler=dict(type='gaussian',std=0.008))\n",
    "    n.L_ff1 = L.InnerProduct(n.X_L_HC, num_output=node_sizes['HC_L_ff'], param=dict(lr_mult=lr['HC']), weight_filler=dict(type='xavier'))\n",
    "    n.NLinEnL1 = L.ReLU(n.L_ff1, in_place=True)\n",
    "    n.dropL1 = L.Dropout(n.L_ff1, in_place=True,dropout_param=dict(dropout_ratio=dr['HC']))\n",
    "    \n",
    "    #ff layers Right HC\n",
    "    #n.R_ff1 = L.InnerProduct(n.X_R_HC, num_output=node_sizes['R_ff1'], param=dict(lr_mult=2), weight_filler=dict(type='gaussian',std=0.008))\n",
    "    n.R_ff1 = L.InnerProduct(n.X_R_HC, num_output=node_sizes['HC_R_ff'], param=dict(lr_mult=lr['HC']), weight_filler=dict(type='xavier'))\n",
    "    n.NLinEnR1 = L.ReLU(n.R_ff1, in_place=True)\n",
    "    n.dropR1 = L.Dropout(n.R_ff1, in_place=True,dropout_param=dict(dropout_ratio=dr['HC']))\n",
    "    \n",
    "    #ff layers Concat\n",
    "    n.concat = L.Concat(n.L_ff1,n.R_ff1, concat_param=dict(axis=1))\n",
    "    n.ff3 = L.InnerProduct(n.concat, num_output=node_sizes['COMB_ff'], param=dict(lr_mult=1), weight_filler=dict(type='xavier'))\n",
    "    n.NLinEn3 = L.ReLU(n.ff3, in_place=True)\n",
    "  \n",
    "    #Task layers    \n",
    "    if Clinical_Scale == 'BOTH': ## Split layers (multitask)\n",
    "        n.ff1_ADAS13 = L.InnerProduct(n.ff3, num_output=node_sizes['ADAS_ff'], param=dict(lr_mult=1), weight_filler=dict(type='xavier'))\n",
    "        n.NLin1ADAS13 = L.ReLU(n.ff1_ADAS13, in_place=True)\n",
    "        \n",
    "        n.ff1_MMSE = L.InnerProduct(n.ff3, num_output=node_sizes['MMSE_ff'], param=dict(lr_mult=1), weight_filler=dict(type='xavier'))\n",
    "        n.NLin1MMSE = L.ReLU(n.ff1_MMSE, in_place=True)\n",
    "    else:\n",
    "        #n.ff4 = L.InnerProduct(n.ff3, num_output=node_sizes['ff4'], param=dict(lr_mult=1), weight_filler=dict(type='gaussian',std=0.177))\n",
    "        n.ff4 = L.InnerProduct(n.ff3, num_output=node_sizes['COMB_ff'], param=dict(lr_mult=1), weight_filler=dict(type='xavier'))\n",
    "        n.NLinEn4 = L.ReLU(n.ff4, in_place=True)\n",
    "    \n",
    "    #--------Output--------------#\n",
    "    #n.output = L.InnerProduct(n.ff4, num_output=1, weight_filler=dict(type='gaussian',std=0.177))          \n",
    "    if Clinical_Scale == 'ADAS13':\n",
    "        n.output = L.InnerProduct(n.ff3, num_output=1, weight_filler=dict(type='xavier'))\n",
    "        n.loss = L.EuclideanLoss(n.output, n.adas)            \n",
    "    elif Clinical_Scale == 'MMSE':\n",
    "        n.output = L.InnerProduct(n.ff3, num_output=1, weight_filler=dict(type='xavier'))\n",
    "        n.loss = L.EuclideanLoss(n.output, n.mmse)\n",
    "    elif Clinical_Scale == 'BOTH':\n",
    "        n.output_ADAS13 = L.InnerProduct(n.ff1_ADAS13, num_output=1, weight_filler=dict(type='xavier'))\n",
    "        n.ADAS13_loss = L.EuclideanLoss(n.output_ADAS13, n.adas,loss_weight=tr['ADAS'])          \n",
    "        n.output_MMSE = L.InnerProduct(n.ff1_MMSE, num_output=1, weight_filler=dict(type='xavier'))\n",
    "        n.MMSE_loss = L.EuclideanLoss(n.output_MMSE, n.mmse,loss_weight=tr['MMSE'])  \n",
    "    else:\n",
    "        print 'Unknow Clinical Scale: {}'.format(Clinical_Scale)\n",
    "    \n",
    "    return n.to_proto()\n",
    "\n",
    "def adninet_ff_CT(hdf5, batch_size, node_sizes, dr, lr, tr, Clinical_Scale):\n",
    "    n = caffe.NetSpec()\n",
    "    \n",
    "    #------- Input -----------------#\n",
    "    if Clinical_Scale == 'ADAS13':\n",
    "        n.X_CT_SpecCluster_dyn,n.adas  = L.HDF5Data(name='data',batch_size=batch_size, source=hdf5,ntop=2) #orig\n",
    "    elif Clinical_Scale == 'MMSE':\n",
    "        n.X_CT_SpecCluster_dyn,n.mmse  = L.HDF5Data(name='data',batch_size=batch_size, source=hdf5,ntop=2) #orig\n",
    "    elif Clinical_Scale == 'BOTH':\n",
    "        n.X_CT_SpecCluster_dyn,n.adas,n.mmse  = L.HDF5Data(name='data',batch_size=batch_size, source=hdf5,ntop=3) #orig\n",
    "    else:\n",
    "        print 'Unknow Clinical Scale: {}'.format(Clinical_Scale)\n",
    "        \n",
    "    #-------Hidden Layers-----------#\n",
    "    n.ff1 = L.InnerProduct(n.X_CT_SpecCluster_dyn, num_output=node_sizes['CT_ff'], param=dict(lr_mult=lr['CT']), weight_filler=dict(type='xavier'))\n",
    "    n.NLinEnL1 = L.ReLU(n.ff1, in_place=True)\n",
    "    n.dropL1 = L.Dropout(n.ff1, in_place=True,dropout_param=dict(dropout_ratio=dr['CT'])) \n",
    "\n",
    "    #Task Layers\n",
    "    if Clinical_Scale == 'BOTH': ## Split layers (multitask)\n",
    "        n.ff1_ADAS13 = L.InnerProduct(n.ff1, num_output=node_sizes['ADAS_ff'], param=dict(lr_mult=1), weight_filler=dict(type='xavier'))\n",
    "        n.NLin1ADAS13 = L.ReLU(n.ff1_ADAS13, in_place=True)\n",
    "        \n",
    "        n.ff1_MMSE = L.InnerProduct(n.ff1, num_output=node_sizes['MMSE_ff'], param=dict(lr_mult=1), weight_filler=dict(type='xavier'))\n",
    "        n.NLin1MMSE = L.ReLU(n.ff1_MMSE, in_place=True)        \n",
    "    else:\n",
    "        n.ff2 = L.InnerProduct(n.ff1, num_output=node_sizes['CT_ff'], param=dict(lr_mult=lr['CT']), weight_filler=dict(type='xavier'))\n",
    "        n.NLinEnL2 = L.ReLU(n.ff2, in_place=True)\n",
    "        n.dropL2 = L.Dropout(n.ff2, in_place=True,dropout_param=dict(dropout_ratio=dr['CT']))\n",
    "    \n",
    "    #--------Output--------------#\n",
    "    #n.output = L.InnerProduct(n.ff4, num_output=1, weight_filler=dict(type='gaussian',std=0.177))          \n",
    "    if Clinical_Scale == 'ADAS13':\n",
    "        n.output = L.InnerProduct(n.ff2, num_output=1, weight_filler=dict(type='xavier'))\n",
    "        n.loss = L.EuclideanLoss(n.output, n.adas)            \n",
    "    elif Clinical_Scale == 'MMSE':\n",
    "        n.output = L.InnerProduct(n.ff2, num_output=1, weight_filler=dict(type='xavier'))\n",
    "        n.loss = L.EuclideanLoss(n.output, n.mmse)\n",
    "    elif Clinical_Scale == 'BOTH':\n",
    "        n.output_ADAS13 = L.InnerProduct(n.ff1_ADAS13, num_output=1, weight_filler=dict(type='xavier'))\n",
    "        n.ADAS13_loss = L.EuclideanLoss(n.output_ADAS13, n.adas,loss_weight=tr['ADAS'])          \n",
    "        n.output_MMSE = L.InnerProduct(n.ff1_MMSE, num_output=1, weight_filler=dict(type='xavier'))\n",
    "        n.MMSE_loss = L.EuclideanLoss(n.output_MMSE, n.mmse,loss_weight=tr['MMSE'])  \n",
    "    else:\n",
    "        print 'Unknow Clinical Scale: {}'.format(Clinical_Scale)\n",
    "    return n.to_proto()\n",
    "\n",
    "def adninet_ff_HC_CT_unified(hdf5, batch_size, node_sizes, dr, lr, tr, Clinical_Scale):\n",
    "    n = caffe.NetSpec()\n",
    "    \n",
    "    #------- Input -----------------#\n",
    "    if Clinical_Scale == 'ADAS13':\n",
    "        n.X_HC_CT,n.adas  = L.HDF5Data(name='data',batch_size=batch_size, source=hdf5,ntop=2) #orig\n",
    "    elif Clinical_Scale == 'MMSE':\n",
    "        n.X_HC_CT,n.mmse  = L.HDF5Data(name='data',batch_size=batch_size, source=hdf5,ntop=2) #orig\n",
    "    elif Clinical_Scale == 'DX':\n",
    "        n.X_HC_CT,n.dx_cat3  = L.HDF5Data(name='data',batch_size=batch_size, source=hdf5,ntop=2) #orig\n",
    "    elif Clinical_Scale == 'BOTH':\n",
    "        n.X_HC_CT,n.adas,n.mmse  = L.HDF5Data(name='data',batch_size=batch_size, source=hdf5,ntop=3) #orig\n",
    "    else:\n",
    "        print 'Unknow Clinical Scale: {}'.format(Clinical_Scale)\n",
    "        \n",
    "    #-------Hidden Layers-----------#\n",
    "    n.ff1 = L.InnerProduct(n.X_HC_CT, num_output=node_sizes['HC_CT_ff'], param=dict(lr_mult=lr['HC_CT']), weight_filler=dict(type='xavier'))\n",
    "    n.NLinEnL1 = L.ReLU(n.ff1, in_place=True)\n",
    "    n.dropL1 = L.Dropout(n.ff1, in_place=True,dropout_param=dict(dropout_ratio=dr['HC_CT'])) \n",
    "\n",
    "    #Task Layers\n",
    "    if Clinical_Scale == 'BOTH': ## Split layers (multitask)\n",
    "        n.ff1_ADAS13 = L.InnerProduct(n.ff1, num_output=node_sizes['ADAS_ff'], param=dict(lr_mult=1), weight_filler=dict(type='xavier'))\n",
    "        n.NLin1ADAS13 = L.ReLU(n.ff1_ADAS13, in_place=True)\n",
    "        \n",
    "        n.ff1_MMSE = L.InnerProduct(n.ff1, num_output=node_sizes['MMSE_ff'], param=dict(lr_mult=1), weight_filler=dict(type='xavier'))\n",
    "        n.NLin1MMSE = L.ReLU(n.ff1_MMSE, in_place=True)        \n",
    "    else:\n",
    "        n.ff2 = L.InnerProduct(n.ff1, num_output=node_sizes['HC_CT_ff'], param=dict(lr_mult=lr['HC_CT']), weight_filler=dict(type='xavier'))\n",
    "        n.NLinEnL2 = L.ReLU(n.ff2, in_place=True)\n",
    "        n.dropL2 = L.Dropout(n.ff2, in_place=True,dropout_param=dict(dropout_ratio=dr['HC_CT']))\n",
    "    \n",
    "    #--------Output--------------#\n",
    "    #n.output = L.InnerProduct(n.ff4, num_output=1, weight_filler=dict(type='gaussian',std=0.177))          \n",
    "    if Clinical_Scale == 'ADAS13':\n",
    "        n.output = L.InnerProduct(n.ff2, num_output=1, weight_filler=dict(type='xavier'))\n",
    "        n.loss = L.EuclideanLoss(n.output, n.adas)            \n",
    "    elif Clinical_Scale == 'MMSE':\n",
    "        n.output = L.InnerProduct(n.ff2, num_output=1, weight_filler=dict(type='xavier'))\n",
    "        n.loss = L.EuclideanLoss(n.output, n.mmse)\n",
    "    elif Clinical_Scale == 'DX':\n",
    "        n.output = L.InnerProduct(n.ff2, num_output=4, weight_filler=dict(type='xavier'))\n",
    "        n.loss = L.SoftmaxWithLoss(n.output, n.dx_cat3)\n",
    "    elif Clinical_Scale == 'BOTH':\n",
    "        n.output_ADAS13 = L.InnerProduct(n.ff1_ADAS13, num_output=1, weight_filler=dict(type='xavier'))\n",
    "        n.ADAS13_loss = L.EuclideanLoss(n.output_ADAS13, n.adas,loss_weight=tr['ADAS'])          \n",
    "        n.output_MMSE = L.InnerProduct(n.ff1_MMSE, num_output=1, weight_filler=dict(type='xavier'))\n",
    "        n.MMSE_loss = L.EuclideanLoss(n.output_MMSE, n.mmse,loss_weight=tr['MMSE'])  \n",
    "    else:\n",
    "        print 'Unknow Clinical Scale: {}'.format(Clinical_Scale)\n",
    "    return n.to_proto()\n",
    "\n",
    "def adninet_ff_HC_CT(hdf5, batch_size, node_sizes, dr, lr, tr, Clinical_Scale):\n",
    "    n = caffe.NetSpec()\n",
    "    \n",
    "    #------- Input -----------------#\n",
    "    if Clinical_Scale == 'ADAS13':\n",
    "        n.X_L_HC,n.X_R_HC,n.X_CT_SpecCluster_dyn,n.adas  = L.HDF5Data(name='data',batch_size=batch_size, source=hdf5,ntop=4) #orig\n",
    "    elif Clinical_Scale == 'MMSE':\n",
    "        n.X_L_HC,n.X_R_HC,n.X_CT_SpecCluster_dyn,n.mmse  = L.HDF5Data(name='data',batch_size=batch_size, source=hdf5,ntop=4) #orig\n",
    "    elif Clinical_Scale == 'BOTH':\n",
    "        n.X_L_HC,n.X_R_HC,n.X_CT_SpecCluster_dyn,n.adas,n.mmse  = L.HDF5Data(name='data',batch_size=batch_size, source=hdf5,ntop=5) #orig\n",
    "    elif Clinical_Scale == 'DX':\n",
    "        n.X_L_HC,n.X_R_HC,n.X_CT_SpecCluster_dyn,n.dx_cat3  = L.HDF5Data(name='data',batch_size=batch_size, source=hdf5,ntop=4) #orig\n",
    "    elif Clinical_Scale == 'ADAS13_DX':\n",
    "        n.X_L_HC,n.X_R_HC,n.X_CT_SpecCluster_dyn,n.adas, n.dx_cat3  = L.HDF5Data(name='data',batch_size=batch_size, source=hdf5,ntop=5) #orig\n",
    "    else:\n",
    "        print 'Unknow Clinical Scale: {}'.format(Clinical_Scale)\n",
    "        \n",
    "    #-------Hidden Layers-----------#\n",
    "    #ff layers Left HC\n",
    "    #n.L_ff1 = L.InnerProduct(n.X_L_HC, num_output=node_sizes['L_ff1'], param=dict(lr_mult=2), weight_filler=dict(type='gaussian',std=0.008))\n",
    "    n.L_ff1 = L.InnerProduct(n.X_L_HC, num_output=node_sizes['HC_L_ff'], param=dict(lr_mult=lr['HC']), weight_filler=dict(type='xavier'))\n",
    "    n.NLinEnL1 = L.ReLU(n.L_ff1, in_place=True)\n",
    "    n.dropL1 = L.Dropout(n.L_ff1, in_place=True,dropout_param=dict(dropout_ratio=dr['HC']))\n",
    "    #n.L_ff2 = L.InnerProduct(n.L_ff1, num_output=node_sizes['L_ff2'], param=dict(lr_mult=2), weight_filler=dict(type='gaussian',std=0.177))\n",
    "#     n.L_ff2 = L.InnerProduct(n.L_ff1, num_output=node_sizes['HC_L_ff'], param=dict(lr_mult=lr['HC']), weight_filler=dict(type='xavier'))\n",
    "#     n.NLinEnL2 = L.ReLU(n.L_ff2, in_place=True)\n",
    "#     n.dropL2 = L.Dropout(n.L_ff2, in_place=True,dropout_param=dict(dropout_ratio=dr['HC']))\n",
    "    \n",
    "    #ff layers Right HC\n",
    "    #n.R_ff1 = L.InnerProduct(n.X_R_HC, num_output=node_sizes['R_ff1'], param=dict(lr_mult=2), weight_filler=dict(type='gaussian',std=0.008))\n",
    "    n.R_ff1 = L.InnerProduct(n.X_R_HC, num_output=node_sizes['HC_R_ff'], param=dict(lr_mult=lr['HC']), weight_filler=dict(type='xavier'))\n",
    "    n.NLinEnR1 = L.ReLU(n.R_ff1, in_place=True)\n",
    "    n.dropR1 = L.Dropout(n.R_ff1, in_place=True,dropout_param=dict(dropout_ratio=dr['HC']))\n",
    "    #n.R_ff2 = L.InnerProduct(n.R_ff1, num_output=node_sizes['R_ff2'], param=dict(lr_mult=2), weight_filler=dict(type='gaussian',std=0.177))\n",
    "#     n.R_ff2 = L.InnerProduct(n.R_ff1, num_output=node_sizes['HC_R_ff'], param=dict(lr_mult=lr['HC']), weight_filler=dict(type='xavier'))\n",
    "#     n.NLinEnR2 = L.ReLU(n.R_ff2, in_place=True)\n",
    "#     n.dropR2 = L.Dropout(n.R_ff2, in_place=True,dropout_param=dict(dropout_ratio=dr['HC']))\n",
    "    \n",
    "    #ff layers CT\n",
    "    #n.ff1 = L.InnerProduct(n.X_CT, num_output=node_sizes['ff1'], param=dict(lr_mult=2), weight_filler=dict(type='gaussian',std=0.008))\n",
    "    n.ff1 = L.InnerProduct(n.X_CT_SpecCluster_dyn, num_output=node_sizes['CT_ff'], param=dict(lr_mult=lr['CT']), weight_filler=dict(type='xavier'))\n",
    "    n.NLinEn1 = L.ReLU(n.ff1, in_place=True)\n",
    "    n.drop1 = L.Dropout(n.ff1, in_place=True,dropout_param=dict(dropout_ratio=dr['CT']))\n",
    "    #n.ff2 = L.InnerProduct(n.ff1, num_output=node_sizes['ff2'], param=dict(lr_mult=), weight_filler=dict(type='gaussian',std=0.177))\n",
    "#     n.ff2 = L.InnerProduct(n.ff1, num_output=node_sizes['CT_ff'], param=dict(lr_mult=lr['CT']), weight_filler=dict(type='xavier'))\n",
    "#     n.NLinEn2 = L.ReLU(n.ff2, in_place=True)\n",
    "#     n.drop2 = L.Dropout(n.ff2, in_place=True,dropout_param=dict(dropout_ratio=dr['CT']))\n",
    "    \n",
    "     #ff layers Concat\n",
    "    n.concat = L.Concat(n.L_ff1,n.R_ff1,n.ff1, concat_param=dict(axis=1))\n",
    "    #n.concat = L.Concat(n.X_L_HC,n.X_R_HC,n.X_CT, concat_param=dict(axis=1))\n",
    "    \n",
    "    #n.ff3 = L.InnerProduct(n.concat, num_output=node_sizes['ff3'], param=dict(lr_mult=1), weight_filler=dict(type='gaussian',std=0.177))\n",
    "    n.ff3 = L.InnerProduct(n.concat, num_output=node_sizes['COMB_ff'], param=dict(lr_mult=lr['COMB']), weight_filler=dict(type='xavier'))\n",
    "    n.NLinEn3 = L.ReLU(n.ff3, in_place=True)\n",
    "    n.dropC1 = L.Dropout(n.ff3, in_place=True,dropout_param=dict(dropout_ratio=dr['COMB']))\n",
    "\n",
    "    #Task layers    \n",
    "    if Clinical_Scale == 'BOTH': ## Split layers (multitask)\n",
    "        #n.ff1_ADAS13, n.ff1_MMSE = L.Split(n.ff3,num_output=2) #This is done automatically by caffe! \n",
    "        n.ff1_ADAS13 = L.InnerProduct(n.ff3, num_output=node_sizes['ADAS_ff'], param=dict(lr_mult=1), weight_filler=dict(type='xavier'))\n",
    "        n.NLin1ADAS13 = L.ReLU(n.ff1_ADAS13, in_place=True)\n",
    "        #n.ff2_ADAS13 = L.InnerProduct(n.ff1_ADAS13, num_output=node_sizes['ADAS_ff'], param=dict(lr_mult=1), weight_filler=dict(type='xavier'))\n",
    "        #n.NLin2ADAS13 = L.ReLU(n.ff2_ADAS13, in_place=True)\n",
    "        \n",
    "        n.ff1_MMSE = L.InnerProduct(n.ff3, num_output=node_sizes['MMSE_ff'], param=dict(lr_mult=1), weight_filler=dict(type='xavier'))\n",
    "        n.NLin1MMSE = L.ReLU(n.ff1_MMSE, in_place=True)\n",
    "        #n.ff2_MMSE = L.InnerProduct(n.ff1_MMSE, num_output=node_sizes['MMSE_ff'], param=dict(lr_mult=1), weight_filler=dict(type='xavier'))\n",
    "        #n.NLin2MMSE = L.ReLU(n.ff2_MMSE, in_place=True)\n",
    "        \n",
    "    elif Clinical_Scale == 'ADAS13_DX':\n",
    "        n.ff1_ADAS13 = L.InnerProduct(n.ff3, num_output=node_sizes['ADAS_ff'], param=dict(lr_mult=1), weight_filler=dict(type='xavier'))\n",
    "        n.NLin1ADAS13 = L.ReLU(n.ff1_ADAS13, in_place=True)\n",
    "        n.ff1_DX = L.InnerProduct(n.ff3, num_output=node_sizes['DX_ff'], param=dict(lr_mult=1), weight_filler=dict(type='xavier'))\n",
    "        n.NLin1DX = L.ReLU(n.ff1_DX, in_place=True)\n",
    "        \n",
    "    else:\n",
    "        #n.ff4 = L.InnerProduct(n.ff3, num_output=node_sizes['ff4'], param=dict(lr_mult=1), weight_filler=dict(type='gaussian',std=0.177))\n",
    "        n.ff4 = L.InnerProduct(n.ff3, num_output=node_sizes['COMB_ff'], param=dict(lr_mult=1), weight_filler=dict(type='xavier'))\n",
    "        n.NLinEn4 = L.ReLU(n.ff4, in_place=True)\n",
    "    \n",
    "    #--------Output--------------#\n",
    "    #n.output = L.InnerProduct(n.ff4, num_output=1, weight_filler=dict(type='gaussian',std=0.177))          \n",
    "    if Clinical_Scale == 'ADAS13':\n",
    "        n.output = L.InnerProduct(n.ff4, num_output=1, weight_filler=dict(type='xavier'))\n",
    "        n.loss = L.EuclideanLoss(n.output, n.adas)            \n",
    "    elif Clinical_Scale == 'MMSE':\n",
    "        n.output = L.InnerProduct(n.ff4, num_output=1, weight_filler=dict(type='xavier'))\n",
    "        n.loss = L.EuclideanLoss(n.output, n.mmse)\n",
    "    elif Clinical_Scale == 'BOTH':\n",
    "        n.output_ADAS13 = L.InnerProduct(n.ff1_ADAS13, num_output=1, weight_filler=dict(type='xavier'))\n",
    "        n.ADAS13_loss = L.EuclideanLoss(n.output_ADAS13, n.adas,loss_weight=tr['ADAS'])          \n",
    "        n.output_MMSE = L.InnerProduct(n.ff1_MMSE, num_output=1, weight_filler=dict(type='xavier'))\n",
    "        n.MMSE_loss = L.EuclideanLoss(n.output_MMSE, n.mmse,loss_weight=tr['MMSE'])  \n",
    "    elif Clinical_Scale == 'DX':\n",
    "        n.output = L.InnerProduct(n.ff4, num_output=3, weight_filler=dict(type='xavier'))\n",
    "        n.loss = L.SoftmaxWithLoss(n.output, n.dx_cat3)\n",
    "        \n",
    "    elif Clinical_Scale == 'ADAS13_DX':\n",
    "        n.output_ADAS13 = L.InnerProduct(n.ff1_ADAS13, num_output=1, weight_filler=dict(type='xavier'))\n",
    "        n.ADAS13_loss = L.EuclideanLoss(n.output_ADAS13, n.adas,loss_weight=tr['ADAS'])          \n",
    "        n.output_DX = L.InnerProduct(n.ff1_DX, num_output=3, weight_filler=dict(type='xavier'))\n",
    "        n.DX_loss = L.SoftmaxWithLoss(n.output_DX, n.dx_cat3,loss_weight=tr['DX'])  \n",
    "    \n",
    "    else:\n",
    "        print 'Unknow Clinical Scale: {}'.format(Clinical_Scale)\n",
    "    \n",
    "    return n.to_proto()\n",
    "\n",
    "def adninet_ae(hdf5, batch_size,node_sizes,modality):\n",
    "    # logistic regression: data, matrix multiplication, and 2-class softmax loss\n",
    "    n = caffe.NetSpec()\n",
    "    \n",
    "    if modality == 'CT':\n",
    "        n.X_CT = L.HDF5Data(name='data',batch_size=batch_size, source=hdf5)\n",
    "        n.code = L.InnerProduct(n.X_CT, num_output=node_sizes['code'], weight_filler=dict(type='gaussian',std=.1, sparse=int(0.1*node_sizes['code'])))\n",
    "        n.NLinEn1 = L.ReLU(n.code, in_place=True)\n",
    "        n.dropC1 = L.Dropout(n.code, in_place=True,dropout_param=dict(dropout_ratio=dr['CT']))\n",
    "        \n",
    "    elif modality =='R_HC':\n",
    "        n.X_R_HC = L.HDF5Data(name='data',batch_size=batch_size, source=hdf5)\n",
    "        n.code = L.InnerProduct(n.X_R_HC, num_output=node_sizes['code'], weight_filler=dict(type='gaussian',std=.1, sparse=int(0.1*node_sizes['code'])))\n",
    "        n.NLinEn1 = L.ReLU(n.code, in_place=True)\n",
    "        n.drop1 = L.Dropout(n.code, in_place=True,dropout_param=dict(dropout_ratio=dr['HC']))\n",
    "        \n",
    "    elif modality =='L_HC':\n",
    "        n.X_L_HC = L.HDF5Data(name='data',batch_size=batch_size, source=hdf5)\n",
    "        n.code = L.InnerProduct(n.X_L_HC, num_output=node_sizes['code'], weight_filler=dict(type='gaussian',std=.1, sparse=int(0.1*node_sizes['code'])))       \n",
    "        n.NLinEn1 = L.ReLU(n.code, in_place=True)\n",
    "        n.drop1 = L.Dropout(n.code, in_place=True,dropout_param=dict(dropout_ratio=dr['HC']))\n",
    "        \n",
    "    elif modality =='HC_CT': #multimodal AE - experimental stage\n",
    "        HC_node_split = 0.8\n",
    "        n.X_L_HC = L.HDF5Data(name='data',batch_size=batch_size, source=hdf5)\n",
    "        n.encoder_L_HC = L.InnerProduct(n.X_L_HC, num_output=int(HC_node_split*node_sizes['En1']), weight_filler=dict(type='gaussian',std=.1, sparse=int(0.2*0.9*node_sizes['En1'])))        \n",
    "        n.NLinEn_L_HC = L.ReLU(n.encoder_L_HC, in_place=True)\n",
    "        \n",
    "        n.X_CT = L.HDF5Data(name='data',batch_size=batch_size, source=hdf5)\n",
    "        n.encoder_CT = L.InnerProduct(n.X_CT, num_output=int((1-HC_node_split)*node_sizes['En1']), weight_filler=dict(type='gaussian',std=.1, sparse=int(0.2*0.1*node_sizes['En1'])))        \n",
    "        n.NLinEn_CT = L.ReLU(n.encoder_CT, in_place=True)\n",
    "        \n",
    "        #Concat         \n",
    "        n.encoder1 = L.Concat(n.encoder_L_HC,n.encoder_CT, concat_param=dict(axis=1))\n",
    "        \n",
    "    else:\n",
    "        print \"wrong modality\"\n",
    "    \n",
    "    #Encoder layers (or common encoder layers for multimodal) \n",
    "    \n",
    "#     n.encoder2 = L.InnerProduct(n.encoder1, num_output=node_sizes['En2'], weight_filler=dict(type='xavier'))\n",
    "#     n.NLinEn2 = L.Sigmoid(n.encoder2, in_place=True)\n",
    "    #code layer\n",
    "#    n.code = L.InnerProduct(n.encoder1, num_output=node_sizes['code'], weight_filler=dict(type='xavier'))  \n",
    "    \n",
    "#     n.decoder1 = L.InnerProduct(n.code, num_output=node_sizes['En2'], weight_filler=dict(type='xavier'))\n",
    "#     n.NLinDe1 = L.ReLU(n.decoder1, in_place=True)\n",
    "    \n",
    "    #Decoder layers\n",
    "    if modality == 'CT':\n",
    "#         n.decoder1 = L.InnerProduct(n.code, num_output=node_sizes['En1'], weight_filler=dict(type='xavier'))\n",
    "#         n.NLinDe1 = L.ReLU(n.decoder1, in_place=True)\n",
    "        n.output = L.InnerProduct(n.code, num_output=node_sizes['out'], weight_filler=dict(type='xavier'))    \n",
    "        n.loss = L.EuclideanLoss(n.output, n.X_CT)                    \n",
    "    \n",
    "    elif modality =='R_HC':\n",
    "#         n.decoder1 = L.InnerProduct(n.code, num_output=node_sizes['En1'], weight_filler=dict(type='xavier'))\n",
    "#         n.NLinDe1 = L.ReLU(n.decoder1, in_place=True)\n",
    "        n.output = L.InnerProduct(n.code, num_output=node_sizes['out'], weight_filler=dict(type='xavier'))    \n",
    "        n.loss = L.SigmoidCrossEntropyLoss(n.output, n.X_R_HC)\n",
    "    elif modality =='L_HC':\n",
    "#         n.decoder1 = L.InnerProduct(n.code, num_output=node_sizes['En1'], weight_filler=dict(type='xavier'))\n",
    "#         n.NLinDe1 = L.ReLU(n.decoder1, in_place=True)\n",
    "        n.output = L.InnerProduct(n.code, num_output=node_sizes['out'], weight_filler=dict(type='xavier'))    \n",
    "        n.loss = L.SigmoidCrossEntropyLoss(n.output, n.X_L_HC)\n",
    "    elif modality =='HC_CT':        \n",
    "        n.decoder_L_HC = L.InnerProduct(n.code, num_output=int(HC_node_split*node_sizes['En1']), weight_filler=dict(type='xavier'))  \n",
    "        n.NLinDe_L_CT = L.ReLU(n.decoder_L_HC, in_place=True)\n",
    "        n.decoder_CT = L.InnerProduct(n.code, num_output=int((1-HC_node_split)*node_sizes['En1']), weight_filler=dict(type='xavier'))  \n",
    "        n.NLinDe_CT = L.ReLU(n.decoder_CT, in_place=True)\n",
    "        \n",
    "        n.output_L_HC = L.InnerProduct(n.decoder_L_HC, num_output=node_sizes['out_HC'], weight_filler=dict(type='xavier'))\n",
    "        n.loss_HC = L.SigmoidCrossEntropyLoss(n.output_L_HC, n.X_L_HC)\n",
    "        \n",
    "        n.output_CT = L.InnerProduct(n.decoder_CT, num_output=node_sizes['out_CT'], weight_filler=dict(type='xavier'))\n",
    "        n.loss_CT = L.EuclideanLoss(n.output_CT, n.X_CT)\n",
    "    else:\n",
    "        print \"wrong modality\"\n",
    "    \n",
    "    return n.to_proto()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 5.01 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def run_caffe(solver,niter,batch_size,multi_task,multi_label,multimodal_autoencode):\n",
    "    # each output is (batch size, feature dim, spatial dim)\n",
    "    #print [(k, v.data.shape) for k, v in solver.net.blobs.items()]\n",
    "    test_interval = 500\n",
    "    test_iter = 20\n",
    "    \n",
    "    if multimodal_autoencode:\n",
    "        train_loss_HC = zeros(niter)\n",
    "        test_loss_HC = zeros(int(np.ceil(niter / test_interval)))\n",
    "        train_loss_CT = zeros(niter)\n",
    "        test_loss_CT = zeros(int(np.ceil(niter / test_interval)))\n",
    "        \n",
    "        for it in range(niter):            \n",
    "            solver.step(1)  # SGD by Caffe \n",
    "            train_loss_HC[it] = solver.net.blobs['loss_HC'].data\n",
    "            train_loss_CT[it] = solver.net.blobs['loss_CT'].data\n",
    "            \n",
    "            if it % test_interval == 0:                        \n",
    "                t_loss_HC = 0\n",
    "                t_loss_CT = 0                                \n",
    "                for test_it in range(test_iter):\n",
    "                    solver.test_nets[0].forward()   \n",
    "                    t_loss_HC += solver.test_nets[0].blobs['loss_HC'].data\n",
    "                    t_loss_CT += solver.test_nets[0].blobs['loss_CT'].data\n",
    "                \n",
    "                test_loss_HC[it // test_interval] = t_loss_HC/(test_iter)\n",
    "                test_loss_CT[it // test_interval] = t_loss_CT/(test_iter)\n",
    "                print 'HC Loss Iteration: {}, train loss(batch, sum): ({},{}), test loss: {}'.format(\n",
    "                            it, train_loss_HC[it], np.sum(train_loss_HC)/it, test_loss_HC[it // test_interval])\n",
    "                print 'CT Loss Iteration: {}, train loss(batch, sum): ({},{}), test loss: {}'.format(\n",
    "                            it, train_loss_CT[it], np.sum(train_loss_CT)/it, test_loss_CT[it // test_interval])\n",
    "                \n",
    "        perf = {'train_loss':[train_loss_HC, train_loss_CT],'test_loss':[test_loss_HC,test_loss_CT]}\n",
    "    else: \n",
    "        \n",
    "        #n_feat = solver.test_nets[0].blobs['data'].data.shape[1]\n",
    "        # losses will also be stored in the log\n",
    "        test_acc = zeros(int(np.ceil(niter / test_interval)))\n",
    "        if not multi_task:\n",
    "            train_loss = zeros(niter)\n",
    "            test_loss = zeros(int(np.ceil(niter / test_interval)))  \n",
    "\n",
    "        else: \n",
    "            if multi_label:\n",
    "                train_ADAS13_loss = zeros(niter)\n",
    "                test_ADAS13_loss = zeros(int(np.ceil(niter / test_interval)))\n",
    "                train_DX_loss = zeros(niter)\n",
    "                test_DX_loss = zeros(int(np.ceil(niter / test_interval)))\n",
    "            else:\n",
    "                train_ADAS13_loss = zeros(niter)\n",
    "                test_ADAS13_loss = zeros(int(np.ceil(niter / test_interval)))\n",
    "                train_MMSE_loss = zeros(niter)\n",
    "                test_MMSE_loss = zeros(int(np.ceil(niter / test_interval)))\n",
    "\n",
    "        #output = zeros((niter, batch_size))\n",
    "        #solver.restore()\n",
    "        #the main solver loop\n",
    "        for it in range(niter):\n",
    "            #solver.net.forward()\n",
    "            solver.step(1)  # SGD by Caffe    \n",
    "            # store the train loss\n",
    "            if not multi_task:\n",
    "                train_loss[it] = solver.net.blobs['loss'].data        \n",
    "            else: \n",
    "                if multi_label:\n",
    "                    train_ADAS13_loss[it] = solver.net.blobs['ADAS13_loss'].data\n",
    "                    train_DX_loss[it] = solver.net.blobs['DX_loss'].data\n",
    "                else:\n",
    "                    train_ADAS13_loss[it] = solver.net.blobs['ADAS13_loss'].data\n",
    "                    train_MMSE_loss[it] = solver.net.blobs['MMSE_loss'].data\n",
    "\n",
    "            # store the output on the first test batch\n",
    "            # (start the forward pass at conv1 to avoid loading new data)\n",
    "            #solver.test_nets[0].forward()\n",
    "            #output[it] = solver.test_nets[0].blobs['output'].data\n",
    "\n",
    "            # run a full test every so often\n",
    "            # (Caffe can also do this for us and write to a log, but we show here\n",
    "            #  how to do it directly in Python, where more complicated things are easier.)\n",
    "            if it % test_interval == 0:        \n",
    "                t_loss = 0\n",
    "                t_ADAS13_loss = 0\n",
    "                t_MMSE_loss = 0\n",
    "                t_DX_loss = 0\n",
    "                correct = 0\n",
    "                for test_it in range(test_iter):\n",
    "                    solver.test_nets[0].forward()                \n",
    "                    if not multi_task:\n",
    "                        t_loss += solver.test_nets[0].blobs['loss'].data\n",
    "                        if multi_label:\n",
    "                            correct += sum(solver.test_nets[0].blobs['output'].data.argmax(1)\n",
    "                               == solver.test_nets[0].blobs['dx_cat3'].data)\n",
    "                    else: \n",
    "                        if multi_label:\n",
    "                            t_ADAS13_loss += solver.test_nets[0].blobs['ADAS13_loss'].data\n",
    "                            t_DX_loss += solver.test_nets[0].blobs['DX_loss'].data\n",
    "                            correct += sum(solver.test_nets[0].blobs['output_DX'].data.argmax(1)\n",
    "                               == solver.test_nets[0].blobs['dx_cat3'].data)\n",
    "\n",
    "                        else:\n",
    "                            t_ADAS13_loss += solver.test_nets[0].blobs['ADAS13_loss'].data\n",
    "                            t_MMSE_loss += solver.test_nets[0].blobs['MMSE_loss'].data\n",
    "\n",
    "                if not multi_task:\n",
    "                    test_loss[it // test_interval] = t_loss/(test_iter)\n",
    "                    if multi_label:\n",
    "                        test_acc[it // test_interval] = float(correct)/(test_iter*batch_size)\n",
    "                    print 'Iteration: {}, train loss(batch, sum): ({},{}), test loss: {}, test acc: {}'.format(\n",
    "                        it, train_loss[it], np.sum(train_loss)/it, test_loss[it // test_interval], test_acc[it // test_interval])\n",
    "                else:\n",
    "                    if multi_label:\n",
    "                        test_ADAS13_loss[it // test_interval] = t_ADAS13_loss/(test_iter)\n",
    "                        test_DX_loss[it // test_interval] = t_DX_loss/(test_iter) \n",
    "                        test_acc[it // test_interval] = float(correct)/(test_iter*batch_size)\n",
    "                        print 'ADAS Loss Iteration: {}, train loss(batch, sum): ({},{}), test loss: {}'.format(\n",
    "                            it, train_ADAS13_loss[it], np.sum(train_ADAS13_loss)/it, test_ADAS13_loss[it // test_interval])\n",
    "                        print 'DX Loss Iteration: {}, train loss(batch, sum): ({},{}), test loss: {}, test acc: {}'.format(\n",
    "                            it, train_DX_loss[it], np.sum(train_DX_loss)/it, test_DX_loss[it // test_interval],test_acc[it // test_interval])\n",
    "                    else:\n",
    "                        test_ADAS13_loss[it // test_interval] = t_ADAS13_loss/(test_iter)\n",
    "                        test_MMSE_loss[it // test_interval] = t_MMSE_loss/(test_iter)             \n",
    "\n",
    "                        print 'ADAS Loss Iteration: {}, train loss(batch, sum): ({},{}), test loss: {}'.format(\n",
    "                            it, train_ADAS13_loss[it], np.sum(train_ADAS13_loss)/it, test_ADAS13_loss[it // test_interval])\n",
    "                        print 'MMSE Loss Iteration: {}, train loss(batch, sum): ({},{}), test loss: {}'.format(\n",
    "                            it, train_MMSE_loss[it], np.sum(train_MMSE_loss)/it, test_MMSE_loss[it // test_interval])\n",
    "\n",
    "        if not multi_task:\n",
    "            perf = {'train_loss':[train_loss],'test_loss':[test_loss],'test_acc':[test_acc]}\n",
    "        else:\n",
    "            if multi_label:\n",
    "                perf = {'train_loss':[train_ADAS13_loss,train_DX_loss],'test_loss':[test_ADAS13_loss,test_DX_loss],'test_acc':[test_acc]}\n",
    "            else:\n",
    "                perf = {'train_loss':[train_ADAS13_loss,train_MMSE_loss],'test_loss':[test_ADAS13_loss,test_MMSE_loss]}\n",
    "                \n",
    "    return perf\n",
    "\n",
    "def pickleIt(my_data,save_path):\n",
    "    f = open(save_path, 'wb')\n",
    "    pickle.dump(my_data, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from caffe.proto import caffe_pb2\n",
    "### define solver\n",
    "def adni_solver(train_net_path, test_net_path,solver_configs,snap_prefix):    \n",
    "    s = caffe_pb2.SolverParameter()\n",
    "    \n",
    "    # Set a seed for reproducible experiments:\n",
    "    # this controls for randomization in training.\n",
    "    s.random_seed = 0xCAFFE\n",
    "\n",
    "    # Specify locations of the train and (maybe) test networks.\n",
    "    s.train_net = train_net_path\n",
    "    s.test_net.append(test_net_path)\n",
    "    s.test_interval = 500  # Test after every 500 training iterations.\n",
    "    s.test_iter.append(30) # Test on 100 batches each time we test.\n",
    "\n",
    "    s.max_iter = 10000     # no. of times to update the net (training iterations)\n",
    "\n",
    "    # EDIT HERE to try different solvers\n",
    "    # solver types include \"SGD\", \"Adam\", and \"Nesterov\" among others.\n",
    "    #s.solver_type = \"Nesterov\"\n",
    "\n",
    "    # Set the initial learning rate for SGD.\n",
    "    #s.base_lr = 0.00001  # EDIT HERE to try different learning rates\n",
    "    s.base_lr = solver_configs['base_lr']\n",
    "    # Set momentum to accelerate learning by\n",
    "    # taking weighted average of current and previous updates.\n",
    "    #if not s.type == \"AdaGrad\":\n",
    "    #    s.momentum = 0.9\n",
    "    # Set `lr_policy` to define how the learning rate changes during training.\n",
    "    # This is the same policy as our default LeNet.\n",
    "    s.lr_policy = \"step\"\n",
    "    s.stepsize = 100000\n",
    "    s.gamma = 0.5\n",
    "    #s.power = 0.75\n",
    "    # EDIT HERE to try the fixed rate (and compare with adaptive solvers)\n",
    "    # `fixed` is the simplest policy that keeps the learning rate constant.\n",
    "    # s.lr_policy = 'fixed'\n",
    "    \n",
    "    # Set weight decay to regularize and prevent overfitting\n",
    "    #s.weight_decay = 1e-3\n",
    "    s.weight_decay = solver_configs['wt_decay']\n",
    "    \n",
    "    # Display the current training loss and accuracy every 1000 iterations.\n",
    "    s.display = 1000\n",
    "\n",
    "    # Snapshots are files used to store networks we've trained.\n",
    "    # We'll snapshot every 5K iterations -- twice during training.\n",
    "    s.snapshot = 2000\n",
    "    s.snapshot_prefix = snap_prefix\n",
    "\n",
    "    # Train on the GPU\n",
    "    s.solver_mode = caffe_pb2.SolverParameter.GPU\n",
    "    \n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MC # 1, Hype # hyp1, Fold # 1\n",
      "loading pretrained weights from /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_1/fold1/pretrained_models/ADNI1_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "ADAS Loss Iteration: 0, train loss(batch, sum): (276.475646973,inf), test loss: 169.92746048\n",
      "MMSE Loss Iteration: 0, train loss(batch, sum): (302.885528564,inf), test loss: 332.851045227\n",
      "ADAS Loss Iteration: 500, train loss(batch, sum): (22.074508667,52.6853998051), test loss: 35.6385593414\n",
      "MMSE Loss Iteration: 500, train loss(batch, sum): (1.34378945827,15.8595392067), test loss: 2.77070240378\n",
      "ADAS Loss Iteration: 1000, train loss(batch, sum): (14.9592075348,46.7179109082), test loss: 40.9244294643\n",
      "MMSE Loss Iteration: 1000, train loss(batch, sum): (0.995526969433,9.27626489872), test loss: 2.87452240586\n",
      "ADAS Loss Iteration: 1500, train loss(batch, sum): (30.3080101013,44.6678233048), test loss: 38.3594620228\n",
      "MMSE Loss Iteration: 1500, train loss(batch, sum): (2.2852871418,7.05841777571), test loss: 3.20488662422\n",
      "ADAS Loss Iteration: 2000, train loss(batch, sum): (32.9175872803,43.5715505507), test loss: 35.5916507244\n",
      "MMSE Loss Iteration: 2000, train loss(batch, sum): (2.04333090782,5.93306683469), test loss: 2.83069300652\n",
      "ADAS Loss Iteration: 2500, train loss(batch, sum): (18.3448677063,42.826366807), test loss: 34.560012269\n",
      "MMSE Loss Iteration: 2500, train loss(batch, sum): (2.35992383957,5.24522218002), test loss: 2.74807761312\n",
      "ADAS Loss Iteration: 3000, train loss(batch, sum): (20.4445953369,42.2688045783), test loss: 38.9401221752\n",
      "MMSE Loss Iteration: 3000, train loss(batch, sum): (1.39151787758,4.77806262735), test loss: 2.77943681479\n",
      "ADAS Loss Iteration: 3500, train loss(batch, sum): (16.034954071,41.8009029147), test loss: 38.2815518856\n",
      "MMSE Loss Iteration: 3500, train loss(batch, sum): (1.5780775547,4.43372791591), test loss: 3.14745284915\n",
      "ADAS Loss Iteration: 4000, train loss(batch, sum): (36.303478241,41.3580021368), test loss: 35.2012887955\n",
      "MMSE Loss Iteration: 4000, train loss(batch, sum): (2.11407279968,4.16796995176), test loss: 2.86627978683\n",
      "ADAS Loss Iteration: 4500, train loss(batch, sum): (54.1884384155,40.9552968019), test loss: 32.4223039627\n",
      "MMSE Loss Iteration: 4500, train loss(batch, sum): (3.03806471825,3.95383324463), test loss: 2.86718289256\n",
      "ADAS Loss Iteration: 5000, train loss(batch, sum): (14.1200857162,40.5454591769), test loss: 37.6647330761\n",
      "MMSE Loss Iteration: 5000, train loss(batch, sum): (3.81588983536,3.77541171483), test loss: 2.81448776126\n",
      "ADAS Loss Iteration: 5500, train loss(batch, sum): (39.5640640259,40.1432042828), test loss: 37.4259981632\n",
      "MMSE Loss Iteration: 5500, train loss(batch, sum): (1.15686476231,3.62303813028), test loss: 3.19035060704\n",
      "ADAS Loss Iteration: 6000, train loss(batch, sum): (28.1780261993,39.7006312202), test loss: 35.1980164051\n",
      "MMSE Loss Iteration: 6000, train loss(batch, sum): (1.17724764347,3.49018627316), test loss: 3.02281347513\n",
      "ADAS Loss Iteration: 6500, train loss(batch, sum): (56.8936233521,39.2576671139), test loss: 30.9132810831\n",
      "MMSE Loss Iteration: 6500, train loss(batch, sum): (2.04409503937,3.37330284261), test loss: 2.90466136336\n",
      "ADAS Loss Iteration: 7000, train loss(batch, sum): (29.2030105591,38.7825667266), test loss: 35.6857928276\n",
      "MMSE Loss Iteration: 7000, train loss(batch, sum): (2.38369941711,3.2691012699), test loss: 2.77466870695\n",
      "ADAS Loss Iteration: 7500, train loss(batch, sum): (79.4760055542,38.2736741381), test loss: 36.3383804321\n",
      "MMSE Loss Iteration: 7500, train loss(batch, sum): (1.3378970623,3.17574119833), test loss: 3.14236900806\n",
      "ADAS Loss Iteration: 8000, train loss(batch, sum): (18.9493160248,37.720795594), test loss: 34.732222271\n",
      "MMSE Loss Iteration: 8000, train loss(batch, sum): (0.835664927959,3.09049121613), test loss: 3.30100032091\n",
      "ADAS Loss Iteration: 8500, train loss(batch, sum): (10.7540369034,37.1321810565), test loss: 28.7084315777\n",
      "MMSE Loss Iteration: 8500, train loss(batch, sum): (2.72506642342,3.01385235943), test loss: 3.11254045069\n",
      "ADAS Loss Iteration: 9000, train loss(batch, sum): (30.7079658508,36.5178888517), test loss: 33.3163013935\n",
      "MMSE Loss Iteration: 9000, train loss(batch, sum): (0.99727243185,2.9434092137), test loss: 2.97699785233\n",
      "ADAS Loss Iteration: 9500, train loss(batch, sum): (33.3356208801,35.8594029789), test loss: 33.7698343277\n",
      "MMSE Loss Iteration: 9500, train loss(batch, sum): (2.01218342781,2.87873774589), test loss: 3.27291504741\n",
      "ADAS Loss Iteration: 10000, train loss(batch, sum): (11.9239854813,35.1749144173), test loss: 33.4368419647\n",
      "MMSE Loss Iteration: 10000, train loss(batch, sum): (1.24649178982,2.81940259573), test loss: 3.48627230227\n",
      "ADAS Loss Iteration: 10500, train loss(batch, sum): (31.5264530182,34.4607044881), test loss: 27.8813383579\n",
      "MMSE Loss Iteration: 10500, train loss(batch, sum): (2.69441413879,2.76479242795), test loss: 3.26570422351\n",
      "ADAS Loss Iteration: 11000, train loss(batch, sum): (24.928976059,33.7290671147), test loss: 30.7774674892\n",
      "MMSE Loss Iteration: 11000, train loss(batch, sum): (1.16772758961,2.71410902114), test loss: 3.09630948305\n",
      "ADAS Loss Iteration: 11500, train loss(batch, sum): (18.8123836517,32.9888244949), test loss: 31.5972049236\n",
      "MMSE Loss Iteration: 11500, train loss(batch, sum): (1.85457658768,2.66777945555), test loss: 3.30537833869\n",
      "ADAS Loss Iteration: 12000, train loss(batch, sum): (9.69569683075,32.244015656), test loss: 33.8229963303\n",
      "MMSE Loss Iteration: 12000, train loss(batch, sum): (1.09026908875,2.62420619482), test loss: 3.48335732222\n",
      "ADAS Loss Iteration: 12500, train loss(batch, sum): (12.146987915,31.502793862), test loss: 28.4987297058\n",
      "MMSE Loss Iteration: 12500, train loss(batch, sum): (4.9370765686,2.58370826801), test loss: 3.32830517292\n",
      "ADAS Loss Iteration: 13000, train loss(batch, sum): (15.0657463074,30.7768055874), test loss: 30.3866298676\n",
      "MMSE Loss Iteration: 13000, train loss(batch, sum): (1.97560012341,2.54551340617), test loss: 3.13970098794\n",
      "ADAS Loss Iteration: 13500, train loss(batch, sum): (6.25067806244,30.0704412322), test loss: 31.391439724\n",
      "MMSE Loss Iteration: 13500, train loss(batch, sum): (0.697280168533,2.5095310699), test loss: 3.0946176827\n",
      "ADAS Loss Iteration: 14000, train loss(batch, sum): (15.605096817,29.3882140083), test loss: 35.5469130039\n",
      "MMSE Loss Iteration: 14000, train loss(batch, sum): (1.45671975613,2.47569867576), test loss: 3.4251318574\n",
      "ADAS Loss Iteration: 14500, train loss(batch, sum): (6.94568061829,28.73384129), test loss: 30.4819722176\n",
      "MMSE Loss Iteration: 14500, train loss(batch, sum): (0.936008572578,2.44360822409), test loss: 3.2081261158\n",
      "ADAS Loss Iteration: 15000, train loss(batch, sum): (17.3133621216,28.1064385098), test loss: 31.0404544353\n",
      "MMSE Loss Iteration: 15000, train loss(batch, sum): (1.31780123711,2.41340603455), test loss: 3.07548985481\n",
      "ADAS Loss Iteration: 15500, train loss(batch, sum): (11.8619804382,27.5056468561), test loss: 32.5221803188\n",
      "MMSE Loss Iteration: 15500, train loss(batch, sum): (3.22225260735,2.38484487945), test loss: 3.12778811455\n",
      "ADAS Loss Iteration: 16000, train loss(batch, sum): (10.0255336761,26.9307770648), test loss: 36.0645510197\n",
      "MMSE Loss Iteration: 16000, train loss(batch, sum): (0.494686305523,2.35788307258), test loss: 3.36899537742\n",
      "ADAS Loss Iteration: 16500, train loss(batch, sum): (13.487537384,26.3815939081), test loss: 31.9378907681\n",
      "MMSE Loss Iteration: 16500, train loss(batch, sum): (1.46579003334,2.33215953161), test loss: 3.15336737037\n",
      "ADAS Loss Iteration: 17000, train loss(batch, sum): (5.91994476318,25.8551920479), test loss: 31.309993124\n",
      "MMSE Loss Iteration: 17000, train loss(batch, sum): (1.48267507553,2.30756980729), test loss: 2.96629223824\n",
      "ADAS Loss Iteration: 17500, train loss(batch, sum): (6.51272344589,25.3518743712), test loss: 32.9489492893\n",
      "MMSE Loss Iteration: 17500, train loss(batch, sum): (0.786729931831,2.28395945406), test loss: 3.18748221695\n",
      "ADAS Loss Iteration: 18000, train loss(batch, sum): (5.55148363113,24.8686650532), test loss: 35.3647861958\n",
      "MMSE Loss Iteration: 18000, train loss(batch, sum): (1.53119206429,2.26137368801), test loss: 3.31075339913\n",
      "ADAS Loss Iteration: 18500, train loss(batch, sum): (17.7818279266,24.407196705), test loss: 33.049551487\n",
      "MMSE Loss Iteration: 18500, train loss(batch, sum): (1.08640503883,2.23972346535), test loss: 3.21825793684\n",
      "ADAS Loss Iteration: 19000, train loss(batch, sum): (5.89422130585,23.9634464339), test loss: 31.4112477779\n",
      "MMSE Loss Iteration: 19000, train loss(batch, sum): (0.98683822155,2.21891163502), test loss: 2.97489227057\n",
      "ADAS Loss Iteration: 19500, train loss(batch, sum): (5.9101896286,23.5374287624), test loss: 33.3041234016\n",
      "MMSE Loss Iteration: 19500, train loss(batch, sum): (1.83802318573,2.19897090361), test loss: 3.1013068378\n",
      "ADAS Loss Iteration: 20000, train loss(batch, sum): (18.4353141785,23.1282201632), test loss: 35.7395828724\n",
      "MMSE Loss Iteration: 20000, train loss(batch, sum): (1.67437970638,2.17991420921), test loss: 3.34539888501\n",
      "ADAS Loss Iteration: 20500, train loss(batch, sum): (6.30333137512,22.7332784529), test loss: 34.4013606071\n",
      "MMSE Loss Iteration: 20500, train loss(batch, sum): (1.54432284832,2.16163036901), test loss: 3.15511676669\n",
      "ADAS Loss Iteration: 21000, train loss(batch, sum): (9.26424598694,22.3530824305), test loss: 31.2314394474\n",
      "MMSE Loss Iteration: 21000, train loss(batch, sum): (1.11857879162,2.14397760032), test loss: 2.94666369557\n",
      "ADAS Loss Iteration: 21500, train loss(batch, sum): (4.13730192184,21.9857596685), test loss: 33.212385273\n",
      "MMSE Loss Iteration: 21500, train loss(batch, sum): (0.406179308891,2.12692724184), test loss: 3.10378001332\n",
      "ADAS Loss Iteration: 22000, train loss(batch, sum): (4.0043759346,21.6311303227), test loss: 35.2300271511\n",
      "MMSE Loss Iteration: 22000, train loss(batch, sum): (2.71573424339,2.11056098578), test loss: 3.38748780489\n",
      "ADAS Loss Iteration: 22500, train loss(batch, sum): (3.95043849945,21.2884728905), test loss: 33.7191160202\n",
      "MMSE Loss Iteration: 22500, train loss(batch, sum): (0.336891978979,2.09460880749), test loss: 3.18564056158\n",
      "ADAS Loss Iteration: 23000, train loss(batch, sum): (2.397803545,20.9583790482), test loss: 30.9885207176\n",
      "MMSE Loss Iteration: 23000, train loss(batch, sum): (0.390515595675,2.07920375049), test loss: 2.98300530612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/tigrlab/projects/nikhil/ADNI_prediction/code/conda_envs/adni-conda/lib/python2.7/site-packages/ipykernel/__main__.py:124: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/mnt/tigrlab/projects/nikhil/ADNI_prediction/code/conda_envs/adni-conda/lib/python2.7/site-packages/ipykernel/__main__.py:126: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-4ee199674ac6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;31m#run caffe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_caffe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mniter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmulti_task\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmulti_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmultimodal_autoencode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m             \u001b[0mCV_perf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36mrun_caffe\u001b[0;34m(solver, niter, batch_size, multi_task, multi_label, multimodal_autoencode)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Deign Net Architecutre and Run Caffe\n",
    "exp_name = 'Exp6_MC'\n",
    "cohort = 'ADNI1'\n",
    "#preproc = 'ae_preproc_sparse_HC_10k_CT_100k_hyp1'\n",
    "preproc = 'no_preproc'\n",
    "modality = 'HC_CT'\n",
    "Clinical_Scale = 'BOTH'    \n",
    "multi_label = False\n",
    "start_MC=1\n",
    "n_MC=1\n",
    "MC_list = np.arange(start_MC,n_MC+1,1)\n",
    "start_fold = 1\n",
    "n_folds = 1\n",
    "fid_list = np.arange(start_fold,n_folds+1,1)\n",
    "niter = 60000\n",
    "batch_size = 256\n",
    "\n",
    "pretrain = False\n",
    "multimodal_autoencode = False\n",
    "load_pretrained_weights = True\n",
    "\n",
    "if Clinical_Scale in ['BOTH','ADAS13_DX'] :\n",
    "    multi_task = True\n",
    "else:\n",
    "    multi_task = False\n",
    "\n",
    "#Hyperparameter Search\n",
    "#CT': 128, 'L_HC': 64, 'R_HC': 64, 'concat': 16\n",
    "#hyp1 and 2 work for ADNI1+2 MMSE\n",
    "# dr: Dropout rate, lr: learning rate of each modality, tr: loss-weight for each task\n",
    "hype_configs = {\n",
    "                'hyp1':{'node_sizes':{'HC_L_ff':25,'HC_R_ff':25,'CT_ff':100,'HC_CT_ff':25,'COMB_ff':25,\n",
    "                                       'ADAS_ff':25,'MMSE_ff':25,'DX_ff':25,\n",
    "                                       'En1':10000,'En2':2000,'code':600,'out':686},\n",
    "                      'dr':{'HC':0,'CT':0,'HC_CT':0,'COMB':0},'lr':{'HC':.1,'CT':.1,'COMB':1},\n",
    "                      'tr':{'ADAS':1,'MMSE':5,'DX':1},'solver_conf':{'base_lr':5e-6, 'wt_decay':1e-3}},\n",
    "    \n",
    "    \n",
    "#                 'hyp2':{'node_sizes':{'HC_L_ff':25,'HC_R_ff':25,'CT_ff':100,'HC_CT_ff':25,'COMB_ff':25,\n",
    "#                                        'ADAS_ff':25,'MMSE_ff':25,'DX_ff':25,\n",
    "#                                        'En1':10000,'En2':2000,'code':600,'out':686},\n",
    "#                       'dr':{'HC':0,'CT':0,'HC_CT':0,'COMB':0},'lr':{'HC':0.0,'CT':0.0,'COMB':1},\n",
    "#                       'tr':{'ADAS':1,'MMSE':8,'DX':1},'solver_conf':{'base_lr':5e-6, 'wt_decay':1e-3}},\n",
    "    \n",
    "#                 'hyp2':{'node_sizes':{'HC_L_ff':50,'HC_R_ff':50,'CT_ff':50,'HC_CT_ff':25,'COMB_ff':50,\n",
    "#                                        'ADAS_ff':25,'MMSE_ff':25,'DX_ff':25,\n",
    "#                                        'En1':10000,'En2':2000,'code':600,'out':686},\n",
    "#                       'dr':{'HC':0,'CT':0,'HC_CT':0,'COMB':0},'lr':{'HC':.2,'CT':.2,'COMB':1},\n",
    "#                       'tr':{'ADAS':1,'MMSE':8,'DX':1},'solver_conf':{'base_lr':5e-6, 'wt_decay':1e-3}},     \n",
    "                \n",
    "#                 'hyp3':{'node_sizes':{'HC_L_ff':50,'HC_R_ff':50,'CT_ff':200,'HC_CT_ff':25,'COMB_ff':50,\n",
    "#                                        'ADAS_ff':25,'MMSE_ff':25,'DX_ff':25,\n",
    "#                                        'En1':10000,'En2':2000,'code':600,'out':686},\n",
    "#                       'dr':{'HC':0,'CT':0,'HC_CT':0,'COMB':0},'lr':{'HC':0.1,'CT':0.1,'COMB':1},\n",
    "#                       'tr':{'ADAS':1,'MMSE':4,'DX':1},'solver_conf':{'base_lr':3e-6, 'wt_decay':1e-2}},   \n",
    "    \n",
    "#                 'hyp4':{'node_sizes':{'HC_L_ff':50,'HC_R_ff':50,'CT_ff':50,'HC_CT_ff':25,'COMB_ff':25,\n",
    "#                                        'ADAS_ff':25,'MMSE_ff':25,'DX_ff':25,\n",
    "#                                        'En1':10000,'En2':2000,'code':600,'out':686},\n",
    "#                       'dr':{'HC':0,'CT':0,'HC_CT':0,'COMB':0},'lr':{'HC':.1,'CT':.1,'HC_CT':1,'COMB':1},\n",
    "#                       'tr':{'ADAS':1,'MMSE':2,'DX':1},'solver_conf':{'base_lr':2e-6, 'wt_decay':1e-3}}\n",
    "                    \n",
    "#                  'hyp5':{'node_sizes':{'HC_L_ff':50,'HC_R_ff':50,'CT_ff':200,'HC_CT_ff':25,'COMB_ff':50,\n",
    "#                                        'ADAS_ff':25,'MMSE_ff':25,'DX_ff':25,\n",
    "#                                        'En1':10000,'En2':2000,'code':600,'out':686},\n",
    "#                       'dr':{'HC':0,'CT':0,'HC_CT':0,'COMB':0},'lr':{'HC':.1,'CT':.1,'COMB':1},\n",
    "#                       'tr':{'ADAS':1,'MMSE':4,'DX':1},'solver_conf':{'base_lr':7e-6, 'wt_decay':1e-3}},  \n",
    "    \n",
    "                    \n",
    "#                  'hyp6':{'node_sizes':{'HC_L_ff':50,'HC_R_ff':50,'CT_ff':200,'HC_CT_ff':25,'COMB_ff':50,\n",
    "#                                        'ADAS_ff':25,'MMSE_ff':25,'DX_ff':25,\n",
    "#                                        'En1':10000,'En2':2000,'code':600,'out':686},\n",
    "#                       'dr':{'HC':0,'CT':0,'HC_CT':0,'COMB':0},'lr':{'HC':0,'CT':0,'COMB':1},\n",
    "#                       'tr':{'ADAS':1,'MMSE':8,'DX':1},'solver_conf':{'base_lr':7e-6, 'wt_decay':1e-3}},  \n",
    "                }\n",
    "\n",
    "CV_perf_MC = {}\n",
    "for mc in MC_list:\n",
    "    CV_perf_hype = {}\n",
    "    for hype in hype_configs.keys():    \n",
    "        node_sizes = hype_configs[hype]['node_sizes']\n",
    "        dr = hype_configs[hype]['dr']\n",
    "        lr = hype_configs[hype]['lr']\n",
    "        tr = hype_configs[hype]['tr']\n",
    "        solver_configs = hype_configs[hype]['solver_conf']\n",
    "        \n",
    "        if hype in ['hyp1','hyp2']:\n",
    "            HC_snap = 20000 #20000 for ADNI2 5000 for ADNI1\n",
    "            CT_snap = 20000 #20000 for ADNI2 5000 for ADNI1\n",
    "            pre_hype = 'hyp2'\n",
    "        else:\n",
    "            print 'unknown hyp config'\n",
    "            \n",
    "            print hype, pre_hype,HC_snap,CT_snap\n",
    "            \n",
    "        CV_perf = {}\n",
    "        start_time = time.time()\n",
    "        for fid in fid_list:            \n",
    "            print ''\n",
    "            print 'MC # {}, Hype # {}, Fold # {}'.format(mc, hype, fid)\n",
    "            snap_prefix = baseline_dir + 'API/data/MC_{}/fold{}/train_snaps/{}_{}_{}'.format(mc,fid,exp_name,hype,modality)\n",
    "\n",
    "            train_filename_txt = baseline_dir + 'API/data/MC_{}/fold{}/train_C688.txt'.format(mc,fid)\n",
    "            test_filename_txt = baseline_dir + 'API/data/MC_{}/fold{}/test_C688.txt'.format(mc,fid)\n",
    "\n",
    "            train_filename_hdf = baseline_dir + 'API/data/MC_{}/fold{}/inner_train/{}.h5'.format(mc,fid,exp_name)\n",
    "            test_filename_hdf = baseline_dir + 'API/data/MC_{}/fold{}/inner_test/{}.h5'.format(mc,fid,exp_name)\n",
    "            with open(train_filename_txt, 'w') as f:\n",
    "                    f.write(train_filename_hdf + '\\n')    \n",
    "\n",
    "            with open(test_filename_txt, 'w') as f:\n",
    "                    f.write(test_filename_hdf + '\\n')  \n",
    "\n",
    "            # Define Net (examples: 'ADNI_AE_train.prototxt', 'ADNI_FF_train.prototxt')\n",
    "            if pretrain:\n",
    "                train_net_path = baseline_dir + 'API/data/MC_{}/fold{}/ADNI_AE_train.prototxt'.format(mc,fid)\n",
    "                with open(train_net_path, 'w') as f:\n",
    "                    f.write(str(adninet_ae(train_filename_txt, batch_size, node_sizes, modality)))            \n",
    "            else:\n",
    "                train_net_path = baseline_dir + 'API/data/MC_{}/fold{}/ADNI_FF_train_{}_{}.prototxt'.format(mc,fid,hype,modality)\n",
    "                with open(train_net_path, 'w') as f:            \n",
    "                    if modality == 'HC':\n",
    "                          f.write(str(adninet_ff_HC(train_filename_txt, batch_size, node_sizes,dr, lr, tr, Clinical_Scale)))\n",
    "                    elif modality == 'CT':\n",
    "                          f.write(str(adninet_ff_CT(train_filename_txt, batch_size, node_sizes,dr, lr, tr, Clinical_Scale)))\n",
    "                    elif modality == 'HC_CT':\n",
    "                          f.write(str(adninet_ff_HC_CT(train_filename_txt, batch_size, node_sizes,dr, lr, tr, Clinical_Scale )))\n",
    "                    elif modality == 'HC_CT_unified_hyp1':\n",
    "                          f.write(str(adninet_ff_HC_CT_unified(train_filename_txt, batch_size, node_sizes,dr, lr, tr, Clinical_Scale )))\n",
    "                    else:\n",
    "                          print 'Wrong modality'\n",
    "\n",
    "            if pretrain:\n",
    "                test_net_path = baseline_dir + 'API/data/MC_{}/fold{}/ADNI_AE_test.prototxt'.format(mc,fid)\n",
    "                with open(test_net_path, 'w') as f:\n",
    "                    f.write(str(adninet_ae(test_filename_txt, batch_size, node_sizes,modality)))\n",
    "            else:\n",
    "                test_net_path = baseline_dir + 'API/data/MC_{}/fold{}/ADNI_FF_test_{}_{}.prototxt'.format(mc,fid,hype,modality)\n",
    "                with open(test_net_path, 'w') as f:\n",
    "                    if modality == 'HC':\n",
    "                          f.write(str(adninet_ff_HC(test_filename_txt, batch_size, node_sizes,dr, lr, tr, Clinical_Scale)))\n",
    "                    elif modality == 'CT':\n",
    "                          f.write(str(adninet_ff_CT(test_filename_txt, batch_size, node_sizes,dr, lr, tr, Clinical_Scale)))\n",
    "                    elif modality == 'HC_CT':\n",
    "                          f.write(str(adninet_ff_HC_CT(test_filename_txt, batch_size, node_sizes,dr, lr, tr, Clinical_Scale)))\n",
    "                    elif modality == 'HC_CT_unified_hyp1':\n",
    "                          f.write(str(adninet_ff_HC_CT_unified(test_filename_txt, batch_size, node_sizes,dr, lr, tr, Clinical_Scale )))\n",
    "                    else:\n",
    "                          print 'Wrong modality'\n",
    "\n",
    "            # Define Solver\n",
    "            solver_path = baseline_dir + 'API/model_configs/adninet_solver.prototxt'\n",
    "            with open(solver_path, 'w') as f:\n",
    "                f.write(str(adni_solver(train_net_path, test_net_path, solver_configs, snap_prefix)))\n",
    "\n",
    "            ### load the solver and create train and test nets\n",
    "            #solver = None  # ignore this workaround for lmdb data (can't instantiate two solvers on the same data)\n",
    "            #solver = caffe.get_solver(solver_path)\n",
    "            #solver = caffe.NesterovSolver(solver_path)\n",
    "            solver = caffe.NesterovSolver(solver_path)\n",
    "\n",
    "            if load_pretrained_weights:                    \n",
    "                net_name = 'API/data/MC_{}/fold{}/pretrained_models/{}_ff_{}_HC_CT_HC_snap_{}_CT_snap_{}_Sup_Concat.caffemodel'\n",
    "                snap_path = baseline_dir + net_name.format(mc,fid,cohort,pre_hype,HC_snap,CT_snap)\n",
    "                print \"loading pretrained weights from {}\".format(snap_path)        \n",
    "                solver.net.copy_from(snap_path)\n",
    "\n",
    "            #run caffe\n",
    "            results = run_caffe(solver,niter,batch_size,multi_task,multi_label,multimodal_autoencode)\n",
    "            CV_perf[fid] = results\n",
    "            \n",
    "        print('run time for single CV loop: {}'.format(time.time() - start_time))\n",
    "\n",
    "        CV_perf_hype[hype] = CV_perf\n",
    "        \n",
    "CV_perf_MC[mc] = CV_perf_hype\n",
    "\n",
    "# pickleIt(CV_perf_MC, baseline_dir + 'API/CV_perf/train_loss_{}'.format(modality))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.27777777778\n",
      "5.56666666667\n"
     ]
    }
   ],
   "source": [
    "#Time for training \n",
    "#HC_CT fold 9,10, number of iterations: 40k, two hyper-params\n",
    "#start time: 14:47\n",
    "#end time: 15:31\n",
    "#runtime_mean = (13+31)/4\n",
    "#print runtime_mean\n",
    "\n",
    "tx=670/4 #time for 10k iters\n",
    "itx=4 # num of 10k iters\n",
    "hx=2 #hyp choices\n",
    "fx=5 #k-folds\n",
    "mx=5 #mc-folds\n",
    "\n",
    "num_hrs = (tx*itx*hx*fx*mx)/(3600.0)\n",
    "print num_hrs\n",
    "\n",
    "time_for_single_model = num_hrs*36/60\n",
    "print time_for_single_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABbcAAAJoCAYAAABVztwOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9258b43d10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot train loss and acc\n",
    "plt.rcParams['figure.figsize'] = (25, 10)\n",
    "#niter = 30000\n",
    "test_interval = 500\n",
    "n_mc = len(CV_perf_MC.keys())\n",
    "\n",
    "for m, mc in enumerate(CV_perf_MC.keys()): \n",
    "    CV_perf_hype = CV_perf_MC[mc]\n",
    "    \n",
    "    for hype in CV_perf_hype.keys(): \n",
    "        CV_perf = CV_perf_hype[hype]\n",
    "        n_CV_configs = len(CV_perf)\n",
    "        pid = m*n_CV_configs + 1\n",
    "        \n",
    "        for f, fid in enumerate(fid_list):  \n",
    "            train_loss_list = CV_perf[fid]['train_loss']\n",
    "            test_loss_list = CV_perf[fid]['test_loss']\n",
    "            \n",
    "            for train_loss, test_loss in zip(train_loss_list,test_loss_list):\n",
    "                #plt.figure()\n",
    "                ax1 = plt.subplot(n_mc,n_CV_configs,pid)            \n",
    "                ax1.plot(arange(niter), train_loss, label='train',linewidth='.5',alpha=0.25)\n",
    "                ax1.plot(test_interval * arange(len(test_loss)), test_loss, label='test_{}'.format(hype), linewidth='3')                            \n",
    "                ax1.set_xlabel('iteration')\n",
    "                ax1.set_ylabel('loss')\n",
    "                ax1.set_title('fid: {}, hyp: {}, Test loss: {:.2f}'.format(fid, hype, test_loss[-1]))\n",
    "                ax1.legend(loc=1)\n",
    "                ax1.set_ylim(0,100)\n",
    "            pid += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp_name = 'Exp11'\n",
    "preproc = 'no_preproc'\n",
    "modality = 'R_HC'\n",
    "batch_size = 256\n",
    "encoding_layer = 'code'\n",
    "weight_layers = 'code'\n",
    "multi_task = False\n",
    "\n",
    "if modality in ['L_HC', 'R_HC']:\n",
    "    snap_iter = 10000\n",
    "    \n",
    "    if modality == 'R_HC':\n",
    "        output_node_size = 16471\n",
    "    else: \n",
    "        output_node_size = 16086\n",
    "        \n",
    "    hype_configs = {\n",
    "                   'hyp1':{'node_sizes':{'En1':10000,'En2':2000,'code':8000,'out':output_node_size},\n",
    "                  'dr':{'HC':0,'CT':0,'COMB':0},'lr':{'HC':2,'CT':2},\n",
    "                  'solver_conf':{'base_lr':1e-5, 'wt_decay':1e-3}}\n",
    "    }\n",
    "\n",
    "elif modality in ['CT']:  \n",
    "    snap_iter = 100000\n",
    "    \n",
    "    hype_configs = {\n",
    "                    'hyp1':{'node_sizes':{'code':600,'out':686},\n",
    "                      'dr':{'HC':0,'CT':0,'HC_CT':0,'COMB':0},'lr':{'HC':2,'CT':2,'HC_CT':2},'tr':{'ADAS':1,'MMSE':2,'DX':1},\n",
    "                      'solver_conf':{'base_lr':1e-4, 'wt_decay':1e-3}}\n",
    "    }\n",
    "    \n",
    "elif modality in ['HC_CT']:  \n",
    "    snap_iter = 20000\n",
    "    hype_configs = {\n",
    "                 'hyp1':{'node_sizes':{'En1':10000,'En2':2000,'code':500,'out_HC':16086,'out_CT':686},\n",
    "                  'dr':{'HC':0,'CT':0,'COMB':0},'lr':{'HC':2,'CT':2},\n",
    "                  'solver_conf':{'base_lr':1e-5, 'wt_decay':1e-3}}\n",
    "    }\n",
    "    \n",
    "hype = 'hyp1'\n",
    "pretrain_preproc = 'ae_preproc_sparse_HC_10k_CT_100k_{}'.format(hype)\n",
    "fid = 1\n",
    "node_sizes = hype_configs[hype]['node_sizes']\n",
    "dr = hype_configs[hype]['dr']\n",
    "lr = hype_configs[hype]['lr']\n",
    "\n",
    "# Save either L or R HC encodings. Turn on CT + CS save only for one of these. \n",
    "# (Also decide if you want to copy CT raw scores or encodings)\n",
    "save_encodings = True\n",
    "save_scores = False\n",
    "CT_encodings = True\n",
    "\n",
    "for cohort in ['inner_train', 'inner_test','outer_test']:\n",
    "    data_path = baseline_dir + 'API/data/fold{}/{}/{}_{}.h5'.format(fid,cohort,exp_name,preproc)\n",
    "    test_filename_txt = baseline_dir + 'API/data/fold{}/test_C688.txt'.format(fid)\n",
    "    test_net_path = baseline_dir + 'API/data/fold{}/ADNI_AE_test.prototxt'.format(fid)       \n",
    "    input_nodes = ['X_{}'.format(modality)]\n",
    "    #input_nodes = ['X_L_HC','X_CT']\n",
    "    net_file = baseline_dir + 'API/data/fold{}/ADNI_AE_test.prototxt'.format(fid)\n",
    "    with open(net_file, 'w') as f:\n",
    "        f.write(str(adninet_ae(test_filename_txt, 256, node_sizes,modality)))\n",
    "\n",
    "    test_filename_hdf = baseline_dir + 'API/data/fold{}/{}/{}_{}.h5'.format(fid,cohort,exp_name,preproc)\n",
    "    test_filename_txt = baseline_dir + 'API/data/fold{}/{}_C688.txt'.format(fid,cohort)\n",
    "    with open(test_filename_txt, 'w') as f:\n",
    "        f.write(test_filename_hdf + '\\n') \n",
    "\n",
    "    sub.call([\"cp\", baseline_dir + 'API/data/fold{}/{}_C688.txt'.format(fid,cohort), baseline_dir + 'API/data/fold{}/test_C688.txt'.format(fid)])\n",
    "\n",
    "    if modality == 'CT':\n",
    "        model_file = baseline_dir + 'API/data/fold{}/train_snaps/{}_{}_{}_iter_{}.caffemodel'.format(fid,exp_name,hype,modality,snap_iter)  \n",
    "    else:\n",
    "        model_file = baseline_dir + 'API/data/fold{}/train_snaps/{}_{}_{}_iter_{}.caffemodel'.format(fid,exp_name,hype,modality,snap_iter)  \n",
    "        \n",
    "    print 'Check Sparsity for model: {}'.format(model_file)\n",
    "    \n",
    "    results = extract_features(net_file, model_file, data_path, input_nodes, batch_size, encoding_layer, weight_layers,multi_task)\n",
    "    encodings = np.squeeze(results['X_out'])      \n",
    "    \n",
    "    encodings_hdf_file = baseline_dir + 'API/data/fold{}/{}/{}_{}.h5'.format(fid,cohort,exp_name,pretrain_preproc)\n",
    "    \n",
    "    if save_encodings:    \n",
    "        input_data = h5py.File(encodings_hdf_file, 'a')\n",
    "        input_data.create_dataset(input_nodes[0],data=encodings)           \n",
    "        input_data.close()\n",
    "        \n",
    "    if save_scores:\n",
    "        input_data = h5py.File(encodings_hdf_file, 'a')\n",
    "        if not CT_encodings: #copy raw scores for CT instead of encodings\n",
    "            CT_data = load_data(data_path, 'X_CT','no_preproc')                    \n",
    "            input_data.create_dataset('X_CT', data=CT_data)    \n",
    "            \n",
    "        adas_scores = load_data(data_path, 'y','no_preproc')\n",
    "        mmse_scores = load_data(data_path, 'y3','no_preproc')\n",
    "        dx_labels = load_data(data_path, 'dx_cat3','no_preproc')\n",
    "        input_data.create_dataset('y', data=adas_scores)           \n",
    "        input_data.create_dataset('y3', data=mmse_scores)    \n",
    "        input_data.create_dataset('dx_cat3', data=dx_labels)\n",
    "        input_data.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting TSNE embeddings \n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "exp_name = 'Exp11'\n",
    "#preproc = 'no_preproc'\n",
    "#preproc = 'ae_preproc_sparse_HC_10k_CT_100k_hyp1'\n",
    "Clinical_Scale = 'ADAS13_DX' \n",
    "batch_size = 256\n",
    "snap_interval = 2000\n",
    "snap_start = 2000\n",
    "encoding_layer = 'ff3'\n",
    "weight_layers = 'ff3'\n",
    "cohort = 'outer_test'\n",
    "multi_task = False\n",
    "\n",
    "modality = 'HC_CT'\n",
    "snap_end = 21000\n",
    "\n",
    "\n",
    "hype_configs = {\n",
    "            'hyp1':{'node_sizes':{'HC_L_ff':25,'HC_R_ff':25,'CT_ff':25,'HC_CT_ff':25,'COMB_ff':25,'ADAS_ff':25,'MMSE_ff':25,'DX_ff':25,\n",
    "                                       'En1':10000,'En2':2000,'code':600,'out':686},\n",
    "                      'dr':{'HC':0,'CT':0,'HC_CT':0,'COMB':0},'lr':{'HC':2,'CT':2,'HC_CT':2},'tr':{'ADAS':1,'MMSE':2,'DX':1},\n",
    "                      'solver_conf':{'base_lr':1e-6, 'wt_decay':1e-2}},\n",
    "}\n",
    "\n",
    "hype = 'hyp1'\n",
    "fid = 1\n",
    "node_sizes = hype_configs[hype]['node_sizes']\n",
    "dr = hype_configs[hype]['dr']\n",
    "lr = hype_configs[hype]['lr']\n",
    "tr = hype_configs[hype]['tr']\n",
    "\n",
    "data_path = baseline_dir + 'API/data/fold{}/{}/{}_{}.h5'.format(fid,cohort,exp_name,preproc)\n",
    "test_filename_txt = baseline_dir + 'API/data/fold{}/test_C688.txt'.format(fid)\n",
    "test_net_path = baseline_dir + 'API/data/fold{}/ADNI_ff_test.prototxt'.format(fid)       \n",
    "#input_node = 'X_{}'.format(modality)\n",
    "\n",
    "net_file = baseline_dir + 'API/data/fold{}/ADNI_ff_test.prototxt'.format(fid)\n",
    "with open(net_file, 'w') as f:\n",
    "    #f.write(str(adninet_ae(test_filename_txt, 256, node_sizes,modality)))\n",
    "    f.write(str(adninet_ff_HC_CT(test_filename_txt, 256, node_sizes,dr,lr,tr,Clinical_Scale)))\n",
    "    input_nodes = ['X_L_HC','X_R_HC','X_CT']\n",
    "\n",
    "test_filename_hdf = baseline_dir + 'API/data/fold{}/{}/{}_{}.h5'.format(fid,cohort,exp_name,preproc)\n",
    "test_filename_txt = baseline_dir + 'API/data/fold{}/{}_C688.txt'.format(fid,cohort)\n",
    "with open(test_filename_txt, 'w') as f:\n",
    "    f.write(test_filename_hdf + '\\n') \n",
    "\n",
    "sub.call([\"cp\", baseline_dir + 'API/data/fold{}/{}_C688.txt'.format(fid,cohort), baseline_dir + 'API/data/fold{}/test_C688.txt'.format(fid)])\n",
    "\n",
    "n_snaps = len(np.arange(snap_start,snap_end,snap_interval))\n",
    "tsne_encodings = {}\n",
    "net_weights = {}\n",
    "for sn, snap_iter in enumerate(np.arange(snap_start,snap_end,snap_interval)):\n",
    "    print sn, snap_iter\n",
    "    model_file = baseline_dir + 'API/data/fold{}/train_snaps/{}_{}_{}_iter_{}.caffemodel'.format(fid,exp_name,hype,modality,snap_iter)        \n",
    "    results = extract_features(net_file, model_file, data_path, input_nodes, batch_size, encoding_layer, weight_layers,multi_task)\n",
    "    encodings = np.squeeze(results['X_out'])      \n",
    "    net_weights[snap_iter] = results['wt_dict']\n",
    "    print encodings.shape\n",
    "\n",
    "    adas_scores = load_data(data_path, 'y','no_preproc')\n",
    "    mmse_scores = load_data(data_path, 'y3','no_preproc')\n",
    "    dx_labels = load_data(data_path, 'dx_cat3','no_preproc')\n",
    "    tsne_model = TSNE(n_components=2, random_state=0, init='pca')\n",
    "    tsne_encodings[snap_iter] = tsne_model.fit_transform(encodings) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (20, 20)\n",
    "plot_encodings = True\n",
    "plot_wts = False\n",
    "\n",
    "color_scores = dx_labels\n",
    "cm = plt.get_cmap('RdYlBu') \n",
    "marker_size = 100\n",
    "marker_size = (np.mod(color_scores+1,2)+1)*50\n",
    "\n",
    "for sn, snap_iter in enumerate(np.arange(snap_start,snap_end,snap_interval)):\n",
    "    plt.subplot(np.ceil(n_snaps/2.0),2,sn+1)\n",
    "    if plot_encodings:\n",
    "        plt.scatter(tsne_encodings[snap_iter][:,0],tsne_encodings[snap_iter][:,1],c=color_scores,s=marker_size,cmap=cm)\n",
    "    if plot_wts:\n",
    "        plt.imshow(net_weights[snap_iter][weight_layers])\n",
    "        \n",
    "    plt.title(snap_iter)\n",
    "    plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exp6_MC 1 HC_CT\n",
      "Weights Tuned for: both\n",
      "Clinical_Scale: BOTH\n",
      "ADAS corr: [0.59828088703945081]\n",
      "ADAS mse: [50.580842453625266]\n",
      "ADAS means: 0.598280887039, 50.5808424536\n",
      "\n",
      "MMSE corr: [0.50830685801571374]\n",
      "MMSE mse: [5.0539211198694618]\n",
      "MMSE means: 0.508306858016, 5.05392111987\n",
      "\n",
      "opt_hyp: {1: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 5}, 'node_sizes': {'COMB_ff': 25, 'HC_L_ff': 25, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 100, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 25}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 0.1, 'COMB': 1, 'CT': 0.1}}}\n",
      "\n",
      "opt_snap: {1: 2}\n",
      "Weights Tuned for: adas\n",
      "Clinical_Scale: BOTH\n",
      "ADAS corr: [0.59828088703945081]\n",
      "ADAS mse: [50.580842453625266]\n",
      "ADAS means: 0.598280887039, 50.5808424536\n",
      "\n",
      "MMSE corr: [0.50830685801571374]\n",
      "MMSE mse: [5.0539211198694618]\n",
      "MMSE means: 0.508306858016, 5.05392111987\n",
      "\n",
      "opt_hyp: {1: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 5}, 'node_sizes': {'COMB_ff': 25, 'HC_L_ff': 25, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 100, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 25}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 0.1, 'COMB': 1, 'CT': 0.1}}}\n",
      "\n",
      "opt_snap: {1: 2}\n",
      "Weights Tuned for: mmse\n",
      "Clinical_Scale: BOTH\n",
      "ADAS corr: [-0.008355662969101639]\n",
      "ADAS mse: [76.178142218193742]\n",
      "ADAS means: -0.0083556629691, 76.1781422182\n",
      "\n",
      "MMSE corr: [0.51043801770104624]\n",
      "MMSE mse: [4.6746058741528564]\n",
      "MMSE means: 0.510438017701, 4.67460587415\n",
      "\n",
      "opt_hyp: {1: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 5}, 'node_sizes': {'COMB_ff': 25, 'HC_L_ff': 25, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 100, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 25}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 0.1, 'COMB': 1, 'CT': 0.1}}}\n",
      "\n",
      "opt_snap: {1: 0}\n"
     ]
    }
   ],
   "source": [
    "#Get encodings after training\n",
    "#train_filename_hdf = baseline_dir + 'data/train_CT_C688_normed.h5'\n",
    "#test_filename_hdf = baseline_dir + 'data/test_CT_C688_normed.h5'\n",
    "#fid=2\n",
    "#exp_name = 'Exp11'\n",
    "niter = 20000\n",
    "#modality = 'CT'\n",
    "start_fold = 1\n",
    "n_folds = 1\n",
    "fid_list = np.arange(start_fold,n_folds+1,1)\n",
    "#preproc = 'no_preproc'\n",
    "#batch_size = 256\n",
    "snap_interval = 4000\n",
    "snap_start = 4000\n",
    "encoding_layer = 'output'\n",
    "weight_layers = 'output'\n",
    "cohort = 'outer_test'\n",
    "#Clinical_Scale = 'ADAS13'\n",
    "\n",
    "#MC_list = np.arange(1,11,1)\n",
    "\n",
    "if Clinical_Scale in ['ADAS13', 'MMSE']:\n",
    "    fold_euLoss = {}\n",
    "    fold_r = {}\n",
    "    fold_act_scores = {}\n",
    "    fold_pred_scores = {}\n",
    "elif Clinical_Scale == 'BOTH':\n",
    "    fold_euLoss_adas13 = {}\n",
    "    fold_r_adas13 = {}\n",
    "    fold_act_scores_adas13 = {}\n",
    "    fold_pred_scores_adas13 = {}\n",
    "    fold_euLoss_mmse = {}\n",
    "    fold_r_mmse = {}\n",
    "    fold_act_scores_mmse = {}\n",
    "    fold_pred_scores_mmse = {}\n",
    "    \n",
    "idx = 0  \n",
    "df_perf_dict_adas = {}\n",
    "df_perf_dict_mmse = {}\n",
    "df_perf_dict_adas_tuned = {}\n",
    "df_perf_dict_mmse_tuned = {}\n",
    "df_perf_dict_opt = {}\n",
    "\n",
    "for mc in MC_list:\n",
    "    print exp_name, mc, modality\n",
    "\n",
    "    for hype in hype_configs.keys():      \n",
    "        node_sizes = hype_configs[hype]['node_sizes']\n",
    "        dr = hype_configs[hype]['dr']\n",
    "        lr = hype_configs[hype]['lr']\n",
    "\n",
    "        for fid in fid_list:\n",
    "            test_filename_txt = baseline_dir + 'API/data/MC_{}/fold{}/test_C688.txt'.format(mc,fid)\n",
    "            #test_filename_hdf = baseline_dir + 'API/data/fold{}/outer_test/{}_{}.h5'.format(fid,exp_name,preproc)\n",
    "            #with open(test_filename_txt, 'w') as f:\n",
    "            #        f.write(test_filename_hdf + '\\n')  \n",
    "\n",
    "            test_net_path = baseline_dir + 'API/data/MC_{}/fold{}/ADNI_FF_test.prototxt'.format(mc,fid)\n",
    "            with open(test_net_path, 'w') as f:\n",
    "                if modality == 'HC':\n",
    "                    f.write(str(adninet_ff_HC(test_filename_txt, batch_size, node_sizes,dr,lr,tr,Clinical_Scale)))\n",
    "                    input_nodes = ['X_L_HC','X_R_HC']\n",
    "                elif modality == 'CT':\n",
    "                    f.write(str(adninet_ff_CT(test_filename_txt, batch_size, node_sizes,dr,lr,tr,Clinical_Scale)))\n",
    "                    input_nodes = ['X_CT_SpecCluster_dyn']\n",
    "                elif modality == 'HC_CT':\n",
    "                    f.write(str(adninet_ff_HC_CT(test_filename_txt, batch_size, node_sizes,dr,lr,tr,Clinical_Scale)))\n",
    "                    input_nodes = ['X_L_HC','X_R_HC','X_CT_SpecCluster_dyn']\n",
    "                elif modality == 'HC_CT_unified_hyp1':\n",
    "                    f.write(str(adninet_ff_HC_CT_unified(test_filename_txt, batch_size, node_sizes,dr,lr,tr,Clinical_Scale)))\n",
    "                    input_nodes = ['X_HC_CT']\n",
    "                else:\n",
    "                    print 'Wrong modality'\n",
    "\n",
    "            #print 'Hype # {}, MC # {}, Fold # {}, Clinical_Scale {}'.format(hype, mc, fid, Clinical_Scale)\n",
    "            data_path = baseline_dir + 'API/data/MC_{}/fold{}/{}/{}.h5'.format(mc,fid,cohort,exp_name)\n",
    "            if Clinical_Scale == 'ADAS13':\n",
    "                act_scores = load_data(data_path, 'adas','no_preproc')\n",
    "            elif Clinical_Scale == 'MMSE': \n",
    "                act_scores = load_data(data_path, 'mmse','no_preproc')\n",
    "            elif Clinical_Scale == 'BOTH':\n",
    "                act_scores_adas13 = load_data(data_path, 'adas','no_preproc')\n",
    "                act_scores_mmse = load_data(data_path, 'mmse','no_preproc')\n",
    "            else:\n",
    "                print 'unknown clinical scale'\n",
    "\n",
    "            net_file = baseline_dir + 'API/data/MC_{}/fold{}/ADNI_FF_test.prototxt'.format(mc,fid)\n",
    "            test_filename_hdf = baseline_dir + 'API/data/MC_{}/fold{}/{}/{}.h5'.format(mc,fid,cohort,exp_name)\n",
    "            test_filename_txt = baseline_dir + 'API/data/MC_{}/fold{}/{}_C688.txt'.format(mc,fid,cohort)\n",
    "            with open(test_filename_txt, 'w') as f:\n",
    "                    f.write(test_filename_hdf + '\\n')  \n",
    "\n",
    "            sub.call([\"cp\", baseline_dir + 'API/data/MC_{}/fold{}/{}_C688.txt'.format(mc,fid,cohort), baseline_dir + \n",
    "                      'API/data/MC_{}/fold{}/test_C688.txt'.format(mc,fid)])\n",
    "            #data_path = '/projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/CV_Exp4_ADNI1_ADAS13_NN_valid.h5'\n",
    "            #adas_scores = load_data(data_path, 'Fold_{}_y'.format(fid),'no_preproc')\n",
    "\n",
    "            if Clinical_Scale in ['ADAS13', 'MMSE']:                \n",
    "                multi_task = False\n",
    "                cs_list = ['opt']\n",
    "                iter_euLoss = []\n",
    "                iter_r = []        \n",
    "                iter_pred_scores = []\n",
    "                for snap_iter in np.arange(snap_start,niter+1,snap_interval):\n",
    "                    model_file = baseline_dir + 'API/data/MC_{}/fold{}/train_snaps/{}_{}_{}_iter_{}.caffemodel'.format(mc,fid,exp_name,hype,modality,snap_iter)        \n",
    "                    results = extract_features(net_file, model_file, data_path, input_nodes, batch_size, encoding_layer, weight_layers,multi_task)\n",
    "                    encodings = np.squeeze(results['X_out'])            \n",
    "                    iter_pred_scores.append(np.squeeze(results['X_out']))            \n",
    "                    iter_euLoss.append(0.5*mse(encodings,act_scores))  #This is to be consistent with the caffe loss funtion\n",
    "                    iter_r.append(stats.pearsonr(encodings,act_scores)[0])\n",
    "\n",
    "                config_idx = '{}_{}'.format(hype,fid)\n",
    "                fold_euLoss[config_idx] = np.array(iter_euLoss)\n",
    "                fold_r[config_idx] = np.array(iter_r)\n",
    "                fold_act_scores[fid] = act_scores\n",
    "                fold_pred_scores[config_idx] = np.array(iter_pred_scores)        \n",
    "\n",
    "            elif Clinical_Scale == 'BOTH':\n",
    "                multi_task = True\n",
    "                cs_list = ['adas','mmse']\n",
    "                iter_euLoss_adas13 = []\n",
    "                iter_r_adas13 = []        \n",
    "                iter_pred_scores_adas13 = []\n",
    "                iter_euLoss_mmse = []\n",
    "                iter_r_mmse = []        \n",
    "                iter_pred_scores_mmse = []\n",
    "\n",
    "                for snap_iter in np.arange(snap_start,niter+1,snap_interval):\n",
    "                    model_file = baseline_dir + 'API/data/MC_{}/fold{}/train_snaps/{}_{}_{}_iter_{}.caffemodel'.format(mc,fid,exp_name,hype,modality,snap_iter)        \n",
    "                    results = extract_features(net_file, model_file, data_path, input_nodes, batch_size, encoding_layer, weight_layers,multi_task)\n",
    "                    encodings = results['X_out']   \n",
    "                    encodings_adas13 = np.squeeze(encodings['adas13'])\n",
    "                    encodings_mmse = np.squeeze(encodings['mmse'])\n",
    "                    iter_pred_scores_adas13.append(encodings_adas13)            \n",
    "                    iter_pred_scores_mmse.append(encodings_mmse)                 \n",
    "                    iter_euLoss_adas13.append(0.5*mse(encodings_adas13,act_scores_adas13))  #This is to be consistent with the caffe loss funtion\n",
    "                    iter_euLoss_mmse.append(0.5*mse(encodings_mmse,act_scores_mmse))  #This is to be consistent with the caffe loss funtion\n",
    "                    iter_r_adas13.append(stats.pearsonr(encodings_adas13,act_scores_adas13)[0])                                \n",
    "                    iter_r_mmse.append(stats.pearsonr(encodings_mmse,act_scores_mmse)[0])\n",
    "\n",
    "                config_idx = '{}_{}'.format(hype,fid)\n",
    "                fold_euLoss_adas13[config_idx] = np.array(iter_euLoss_adas13)\n",
    "                fold_r_adas13[config_idx] = np.array(iter_r_adas13)\n",
    "                fold_act_scores_adas13[fid] = act_scores_adas13\n",
    "                fold_pred_scores_adas13[config_idx] = np.array(iter_pred_scores_adas13)        \n",
    "                fold_euLoss_mmse[config_idx] = np.array(iter_euLoss_mmse)\n",
    "                fold_r_mmse[config_idx] = np.array(iter_r_mmse)\n",
    "                fold_act_scores_mmse[fid] = act_scores_mmse\n",
    "                fold_pred_scores_mmse[config_idx] = np.array(iter_pred_scores_mmse)        \n",
    "\n",
    "    \n",
    "    if Clinical_Scale in ['ADAS13', 'MMSE']:\n",
    "        fold_perf_dict = {'fold_r':fold_r,'fold_euLoss':fold_euLoss,'fold_act_scores':fold_act_scores,'fold_pred_scores':fold_pred_scores}\n",
    "    else: \n",
    "        fold_perf_dict = {'fold_r_adas13':fold_r_adas13,'fold_r_mmse':fold_r_mmse,'fold_euLoss_adas13':fold_euLoss_adas13,'fold_euLoss_mmse':fold_euLoss_mmse,\n",
    "                         'fold_act_scores_adas13':fold_act_scores_adas13,'fold_act_scores_mmse':fold_act_scores_mmse,\n",
    "                          'fold_pred_scores_adas13':fold_pred_scores_adas13,'fold_pred_scores_mmse':fold_pred_scores_mmse}\n",
    "        \n",
    "    opt_metric = 'euLoss' #euLoss or corr or both\n",
    "    #task_weights = {'ADAS':1,'MMSE':0} \n",
    "    save_multitask_results = False\n",
    "    CV_model_dir = '/projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/output/'  \n",
    "    save_path = '{}{}_{}_NN_{}'.format(CV_model_dir,exp_name,mc,modality)\n",
    "    \n",
    "    # Create dictionaries of perfromance based on differnt task weights \n",
    "    for key, task_weights in {'adas':{'ADAS':1,'MMSE':0},'mmse':{'ADAS':0,'MMSE':1},'both':{'ADAS':1,'MMSE':1}}.items():\n",
    "        print 'Weights Tuned for: {}'.format(key)                              \n",
    "        results = compute_MC_results(fold_perf_dict, multi_task, opt_metric, task_weights, save_multitask_results, save_path)  \n",
    "\n",
    "        # populate the perf dictionary for 10 MC x 10 folds\n",
    "        model_choice = 'APANN'    \n",
    "        for f, fid in enumerate(fid_list): \n",
    "            if key in ['adas','mmse']:\n",
    "                r_valid = results['{}_r'.format(key)][f]\n",
    "                MSE_valid = results['{}_mse'.format(key)][f]\n",
    "                RMSE_valid = results['{}_rmse'.format(key)][f]\n",
    "\n",
    "                if key == 'adas':\n",
    "                    df_perf_dict_adas_tuned[idx] = {'MC':mc,'modality':modality,'model_choice':model_choice,'KF':fid,\n",
    "                                         'CV_MSE':MSE_valid,'CV_RMSE':RMSE_valid,'CV_r':r_valid,'CV_R2':0}\n",
    "                elif key == 'mmse':\n",
    "                    df_perf_dict_mmse_tuned[idx] = {'MC':mc,'modality':modality,'model_choice':model_choice,'KF':fid,\n",
    "                                         'CV_MSE':MSE_valid,'CV_RMSE':RMSE_valid,'CV_r':r_valid,'CV_R2':0}\n",
    "                else: \n",
    "                    print 'unknown key'\n",
    "\n",
    "            elif key == 'both':                    \n",
    "                for cs in cs_list:            \n",
    "                    r_valid = results['{}_r'.format(cs)][f]\n",
    "                    MSE_valid = results['{}_mse'.format(cs)][f]\n",
    "                    RMSE_valid = results['{}_rmse'.format(cs)][f]\n",
    "\n",
    "                    if cs == 'adas':\n",
    "                        df_perf_dict_adas[idx] = {'MC':mc,'modality':modality,'model_choice':model_choice,'KF':fid,\n",
    "                                         'CV_MSE':MSE_valid,'CV_RMSE':RMSE_valid,'CV_r':r_valid,'CV_R2':0}\n",
    "                    elif cs == 'mmse':\n",
    "                        df_perf_dict_mmse[idx] = {'MC':mc,'modality':modality,'model_choice':model_choice,'KF':fid,\n",
    "                                         'CV_MSE':MSE_valid,'CV_RMSE':RMSE_valid,'CV_r':r_valid,'CV_R2':0}                    \n",
    "                    else: \n",
    "                        print 'unknown key'\n",
    "\n",
    "\n",
    "            else: #single task dictionary\n",
    "                df_perf_dict_opt[idx] = {'MC':mc,'modality':modality,'model_choice':model_choice,'KF':fid,\n",
    "                                         'CV_MSE':MSE_valid,'CV_RMSE':RMSE_valid,'CV_r':r_valid,'CV_R2':0}\n",
    "\n",
    "            idx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving results at: /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/output/\n"
     ]
    }
   ],
   "source": [
    "#Save df style dictionaly for seaborn plots\n",
    "cohort = 'ADNI1'\n",
    "update = 1\n",
    "df_perf_dict_path = CV_model_dir + 'df_perf_dict_{}_{}_{}_ADAS13_up_{}.pkl'.format(exp_name, cohort,modality,update)                \n",
    "pickleIt(df_perf_dict_adas,df_perf_dict_path)\n",
    "df_perf_dict_path = CV_model_dir + 'df_perf_dict_{}_{}_{}_MMSE_up_{}.pkl'.format(exp_name, cohort,modality,update)  \n",
    "pickleIt(df_perf_dict_mmse,df_perf_dict_path)\n",
    "\n",
    "df_perf_dict_path = CV_model_dir + 'df_perf_dict_{}_{}_{}_ADAS13_tuned_up_{}.pkl'.format(exp_name,cohort,modality,update)                \n",
    "pickleIt(df_perf_dict_adas_tuned,df_perf_dict_path)\n",
    "df_perf_dict_path = CV_model_dir + 'df_perf_dict_{}_{}_{}_MMSE_tuned_up_{}.pkl'.format(exp_name, cohort,modality,update)  \n",
    "pickleIt(df_perf_dict_mmse_tuned,df_perf_dict_path)\n",
    "\n",
    "\n",
    "print 'saving results at: {}'.format(CV_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (20, 25)\n",
    "n_rows = n_folds\n",
    "n_cols = 2\n",
    "pid = 1\n",
    "plot_perf = False\n",
    "\n",
    "if multi_task:\n",
    "    euLosses = [fold_euLoss_adas13,fold_euLoss_mmse]\n",
    "    corrs = [fold_r_adas13,fold_r_mmse]\n",
    "else:\n",
    "    euLosses = [fold_euLoss]\n",
    "    corrs = [fold_r]\n",
    "    \n",
    "for fold_euLoss, fold_r in zip(euLosses, corrs):\n",
    "    for hype_fid in fold_euLoss.keys():\n",
    "        hype = int(hype_fid.split('_')[0][3])\n",
    "        fid = int(hype_fid.split('_')[1])    \n",
    "        \n",
    "        if plot_perf:\n",
    "            plt.figure(fid)\n",
    "            plt.subplot(n_rows,n_cols,1)\n",
    "            plt.plot(np.arange(snap_start,niter+1,snap_interval),fold_euLoss[hype_fid],label=hype_fid)\n",
    "            plt.title('Euclidean loss , fid: {}'.format(fid))\n",
    "            plt.legend()\n",
    "            plt.subplot(n_rows,n_cols,2)\n",
    "            plt.plot(np.arange(snap_start,niter+1,snap_interval),fold_r[hype_fid],label=hype_fid)\n",
    "            plt.title('correlation, fid: {}'.format(fid))\n",
    "            plt.legend(loc=2)\n",
    "\n",
    "print preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def compute_MC_results(fold_perf_dict, multi_task, opt_metric, task_weights, save_multitask_results, save_path):\n",
    "    fold_r_dict = {}\n",
    "    fold_euLoss_dict = {}\n",
    "    fold_act_scores_dict = {}\n",
    "    fold_pred_scores_dict = {}\n",
    "\n",
    "    if multi_task:\n",
    "        fold_r_dict['ADAS'] = fold_perf_dict['fold_r_adas13']\n",
    "        fold_r_dict['MMSE'] = fold_perf_dict['fold_r_mmse']\n",
    "        fold_euLoss_dict['ADAS'] = fold_perf_dict['fold_euLoss_adas13']\n",
    "        fold_euLoss_dict['MMSE'] = fold_perf_dict['fold_euLoss_mmse']\n",
    "        fold_act_scores_dict['ADAS'] = fold_perf_dict['fold_act_scores_adas13']\n",
    "        fold_act_scores_dict['MMSE'] = fold_perf_dict['fold_act_scores_mmse']\n",
    "        fold_pred_scores_dict['ADAS'] = fold_perf_dict['fold_pred_scores_adas13']\n",
    "        fold_pred_scores_dict['MMSE'] = fold_perf_dict['fold_pred_scores_mmse']\n",
    "        \n",
    "        NN_results = computePerfMetrics(fold_r_dict, fold_euLoss_dict, fold_act_scores_dict, fold_pred_scores_dict, opt_metric, hype_configs, \n",
    "                                        Clinical_Scale,task_weights)\n",
    "        adas_r = NN_results['opt_ADAS']['CV_r'].values()\n",
    "        mmse_r = NN_results['opt_MMSE']['CV_r'].values()\n",
    "        adas_mse = NN_results['opt_ADAS']['CV_MSE'].values()\n",
    "        mmse_mse = NN_results['opt_MMSE']['CV_MSE'].values()\n",
    "        adas_rmse = NN_results['opt_ADAS']['CV_RMSE'].values()\n",
    "        mmse_rmse = NN_results['opt_MMSE']['CV_RMSE'].values()\n",
    "        opt_hyp = NN_results['opt_hype']\n",
    "        opt_snap = NN_results['opt_snap']\n",
    "        predicted_CV_scores = NN_results['opt_ADAS']['predicted_CV_scores']\n",
    "        actual_CV_scores = NN_results['opt_ADAS']['actual_CV_scores']\n",
    "        \n",
    "        print 'ADAS corr: {}'.format(adas_r)\n",
    "        print 'ADAS mse: {}'.format(adas_mse)\n",
    "        print 'ADAS means: {}, {}'.format(np.mean(adas_r),np.mean(adas_mse))\n",
    "        print ''\n",
    "        print 'MMSE corr: {}'.format(mmse_r)\n",
    "        print 'MMSE mse: {}'.format(mmse_mse)\n",
    "        print 'MMSE means: {}, {}'.format(np.mean(mmse_r),np.mean(mmse_mse))\n",
    "        print ''\n",
    "        print 'opt_hyp: {}'.format(opt_hyp)\n",
    "        print ''\n",
    "        print 'opt_snap: {}'.format(opt_snap)\n",
    "        \n",
    "        return {'adas_r':adas_r, 'adas_mse':adas_mse, 'adas_rmse':adas_rmse, 'mmse_r':mmse_r, 'mmse_mse':mmse_mse, 'mmse_rmse':mmse_rmse,\n",
    "               'predicted_CV_scores':predicted_CV_scores,'actual_CV_scores':actual_CV_scores}\n",
    "\n",
    "    else:    \n",
    "        \n",
    "        NN_results = computeSingleTaskPerfMetrics(fold_perf_dict, opt_metric, hype_configs)\n",
    "        opt_r = NN_results['opt_r'].values()        \n",
    "        opt_mse = NN_results['opt_mse'].values()        \n",
    "        opt_rmse = NN_results['opt_rmse'].values()        \n",
    "        opt_hyp = NN_results['opt_hype']\n",
    "        opt_snap = NN_results['opt_snap']\n",
    "        predicted_CV_scores = NN_results['predicted_CV_scores']\n",
    "        actual_CV_scores = NN_results['actual_CV_scores']\n",
    "        print 'opt corr: {}'.format(opt_r)\n",
    "        print 'opt mse: {}'.format(opt_mse)\n",
    "        print 'means: {}, {}'.format(np.mean(opt_r),np.mean(opt_mse))\n",
    "        print ''\n",
    "        print 'opt_snap: {}'.format(opt_snap)\n",
    "        print ''\n",
    "    \n",
    "        return {'opt_r':opt_r, 'opt_mse':opt_mse, 'opt_rmse':opt_rmse,'predicted_CV_scores':predicted_CV_scores,'actual_CV_scores':actual_CV_scores}\n",
    "    \n",
    "\n",
    "\n",
    "    if save_multitask_results:\n",
    "        ts = time.time()\n",
    "        st = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d-%H-%M-%S')        \n",
    "        save_path = save_path + '_' + st + '.pkl' \n",
    "        print 'saving results at: {}'.format(save_path)\n",
    "        output = open(save_path, 'wb')\n",
    "        pickle.dump(NN_results, output)\n",
    "        output.close()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'predicted_CV_scores'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-6f668dc9c41d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predicted_CV_scores'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'actual_CV_scores'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpearsonr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'predicted_CV_scores'"
     ]
    }
   ],
   "source": [
    "a = np.squeeze(results['predicted_CV_scores'][7])\n",
    "b = np.squeeze(results['actual_CV_scores'][7])\n",
    "\n",
    "print a , b                               \n",
    "print stats.pearsonr(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute ptimal hyp_config for each fold(based on inner_test)\n",
    "# if multi_task is set then compute hyp_config based on ADAS+MMSE perf (mse, r values)\n",
    "# if multi_task is set then ADAS and MMSE act_scores and pred_scores are wrapped in dictionaries \n",
    "# task_weights: dict of weights for each task --> only used in Clinical_Scale = BOTH\n",
    "# opt_metric = mse or corr\n",
    "def computePerfMetrics(fold_r, fold_euLoss, fold_act_scores, fold_pred_scores, opt_metric, hype_configs, Clinical_Scale,task_weights):\n",
    "    # First generate lists per fold with all hyp results\n",
    "    fid_hype_map = defaultdict(list)\n",
    "    fid_euLoss_perf= defaultdict(list)\n",
    "    fid_r_perf= defaultdict(list)\n",
    "    \n",
    "     # find optimal hyp_snp combination for each fold based on corr and euLoss\n",
    "    opt_hype = {}\n",
    "    opt_snap = {}\n",
    "\n",
    "    opt_r_adas = {}\n",
    "    opt_mse_adas = {}\n",
    "    opt_rmse_adas = {}\n",
    "    actual_scores_adas = defaultdict(list)\n",
    "    opt_pred_scores_adas = defaultdict(list)\n",
    "\n",
    "    opt_r_mmse = {}\n",
    "    opt_mse_mmse = {}\n",
    "    opt_rmse_mmse = {}\n",
    "    actual_scores_mmse = defaultdict(list)\n",
    "    opt_pred_scores_mmse = defaultdict(list)\n",
    "\n",
    "    print 'Clinical_Scale: {}'.format(Clinical_Scale)\n",
    "    if not Clinical_Scale == 'BOTH':  #Does not produce all the metrics yet..\n",
    "        print 'This function does not work for single clinical scale models. Use the code from the next cell'\n",
    "    \n",
    "    else:\n",
    "        fold_r_ADAS = fold_r['ADAS']\n",
    "        fold_r_MMSE = fold_r['MMSE']\n",
    "        fold_euLoss_ADAS = fold_euLoss['ADAS']\n",
    "        fold_euLoss_MMSE = fold_euLoss['MMSE']\n",
    "        fid_r_perf_ADAS = defaultdict(list)\n",
    "        fid_r_perf_MMSE = defaultdict(list)\n",
    "        fid_euLoss_perf_ADAS = defaultdict(list)\n",
    "        fid_euLoss_perf_MMSE = defaultdict(list)\n",
    "        for hype_fid in fold_euLoss_ADAS.keys():\n",
    "            hype = int(hype_fid.split('_')[0][3])\n",
    "            fid = int(hype_fid.split('_')[1]) \n",
    "            \n",
    "            fid_r_perf_ADAS[fid].append(fold_r_ADAS[hype_fid])\n",
    "            fid_r_perf_MMSE[fid].append(fold_r_MMSE[hype_fid])\n",
    "            fid_euLoss_perf_ADAS[fid].append(fold_euLoss_ADAS[hype_fid])\n",
    "            fid_euLoss_perf_MMSE[fid].append(fold_euLoss_MMSE[hype_fid])\n",
    "            fid_hype_map[fid].append(hype)\n",
    "            \n",
    "            #Joint scores (weighted addition)\n",
    "            fid_r_perf[fid].append(task_weights['ADAS']*fold_r_ADAS[hype_fid] + task_weights['MMSE']*fold_r_MMSE[hype_fid])\n",
    "            fid_euLoss_perf[fid].append(task_weights['ADAS']*fold_euLoss_ADAS[hype_fid] + task_weights['MMSE']*fold_euLoss_MMSE[hype_fid])\n",
    "\n",
    "        fold_act_scores_adas = fold_act_scores['ADAS']\n",
    "        fold_act_scores_mmse = fold_act_scores['MMSE']\n",
    "        fold_pred_scores_adas = fold_pred_scores['ADAS']\n",
    "        fold_pred_scores_mmse = fold_pred_scores['MMSE']\n",
    "\n",
    "        for fid in fid_hype_map.keys():\n",
    "            r_perf_array_adas = np.array(fid_r_perf_ADAS[fid])\n",
    "            r_perf_array_mmse = np.array(fid_r_perf_MMSE[fid])\n",
    "            r_perf_array = np.array(fid_r_perf[fid])\n",
    "            euLoss_perf_array_adas = np.array(fid_euLoss_perf_ADAS[fid])\n",
    "            euLoss_perf_array_mmse = np.array(fid_euLoss_perf_MMSE[fid])\n",
    "            euLoss_perf_array = np.array(fid_euLoss_perf[fid])\n",
    "\n",
    "            if opt_metric == 'euLoss':\n",
    "                h,snp = np.unravel_index(euLoss_perf_array.argmin(), euLoss_perf_array.shape)\n",
    "            else:\n",
    "                h,snp = np.unravel_index(r_perf_array.argmax(), r_perf_array.shape)\n",
    "\n",
    "            opt_hype[fid] = hype_configs['hyp{}'.format(fid_hype_map[fid][h])]\n",
    "            opt_snap[fid] = snp\n",
    "\n",
    "            opt_r_adas[fid] = r_perf_array_adas[h,snp]\n",
    "            opt_mse_adas[fid] = 2*euLoss_perf_array_adas[h,snp] #Convert back to MSE\n",
    "            opt_rmse_adas[fid] = np.sqrt(2*euLoss_perf_array_adas[h,snp]) #RMSE\n",
    "            opt_r_mmse[fid] = r_perf_array_mmse[h,snp] \n",
    "            opt_mse_mmse[fid] = 2*euLoss_perf_array_mmse[h,snp] #Convert back to MSE\n",
    "            opt_rmse_mmse[fid] = np.sqrt(2*euLoss_perf_array_mmse[h,snp]) #RMSE\n",
    "\n",
    "            actual_scores_adas[fid].append(fold_act_scores_adas[fid])\n",
    "            opt_pred_scores_adas[fid].append(fold_pred_scores_adas['hyp{}_{}'.format(fid_hype_map[fid][h],fid)][snp])\n",
    "            actual_scores_mmse[fid].append(fold_act_scores_mmse[fid])\n",
    "            opt_pred_scores_mmse[fid].append(fold_pred_scores_mmse['hyp{}_{}'.format(fid_hype_map[fid][h],fid)][snp])\n",
    "\n",
    "        opt_ADAS = {'CV_r':opt_r_adas,'CV_MSE':opt_mse_adas,'CV_RMSE':opt_rmse_adas,'actual_CV_scores':actual_scores_adas,'predicted_CV_scores':opt_pred_scores_adas}\n",
    "        opt_MMSE = {'CV_r':opt_r_mmse,'CV_MSE':opt_mse_mmse,'CV_RMSE':opt_rmse_mmse,'actual_CV_scores':actual_scores_mmse,'predicted_CV_scores':opt_pred_scores_mmse}\n",
    "    \n",
    "    return {'opt_hype':opt_hype, 'opt_snap':opt_snap, 'opt_ADAS':opt_ADAS, 'opt_MMSE':opt_MMSE}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Find optimal config based on inner_test\n",
    "def computeSingleTaskPerfMetrics(fold_perf_dict,opt_metric,hype_configs):\n",
    "    corrs = fold_perf_dict['fold_r']\n",
    "    euLosses = fold_perf_dict['fold_euLoss']\n",
    "    act_scores = fold_perf_dict['fold_act_scores']\n",
    "    pred_scores = fold_perf_dict['fold_pred_scores']\n",
    "\n",
    "    \n",
    "    NN_multitask_results = {}\n",
    "   \n",
    "    snap_array = np.arange(snap_start,niter+1,snap_start)\n",
    "\n",
    "    fid_hype_map = defaultdict(list)\n",
    "    fid_euLoss_perf= defaultdict(list)\n",
    "    fid_r_perf= defaultdict(list)\n",
    "    for hype_fid in fold_euLoss.keys():\n",
    "        hype = int(hype_fid.split('_')[0][3])\n",
    "        fid = int(hype_fid.split('_')[1])\n",
    "        fid_euLoss_perf[fid].append(fold_euLoss[hype_fid])\n",
    "        fid_r_perf[fid].append(fold_r[hype_fid])\n",
    "        fid_hype_map[fid].append(hype)\n",
    "\n",
    "    opt_r = {}\n",
    "    opt_mse = {}\n",
    "    opt_rmse = {}\n",
    "    opt_hype = {}\n",
    "    opt_snap = {}\n",
    "    actual_scores = {}\n",
    "    opt_pred_scores = {}\n",
    "\n",
    "    for fid in fid_hype_map.keys():\n",
    "        r_perf_array = np.array(fid_r_perf[fid])\n",
    "        euLoss_perf_array = np.array(fid_euLoss_perf[fid])\n",
    "\n",
    "        # if want to find best hyp from mse values\n",
    "        if opt_metric == 'euLoss':\n",
    "            h,snp = np.unravel_index(euLoss_perf_array.argmin(), euLoss_perf_array.shape)\n",
    "        else:\n",
    "            h,snp = np.unravel_index(r_perf_array.argmax(), r_perf_array.shape)\n",
    "            \n",
    "        eu_loss = euLoss_perf_array[h,snp]\n",
    "        r = r_perf_array[h,snp]        \n",
    "        opt_r[fid] = r\n",
    "        opt_mse[fid] = 2*eu_loss\n",
    "        opt_rmse[fid] = np.sqrt(2*eu_loss)\n",
    "        #print 'fid:{}, best hype:{}, snap: {}, euLoss:{}'.format(fid, fid_hype_map[fid][h],snap_array[snp],eu_loss)        \n",
    "        opt_snap[fid] = snp\n",
    "        opt_hype[fid] = hype_configs['hyp{}'.format(fid_hype_map[fid][h])]\n",
    "        actual_scores[fid] = fold_act_scores[fid]\n",
    "        opt_pred_scores[fid] = fold_pred_scores['hyp{}_{}'.format(fid_hype_map[fid][h],fid)][snp]\n",
    "\n",
    "    #print 'CV Perf: r:{}, mse:{}'.format(np.mean(opt_r.values()), np.mean(opt_mse.values()))\n",
    "    #print opt_r\n",
    "    #print opt_mse\n",
    "    return {'opt_r':opt_r,'opt_mse':opt_mse,'opt_rmse':opt_rmse,'opt_hype':opt_hype,'opt_snap':opt_snap, 'actual_scores':actual_scores,'opt_pred_scores':opt_pred_scores}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "boxplots_dir = '/projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/montage_data/'\n",
    "\n",
    "model_file = 'Exp6_ADNI1_ADAS13_NN_HC_CT_2016-05-06-17-14-49.pkl'\n",
    "print model_file\n",
    "CV_data = pickle.load(open(boxplots_dir + model_file,'rb'))\n",
    "\n",
    "print 'old CV_r: {}'.format(CV_data['CV_r'])\n",
    "print ''\n",
    "print 'old mean(CV_r): {}, mean(MSE): {}'.format(np.mean(CV_data['CV_r']),np.mean(CV_data['CV_MSE']))\n",
    "print ''\n",
    "print 'old CV_mse: {}'.format(CV_data['CV_MSE'])\n",
    "#print CV_data['tid_snap_config_dict']\n",
    "\n",
    "NN_results = {}\n",
    "NN_results['CV_MSE'] = opt_mse\n",
    "NN_results['CV_r'] = opt_r\n",
    "NN_results['predicted_CV_scores'] = opt_pred_scores\n",
    "NN_results['actual_CV_scores'] = actual_scores\n",
    "NN_results['tid_snap_config_dict'] = opt_hype\n",
    "\n",
    "# #Combine second saved perf file with the previous one\n",
    "# model_file_2 = 'Exp11_ADNI2_ADAS13_NN_HC_CT_2016-05-06-00-03-01.pkl'\n",
    "# print model_file\n",
    "# NN_results = pickle.load(open(boxplots_dir + model_file_2,'rb'))\n",
    "\n",
    "idx_pairs = {4:0,5:1}\n",
    "updated_CV_data = update_fold_perf(boxplots_dir + model_file, NN_results, idx_pairs)\n",
    "print ''\n",
    "print 'new CV_r: {}'.format(updated_CV_data['CV_r'])\n",
    "print ''\n",
    "print 'new mean(CV_r): {}, mean(MSE): {}'.format(np.mean(updated_CV_data['CV_r']),np.mean(updated_CV_data['CV_MSE']))\n",
    "print ''\n",
    "print 'new CV_mse: {}'.format(updated_CV_data['CV_MSE'])\n",
    "\n",
    "save_updated_perf = False\n",
    "if save_updated_perf:\n",
    "    ts = time.time()\n",
    "    st = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d-%H-%M-%S')\n",
    "    montage_dir = '/projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/montage_data/'  \n",
    "    save_name = '{}Exp6_ADNI1_ADAS13_NN_{}_{}.pkl'.format(montage_dir,modality,st)\n",
    "    print 'saving results at: {}'.format(save_name)\n",
    "    output = open(save_name, 'wb')\n",
    "    pickle.dump(updated_CV_data, output)\n",
    "    output.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sqrt(5.64658243068)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Update fold performance for multitask\n",
    "print NN_results['opt_ADAS'].keys()\n",
    "\n",
    "boxplots_dir = '/projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/montage_data/'\n",
    "#model_file = 'Exp11_ADNI2_ADAS13_MMSE_NN_HC_CT_2016-06-04-13-15-43.pkl'\n",
    "model_file_soa = 'Exp11_ADNI2_ADAS13_MMSE_NN_HC_CT_2016-08-24-14-23-52.pkl'\n",
    "print 'current state of art: ' + model_file_soa\n",
    "CV_data = pickle.load(open(boxplots_dir + model_file_soa,'rb'))\n",
    "\n",
    "print 'ADAS'\n",
    "print CV_data['opt_ADAS']['CV_r']\n",
    "print CV_data['opt_ADAS']['CV_MSE']\n",
    "print np.mean(CV_data['opt_ADAS']['CV_r'].values())\n",
    "print np.mean(CV_data['opt_ADAS']['CV_MSE'].values())\n",
    "print 'MMSE'\n",
    "print CV_data['opt_MMSE']['CV_r']\n",
    "print CV_data['opt_MMSE']['CV_MSE']\n",
    "print np.mean(CV_data['opt_MMSE']['CV_r'].values())\n",
    "print np.mean(CV_data['opt_MMSE']['CV_MSE'].values())\n",
    "\n",
    "#load old file\n",
    "# model_file = 'Exp11_ADNI2_ADAS13_MMSE_NN_HC_CT_2016-08-24-14-02-48.pkl'\n",
    "# print 'updated fold result file: ' + model_file\n",
    "# NN_results = pickle.load(open(boxplots_dir + model_file,'rb'))\n",
    "\n",
    "idx_pairs = {1:1,3:3}\n",
    "CV_data = update_multifold_perf(boxplots_dir + model_file_soa, NN_results, idx_pairs)\n",
    "\n",
    "print \"\"\n",
    "print 'updated CV_data'\n",
    "print 'ADAS'\n",
    "print CV_data['opt_ADAS']['CV_r']\n",
    "print CV_data['opt_ADAS']['CV_MSE']\n",
    "print np.mean(CV_data['opt_ADAS']['CV_r'].values())\n",
    "print np.mean(CV_data['opt_ADAS']['CV_MSE'].values())\n",
    "print 'MMSE'\n",
    "print CV_data['opt_MMSE']['CV_r']\n",
    "print CV_data['opt_MMSE']['CV_MSE']\n",
    "print np.mean(CV_data['opt_MMSE']['CV_r'].values())\n",
    "print np.mean(CV_data['opt_MMSE']['CV_MSE'].values())\n",
    "\n",
    "save_name = '{}Exp11_ADNI2_ADAS13_MMSE_NN_{}_{}.pkl'.format(montage_dir,modality,st)\n",
    "#print 'saving results at: {}'.format(save_name)\n",
    "\n",
    "save_updated_perf = False\n",
    "if save_updated_perf:\n",
    "    ts = time.time()\n",
    "    st = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d-%H-%M-%S')\n",
    "    montage_dir = '/projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/montage_data/'  \n",
    "    save_name = '{}Exp11_ADNI2_ADAS13_MMSE_NN_{}_{}.pkl'.format(montage_dir,modality,st)\n",
    "    print 'saving results at: {}'.format(save_name)\n",
    "    output = open(save_name, 'wb')\n",
    "    pickle.dump(CV_data, output)\n",
    "    output.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "def update_fold_perf(saved_perf_file, new_perf_dict,idx_pairs): #idx_pairs={'old_idx':new_idx}\n",
    "    CV_data = pickle.load(open(saved_perf_file,'rb'))    \n",
    "    for key in CV_data.keys():        \n",
    "        for idx in idx_pairs.keys():            \n",
    "            CV_data[key][idx] = new_perf_dict[key][idx_pairs[idx]]\n",
    "\n",
    "    return CV_data\n",
    "\n",
    "def update_multifold_perf(saved_perf_file, new_perf_dict, idx_pairs):    \n",
    "    perf_metrics = ['CV_r', 'actual_CV_scores', 'CV_MSE', 'predicted_CV_scores']    \n",
    "    CV_data = pickle.load(open(saved_perf_file,'rb'))    \n",
    "    for key in CV_data.keys():\n",
    "        if key == 'opt_hype':\n",
    "            for idx_key,idx_val in idx_pairs.iteritems():\n",
    "                CV_data[key][idx_key] = new_perf_dict[key][idx_val]\n",
    "                \n",
    "        else:\n",
    "            for pm in perf_metrics:\n",
    "                for idx_key,idx_val in idx_pairs.iteritems():\n",
    "                    CV_data[key][pm][idx_key] = new_perf_dict[key][pm][idx_val]\n",
    "    \n",
    "    return CV_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boxplots_dir = '/projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/montage_data/'\n",
    "model_files = ['Exp11_ADNI2_ADAS13_MMSE_NN_HC_CT_2016-06-04-13-15-43.pkl',             \n",
    "             'Exp11_ADNI2_ADAS13_MMSE_NN_HC_CT_2016-05-23-07-31-29.pkl']\n",
    "\n",
    "#'Exp11_ADNI2_ADAS13_MMSE_NN_HC_CT_2016-06-03-19-29-16_Fold9_10.pkl'\n",
    "\n",
    "Clinical_Scale = 'ADAS'\n",
    "perf_array = []\n",
    "for mf in model_files:\n",
    "    CV_data = pickle.load(open(boxplots_dir + mf,'rb'))['opt_{}'.format(Clinical_Scale)]        \n",
    "    perf_array.append(CV_data['CV_r'].values())\n",
    "\n",
    "print (np.max(np.array(perf_array),axis=0))\n",
    "print np.mean(np.max(np.array(perf_array),axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "#print 'modality: {} mse: {}, r: {}'.format(modality, np.mean(2*np.array(fold_euLoss)[:,-1]),np.mean(np.array(fold_r)[:,-1]))\n",
    "#CV_perf ={'fid_list': fid_hype_map.keys(), 'hype_configs':opt_hype,'fold_mse':opt_mse,'fold_r':opt_r}\n",
    "#pickleIt(CV_perf, baseline_dir + 'API/CV_perf/outer_test_{}.pkl'.format(modality))\n",
    "#print \"Saving opt perf for fids: {} with modality: {}\".format(fid_hype_map.keys(),modality)\n",
    "\n",
    "\n",
    "save_detailed_results = True\n",
    "multi_task = True\n",
    "\n",
    "if save_detailed_results:\n",
    "    # dictionaries for summarized results    \n",
    "    if not multi_task:\n",
    "        NN_results = {}\n",
    "        NN_results['CV_MSE'] = opt_mse\n",
    "        NN_results['CV_r'] = opt_r\n",
    "        NN_results['predicted_CV_scores'] = opt_pred_scores\n",
    "        NN_results['actual_CV_scores'] = actual_scores\n",
    "        NN_results['tid_snap_config_dict'] = opt_hype\n",
    "        print opt_r\n",
    "        print opt_mse\n",
    "        \n",
    "    else:\n",
    "        NN_results = NN_multitask_results\n",
    "        print 'ADAS13, opt_r: {}'.format(NN_multitask_results['ADAS13']['opt_r'])\n",
    "        print 'ADAS13, opt_mse {}: '.format(NN_multitask_results['ADAS13']['opt_mse'])\n",
    "        print 'MMSE, opt_r: {}'.format(NN_multitask_results['MMSE']['opt_r'])\n",
    "        print 'MMSE, opt_mse: {}'.format(NN_multitask_results['MMSE']['opt_mse'])\n",
    "        \n",
    "    ts = time.time()\n",
    "    st = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d-%H-%M-%S')\n",
    "    montage_dir = '/projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/montage_data/'  \n",
    "    save_name = '{}Exp6_ADNI1_BOTH_NN_{}_{}.pkl'.format(montage_dir,modality,st)\n",
    "    print 'saving results at: {}'.format(save_name)\n",
    "    output = open(save_name, 'wb')\n",
    "    pickle.dump(NN_results, output)\n",
    "    output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_APIdata(in_data_path,out_data_path,fid,modalities,preproc):\n",
    "    print in_data_path\n",
    "    #Input config file generation\n",
    "    for modality in modalities:\n",
    "        in_data = load_data(in_data_path, 'Fold_{}_{}'.format(fid,modality), preproc)         \n",
    "\n",
    "        # HDF5 is pretty efficient, but can be further compressed.\n",
    "        comp_kwargs = {'compression': 'gzip', 'compression_opts': 1}\n",
    "        with h5py.File(out_data_path, 'a') as f:      \n",
    "            if modality == 'X_R_CT': #Fix the typo            \n",
    "                modality = 'X_CT'            \n",
    "\n",
    "            f.create_dataset('{}'.format(modality), data=in_data, **comp_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Generate API style data (options: scale / normalize)\n",
    "exp_name = 'Exp6'\n",
    "exp_name_out = 'Exp6_MC'\n",
    "cohorts = ['inner_train','inner_test','outer_test']\n",
    "modalities = ['X_L_HC','X_R_HC','X_R_CT','adas','mmse','dx']\n",
    "dataset = 'ADNI1'\n",
    "preproc = 'no_preproc' #binary labels\n",
    "baseline_dir = '/projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/'\n",
    "\n",
    "for mc in np.arange(1,3,1):\n",
    "    for fid in np.arange(1,11,1):\n",
    "        for cohort in cohorts:            \n",
    "            if cohort == 'inner_train':\n",
    "                in_data_path = baseline_dir + 'caffe_input/CV_{}_{}_NN_OuterFold_MC_{}_fold{}_train_InnerFold_1.h5'.format(exp_name,dataset,mc,fid)\n",
    "            elif cohort == 'inner_test':\n",
    "                in_data_path = baseline_dir + 'caffe_input/CV_{}_{}_NN_OuterFold_MC_{}_fold{}_valid_InnerFold_1.h5'.format(exp_name,dataset,mc,fid)\n",
    "            else:                \n",
    "                in_data_path = baseline_dir + 'CV_{}_{}_ADAS13_NN_valid_MC_{}.h5'.format(exp_name,dataset,mc)\n",
    "\n",
    "            out_data_path = baseline_dir + 'API/data/MC_{}/fold{}/{}/{}.h5'.format(mc,fid,cohort,exp_name_out)\n",
    "            generate_APIdata(in_data_path,out_data_path,fid,modalities,preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HC: fid[1:4] 8000; fid[5,6] 6000, fid[7,8,9]: 8000 fid 10: 6000\n",
    "CT: fid[1:5] 12000 fid[6:10] 6000\n",
    "\n",
    "#spawn net\n",
    "ADNI_FF_train_hyp1_CT.prototxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fid: 1\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_6/fold1/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_6/fold1/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 2\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_6/fold2/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_6/fold2/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 3\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_6/fold3/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_6/fold3/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 4\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_6/fold4/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_6/fold4/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 5\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_6/fold5/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_6/fold5/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 6\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_6/fold6/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_6/fold6/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 7\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_6/fold7/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_6/fold7/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 8\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_6/fold8/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_6/fold8/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 9\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_6/fold9/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_6/fold9/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 10\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_6/fold10/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_6/fold10/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 1\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_7/fold1/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_7/fold1/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 2\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_7/fold2/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_7/fold2/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 3\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_7/fold3/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_7/fold3/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 4\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_7/fold4/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_7/fold4/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 5\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_7/fold5/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_7/fold5/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 6\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_7/fold6/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_7/fold6/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 7\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_7/fold7/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_7/fold7/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 8\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_7/fold8/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_7/fold8/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 9\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_7/fold9/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_7/fold9/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 10\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_7/fold10/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_7/fold10/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 1\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_8/fold1/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_8/fold1/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 2\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_8/fold2/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_8/fold2/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 3\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_8/fold3/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_8/fold3/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 4\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_8/fold4/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_8/fold4/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 5\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_8/fold5/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_8/fold5/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 6\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_8/fold6/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_8/fold6/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 7\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_8/fold7/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_8/fold7/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 8\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_8/fold8/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_8/fold8/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 9\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_8/fold9/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_8/fold9/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 10\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_8/fold10/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_8/fold10/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 1\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_9/fold1/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_9/fold1/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 2\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_9/fold2/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_9/fold2/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 3\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_9/fold3/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_9/fold3/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 4\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_9/fold4/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_9/fold4/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 5\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_9/fold5/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_9/fold5/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 6\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_9/fold6/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_9/fold6/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 7\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_9/fold7/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_9/fold7/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 8\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_9/fold8/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_9/fold8/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 9\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_9/fold9/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_9/fold9/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 10\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_9/fold10/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_9/fold10/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 1\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_10/fold1/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_10/fold1/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 2\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_10/fold2/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_10/fold2/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 3\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_10/fold3/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_10/fold3/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 4\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_10/fold4/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_10/fold4/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 5\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_10/fold5/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_10/fold5/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 6\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_10/fold6/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_10/fold6/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 7\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_10/fold7/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_10/fold7/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 8\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_10/fold8/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_10/fold8/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 9\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_10/fold9/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_10/fold9/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 10\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_10/fold10/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_10/fold10/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n"
     ]
    }
   ],
   "source": [
    "# Net surgery AE --> FF pretrained weights\n",
    "#Review new FF net params\n",
    "cohort = 'ADNI2'\n",
    "modality = 'HC_CT'\n",
    "pretrain_snap_HC = 20000 #ADNI1: 5000\n",
    "pretrain_snap_CT = 20000 #ADNI1: 5000\n",
    "n_folds = 10\n",
    "baseline_dir = '/projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/' \n",
    "#Custom snaps per fold\n",
    "#HC_iter = [8000,8000,8000,8000,6000,6000,8000,8000,8000,6000]\n",
    "#CT_iter = [12000,12000,12000,12000,12000,6000,6000,6000,6000,6000]\n",
    "#mc=1\n",
    "hc_hyp = 'hyp1'\n",
    "ct_hyp = 'hyp1'\n",
    "pretrain_hyp = 'hyp2' #This is hyp generated using optimal combination of hc and ct hyps. Prototxt file is saved with this hyp extension\n",
    "\n",
    "exp_name = 'Exp11_MC'\n",
    "\n",
    "for mc in np.arange(6,11,1):\n",
    "    for fid in np.arange(1,n_folds+1,1):\n",
    "        print 'fid: {}'.format(fid)\n",
    "        #for AE_branch in ['CT','R_HC','L_HC']:\n",
    "        for AE_branch in ['CT','HC']:\n",
    "            print 'AE_branch: {}'.format(AE_branch)\n",
    "\n",
    "            if AE_branch == 'L_HC':\n",
    "                params_FF = ['L_ff1', 'L_ff2']            \n",
    "                AE_iter = 12000\n",
    "            elif AE_branch == 'R_HC':\n",
    "                params_FF = ['R_ff1', 'R_ff2']            \n",
    "                AE_iter = 12000\n",
    "            elif AE_branch == 'HC':\n",
    "                params_FF = ['L_ff1','R_ff1']\n",
    "                AE_iter = pretrain_snap_HC\n",
    "                hyp = hc_hyp\n",
    "            elif AE_branch == 'CT':\n",
    "                #params_FF = ['ff1', 'ff2']\n",
    "                params_FF = ['ff1']\n",
    "                AE_iter = pretrain_snap_CT\n",
    "                hyp = ct_hyp\n",
    "                #fid for pretain is 1 because it's same definition for all the folds.\n",
    "                #Only use this during 1 of the modalities to avoid overwritting\n",
    "                print 'Spawning new net'\n",
    "                pretrain_net = caffe.Net(baseline_dir + 'API/data/MC_{}/fold{}/ADNI_FF_train_{}_{}.prototxt'.format(mc,fid,pretrain_hyp,modality), caffe.TRAIN)\n",
    "            else:\n",
    "                print 'Wrong AE branch'\n",
    "\n",
    "            # conv_params = {name: (weights, biases)}\n",
    "            conv_params = {pr: (pretrain_net.params[pr][0].data, pretrain_net.params[pr][1].data) for pr in params_FF}\n",
    "\n",
    "            for conv in params_FF:\n",
    "                print 'target {} weights are {} dimensional and biases are {} dimensional'.format(conv, conv_params[conv][0].shape, conv_params[conv][1].shape)\n",
    "\n",
    "            # Review AE net params \n",
    "            #fid for pretain is 1 because it's same definition for all the folds.\n",
    "            net_file = baseline_dir + 'API/data/MC_{}/fold{}/ADNI_FF_train_{}_{}.prototxt'.format(mc,fid,hyp,AE_branch)\n",
    "            #model_file = baseline_dir + 'API/data/fold{}/train_snaps/AE_snaps/AE_{}_iter_{}.caffemodel'.format(fid,AE_branch,AE_iter) \n",
    "            model_file = baseline_dir + 'API/data/MC_{}/fold{}/train_snaps/{}_{}_{}_iter_{}.caffemodel'.format(mc,fid,exp_name,hyp,AE_branch,AE_iter) \n",
    "\n",
    "            AE_net = caffe.Net(net_file, model_file, caffe.TEST)\n",
    "            #params_AE = ['encoder1', 'code']\n",
    "            params_AE = params_FF #if you are using pretrained NN\n",
    "\n",
    "            # fc_params = {name: (weights, biases)}\n",
    "            fc_params = {pr: (AE_net.params[pr][0].data, AE_net.params[pr][1].data) for pr in params_AE}\n",
    "\n",
    "            for fc in params_AE:\n",
    "                print 'pretrained {} weights are {} dimensional and biases are {} dimensional'.format(fc, fc_params[fc][0].shape, fc_params[fc][1].shape)\n",
    "\n",
    "            #transplant net parameters\n",
    "            for pr, pr_conv in zip(params_AE, params_FF):\n",
    "                conv_params[pr_conv][0].flat = fc_params[pr][0].flat  # flat unrolls the arrays\n",
    "                conv_params[pr_conv][1][...] = fc_params[pr][1]\n",
    "\n",
    "            save_net = True\n",
    "            if save_net:\n",
    "                net_name = 'API/data/MC_{}/fold{}/pretrained_models/{}_ff_{}_{}_HC_snap_{}_CT_snap_{}_Sup_Concat.caffemodel'\n",
    "                save_path = baseline_dir + net_name.format(mc,fid,cohort,pretrain_hyp,modality,pretrain_snap_HC,pretrain_snap_CT)\n",
    "                print \"Saving net to \" + save_path\n",
    "                pretrain_net.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "CT_data = pickle.load(open('/projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/montage_data/Exp4_ADNI1_ADAS13_NN_CT_2016-03-01-11-18-48.pkl','rb'))\n",
    "CT_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = fold_pred_scores['hyp1_1'][5] #CT_data['predicted_CV_scores'][1]\n",
    "act = fold_act_scores[1] #CT_data['actual_CV_scores'][1]\n",
    "print act\n",
    "#print CT_data['tid_snap_config_dict']\n",
    "print 'Euclidean loss: {}'.format(0.5*mse(pred,act))\n",
    "print stats.pearsonr(pred,act)\n",
    "plt.scatter(pred,act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fold_pred_scores['hyp1_1'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fid = 1\n",
    "exp_name = 'Exp6'\n",
    "preproc = 'no_preproc'\n",
    "train_filename_hdf = baseline_dir + 'API/data/fold{}/inner_train/{}_{}.h5'.format(fid,exp_name,preproc)\n",
    "inner_test_filename_hdf = baseline_dir + 'API/data/fold{}/inner_test/{}_{}.h5'.format(fid,exp_name,preproc)\n",
    "outer_test_filename_hdf = baseline_dir + 'API/data/fold{}/outer_test/{}_{}.h5'.format(fid,exp_name,preproc)\n",
    "train_data = load_data(train_filename_hdf, 'X_R_HC', preproc)\n",
    "inner_test_data = load_data(inner_test_filename_hdf, 'X_R_HC', preproc)\n",
    "outer_test_data = load_data(outer_test_filename_hdf, 'X_R_HC', preproc)\n",
    "train_y = load_data(train_filename_hdf, 'y', preproc)\n",
    "inner_test_y = load_data(inner_test_filename_hdf, 'y', preproc)\n",
    "outer_test_y = load_data(outer_test_filename_hdf, 'y', preproc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print train_data.shape, inner_test_data.shape, outer_test_data.shape\n",
    "print np.mean(np.sum(train_data,axis=1)), np.mean(np.sum(inner_test_data,axis=1)), np.mean(np.sum(outer_test_data,axis=1))\n",
    "print np.mean(train_y), np.mean(inner_test_y), np.mean(outer_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(17358, 16086) (4340, 16086) (71, 16086)\n",
    "3377.85793294 3403.70506912 3427.98591549\n",
    "15.4938933057 15.7380184332 15.7605633803"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CV_data['opt_ADAS']['CV_r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.995929862284 0.981941759176 0.727493333851\n"
     ]
    }
   ],
   "source": [
    "Wxh = 0.5\n",
    "Whh = -1.0\n",
    "hb = -1.0\n",
    "x0 = 9\n",
    "x1 = 4\n",
    "x2 = -2\n",
    "\n",
    "h0 = 1/(1+exp(-Wxh*x0+hb))\n",
    "h1 = 1/(1+exp(h0*Whh - Wxh*x1 + hb))\n",
    "h2 = 1/(1+exp(h1*Whh - Wxh*x2 + hb))\n",
    "\n",
    "print h0,h1,h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
