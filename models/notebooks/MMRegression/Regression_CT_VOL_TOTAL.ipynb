{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import h5py as h5\n",
    "from sklearn.externals import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.cross_validation import KFold\n",
    "import pickle\n",
    "\n",
    "# Useful plotting thingies:\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = 12, 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#datasets\n",
    "data_path = '/projects/nikhil/ADNI_prediction/input_datasets/'\n",
    "\n",
    "#input data\n",
    "train_val_file = data_path + 'cli_ct_seg_fused_train_plus_val.pkl'\n",
    "test_file = '/projects/francisco/data/ADNI/cli_ct_seg_fused_test.pkl'\n",
    "\n",
    "#k-fold indices (from a saved file)\n",
    "kf_file = data_path + 'cli_ct_train_valid_KFold_idx.pkl'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Grab CV data with specific feature columes (independent vars) and specific clinical scale (dependent var)\n",
    "def load_CV_data(in_file, kf_file, clinical_scale, feature_cols):\n",
    "    data = pd.read_pickle(in_file)\n",
    "    all_regex = '|'.join(['^{}'.format(var) for var in feature_cols + clinical_scale])\n",
    "    ct_regex = '|'.join(['^{}'.format(var) for var in feature_cols])\n",
    "    data_trunc = data.filter(regex=all_regex)\n",
    "    data_trunc = data_trunc.dropna(how='any')\n",
    "    print ct_regex\n",
    "    print data_trunc.filter(regex=ct_regex).columns\n",
    "    X = np.sum(np.asarray(data_trunc.filter(regex=ct_regex), dtype=float),axis=1)\n",
    "    y = np.asarray(data_trunc[clinical_scale], dtype=float)\n",
    "    kf = pickle.load( open(kf_file, \"rb\" ) )\n",
    "    X_train = []\n",
    "    X_valid = []\n",
    "    y_train = []\n",
    "    y_valid = []\n",
    "    for train, valid in kf:        \n",
    "        X_train.append(X[train])\n",
    "        X_valid.append(X[valid])\n",
    "        y_train.append(y[train])\n",
    "        y_valid.append(y[valid])\n",
    "    \n",
    "    # Return train and validation lists comprising all folds\n",
    "    return {'X_train':X_train,'X_valid':X_valid,'y_train':y_train,'y_valid':y_valid}\n",
    "\n",
    "#Load test data\n",
    "def load_test_data(in_file, clinical_scale, feature_cols):\n",
    "\n",
    "    data = pd.read_pickle(in_file)\n",
    "    data_trunc = data[clinical_scale + feature_cols]\n",
    "    # remove nans\n",
    "    data_trunc = data_trunc[np.isfinite(data_trunc[clinical_scale])]\n",
    "    X = np.asarray(data_trunc[feature_cols],dtype=float)\n",
    "    y = np.asarray(data_trunc[clinical_scale],dtype=float)\n",
    "    return {'X':X, 'y':y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^CT\n",
      "Index([u'CT_REC.L', u'CT_OLF.L', u'CT_ORBsup.L', u'CT_ORBsupmed.L',\n",
      "       u'CT_ORBmid.L', u'CT_ORBinf.L', u'CT_SFGdor.L', u'CT_MFG.L',\n",
      "       u'CT_IFGoperc.L', u'CT_IFGtriang.L', u'CT_SFGmed.L', u'CT_SMA.L',\n",
      "       u'CT_PCL.L', u'CT_PreCG.L', u'CT_ROL.L', u'CT_PoCG.L', u'CT_SPG.L',\n",
      "       u'CT_IPL.L', u'CT_SMG.L', u'CT_ANG.L', u'CT_PCUN.L', u'CT_SOG.L',\n",
      "       u'CT_MOG.L', u'CT_IOG.L', u'CT_CAL.L', u'CT_CUN.L', u'CT_LING.L',\n",
      "       u'CT_FFG.L', u'CT_HES.L', u'CT_STG.L', u'CT_MTG.L', u'CT_ITG.L',\n",
      "       u'CT_TPOsup.L', u'CT_TPOmid.L', u'CT_ACG.L', u'CT_DCG.L', u'CT_PCG.L',\n",
      "       u'CT_REC.R', u'CT_OLF.R', u'CT_ORBsup.R', u'CT_ORBsupmed.R',\n",
      "       u'CT_ORBmid.R', u'CT_ORBinf.R', u'CT_SFGdor.R', u'CT_MFG.R',\n",
      "       u'CT_IFGoperc.R', u'CT_IFGtriang.R', u'CT_SFGmed.R', u'CT_SMA.R',\n",
      "       u'CT_PCL.R', u'CT_PreCG.R', u'CT_ROL.R', u'CT_PoCG.R', u'CT_SPG.R',\n",
      "       u'CT_IPL.R', u'CT_SMG.R', u'CT_ANG.R', u'CT_PCUN.R', u'CT_SOG.R',\n",
      "       u'CT_MOG.R', u'CT_IOG.R', u'CT_CAL.R', u'CT_CUN.R', u'CT_LING.R',\n",
      "       u'CT_FFG.R', u'CT_HES.R', u'CT_STG.R', u'CT_MTG.R', u'CT_ITG.R',\n",
      "       u'CT_TPOsup.R', u'CT_TPOmid.R', u'CT_ACG.R', u'CT_DCG.R', u'CT_PCG.R'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "feature_cols = ['CT']\n",
    "clinical_scale = ['ADAS13']\n",
    "\n",
    "cv_data = load_CV_data(train_val_file,kf_file, clinical_scale, feature_cols)\n",
    "#test_data = load_test_data(test_file, feature_cols, clinical_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Cross-validation loop\n",
    "stats = []\n",
    "coefs = []\n",
    "\n",
    "for fold in range(len(cv_data['X_train'])):\n",
    "    X = cv_data['X_train'][fold].ravel()\n",
    "    y = cv_data['y_train'][fold].ravel()\n",
    "    X_v = cv_data['X_valid'][fold]\n",
    "    y_v = cv_data['y_valid'][fold]\n",
    "    slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(X,y)\n",
    "    \n",
    "    # validation:\n",
    "    y_hat_v = intercept + slope * X_v\n",
    "    y_hat = intercept + slope * X\n",
    "    mse = mean_squared_error(y_v, y_hat_v)\n",
    "    R2 = r2_score(y_v, y_hat_v)\n",
    "    r = scipy.stats.pearsonr(y_v.ravel(), y_hat_v)\n",
    "    stats.append((R2, p_value, mse, r[0], r[1]))\n",
    "    coefs.append(slope)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean R^2: 0.0977452541679, STD of R^2: 0.0705056686766\n",
      "Mean p-val: 2.87099784776e-16, STD of p-val: 4.44459985743e-16\n",
      "Mean Coefs: -0.273940278558, STD of Coefs:0.0100645030749\n",
      "Mean MSE (val): 69.8623487999, STD of MSE (val): 12.0675500678\n",
      "Mean r (val): 0.356104458657, STD of r (val): 0.0876362572019\n"
     ]
    }
   ],
   "source": [
    "coefs = np.array(coefs)\n",
    "stats = np.array(stats)\n",
    "print 'Mean R^2: {}, STD of R^2: {}'.format(np.mean(stats[:,0]), np.std(stats[:,0]))\n",
    "print 'Mean p-val: {}, STD of p-val: {}'.format(np.mean(stats[:,1]), np.std(stats[:,1]))\n",
    "print 'Mean Coefs: {}, STD of Coefs:{}'.format(np.mean(coefs, axis=0), np.std(coefs, axis=0))\n",
    "print 'Mean MSE (val): {}, STD of MSE (val): {}'.format(np.mean(stats[:,2]), np.std(stats[:,2]))\n",
    "print 'Mean r (val): {}, STD of r (val): {}'.format(np.mean(stats[:,3]), np.std(stats[:,3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
