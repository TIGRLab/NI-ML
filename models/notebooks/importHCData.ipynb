{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import h5py as h5\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#HDF file generate from Jon's scripts comprising matched candidate labels and filenames.\n",
    "input_file = '/projects/nikhil/miccai/input_data_comb/data_t300_adcn.h5'\n",
    "\n",
    "# Run this script for each split, side combination:\n",
    "split = 'test'\n",
    "side = 'l'\n",
    "\n",
    "input_data = h5.File(input_file, 'r')\n",
    "input_HC_all = input_data['{}_{}_data'.format(side, split)][:]\n",
    "input_classes_all = input_data['{}_{}_classes'.format(side, split)][:]\n",
    "input_files_all = input_data['{}_{}_files'.format(side, split)][:]\n",
    "input_data.close()\n",
    "\n",
    "id_participant = re.compile(r\"\"\"\n",
    " (?<=ADNI_)      # Match the first string after ADNI_\n",
    " (.*?)          # Lazy quantifier so it only grabs the first immediate match.\n",
    " (?=_MR)        # End at the _MR\n",
    "\"\"\", re.VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8212\n",
      "(8212, 11427)\n"
     ]
    }
   ],
   "source": [
    "# If creating pairwise datasets (for classification tasks)\n",
    "# Pick the Dx group to ignore AD:0, CN:1, MCI:2 (-1 basically picks all 3 groups)\n",
    "Dx_excl = -1\n",
    "input_classes = input_classes_all[input_classes_all!=Dx_excl]\n",
    "input_files = input_files_all[input_classes_all!=Dx_excl]\n",
    "input_HC = input_HC_all[input_classes_all!=Dx_excl]\n",
    "\n",
    "print len(input_files)\n",
    "print input_HC.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary length: 110\n",
      "110\n"
     ]
    }
   ],
   "source": [
    "# Generate dictionary {subject_id:[candidate_labels]}\n",
    "import collections\n",
    "import scipy.stats as stats\n",
    "\n",
    "subject_idx=[]\n",
    "unique_subject_idx = []\n",
    "subject_vol_dict = collections.OrderedDict()\n",
    "subject_class_dict = collections.OrderedDict()\n",
    "\n",
    "#find volume indices for each unique subject\n",
    "seen = set([])\n",
    "for j, f in enumerate(input_files):\n",
    "    subject_id = re.search(id_participant, f).group(0)\n",
    "    subject_idx.append(subject_id)\n",
    "    if subject_id not in subject_vol_dict:\n",
    "        subject_vol_dict[subject_id]=[]\n",
    "        subject_class_dict[subject_id]=[]\n",
    "    \n",
    "    subject_vol_dict[subject_id].append(input_HC[j])\n",
    "    subject_class_dict[subject_id].append(input_classes[j])\n",
    "\n",
    "    if subject_id not in seen:\n",
    "        unique_subject_idx.append(subject_id)\n",
    "        seen.add(subject_id)\n",
    "    \n",
    "print \"Dictionary length: \" + str(len(subject_vol_dict))\n",
    "    \n",
    "print len(unique_subject_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Save Dictionaries\n",
    "\n",
    "sub_HC_vol_left_file = '/projects/nikhil/ADNI_prediction/input_datasets/HC/subject_HC_vol_dictionary_heldout_left.pkl'\n",
    "sub_HC_vol_right_file = '/projects/nikhil/ADNI_prediction/input_datasets/HC/subject_HC_vol_dictionary_heldout_right.pkl'\n",
    "\n",
    "import pickle\n",
    "f = open(sub_HC_vol_left_file, 'wb')\n",
    "pickle.dump(subject_vol_dict, f)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
