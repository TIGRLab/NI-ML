{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "import h5py\n",
    "import shutil\n",
    "import tempfile\n",
    "import sys\n",
    "import caffe\n",
    "import os\n",
    "import sys\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import pickle\n",
    "import subprocess as sub\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "import pickle\n",
    "import time\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "# Take care with the paths -defaults ones from protobuf are not correct. Need to change snapshot and train / test data paths \n",
    "\n",
    "caffe_root = '/home/nikhil/caffe/'  # this file should be run from {caffe_root}/examples (otherwise change this line)\n",
    "sys.path.insert(0, caffe_root + 'python')\n",
    "\n",
    "baseline_dir = '/projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/'\n",
    "os.chdir(baseline_dir)\n",
    "\n",
    "caffe.set_device(3)\n",
    "caffe.set_mode_gpu()\n",
    "\n",
    "#Useful resources:\n",
    "#http://stackoverflow.com/questions/33140000/how-to-feed-caffe-multi-label-data-in-hdf5-format\n",
    "#http://nbviewer.jupyter.org/github/BVLC/caffe/blob/master/examples/00-classification.ipynb\n",
    "#http://nbviewer.jupyter.org/github/BVLC/caffe/blob/master/examples/01-learning-lenet.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tables as tb\n",
    "from sklearn import preprocessing\n",
    "def load_data(data_path, input_node, preproc):\n",
    "    data = tb.open_file(data_path, 'r')\n",
    "    X_raw = data.get_node('/' + input_node)[:]\n",
    "    if preproc == 'scale':\n",
    "        X = preprocessing.scale(X_raw)\n",
    "    elif preproc == 'norm_max':\n",
    "        X = preprocessing.normalize(X_raw, norm='max')\n",
    "    elif preproc == 'norm_l2':\n",
    "        X = preprocessing.normalize(X_raw, norm='l2')\n",
    "    else:\n",
    "        X = X_raw\n",
    "    data.close()\n",
    "    return X\n",
    "\n",
    "# Some defs to load data and extract encodings from trained net\n",
    "import collections\n",
    "def extract_features(net_file, model_file, data_path, input_nodes, batch_size, encoding_layer, weight_layers, multi_task):\n",
    "    os.chdir(os.path.dirname(net_file))\n",
    "    net = caffe.Net(net_file, model_file, caffe.TEST)        \n",
    "    \n",
    "    #print net.blobs.items()[0]\n",
    "    #print net.blobs.items()[1]\n",
    "    \n",
    "    #Get weights    \n",
    "    layer_list = weight_layers\n",
    "    wt_dict = collections.OrderedDict()\n",
    "    for l, name in enumerate(net._layer_names):            \n",
    "        if name in layer_list:\n",
    "            wt_dict[name] = net.layers[l].blobs[0].data\n",
    "    \n",
    "    BATCH_SIZE = batch_size        \n",
    "    N = load_data(data_path, input_nodes[0],'no_preproc').shape[0]\n",
    "    iters = int(np.ceil(N / float(BATCH_SIZE)))\n",
    "\n",
    "    if not multi_task:\n",
    "        code_layer = net.blobs[encoding_layer]\n",
    "        out_shape = code_layer.data.shape    \n",
    "        X_out = np.zeros(shape=(N, out_shape[1]))        \n",
    "        #print 'X_out.shape: {}'.format(X_out.shape)\n",
    "        \n",
    "    else:\n",
    "        code_layer_adas13 = net.blobs[encoding_layer + '_ADAS13']\n",
    "        code_layer_mmse = net.blobs[encoding_layer + '_MMSE']\n",
    "        out_shape = code_layer_adas13.data.shape \n",
    "        X_out_adas13 = np.zeros(shape=(N, out_shape[1]))\n",
    "        X_out_mmse = np.zeros(shape=(N, out_shape[1]))\n",
    "        #print 'X_out.shape: {},{}'.format(X_out_adas13.shape,X_out_mmse.shape)\n",
    "    \n",
    "    X_list = []\n",
    "    data_layers = []\n",
    "    for i, input_node in enumerate(input_nodes):\n",
    "        X_list.append(load_data(data_path, input_node,'no_preproc'))\n",
    "        #print net.blobs[input_node].shape\n",
    "        \n",
    "        data_layers.append(net.blobs[input_node])    \n",
    "        #print 'X_list shape: {}'.format(X_list[i].shape)\n",
    "        #print 'data_layers shape: {}'.format(data_layers[i].data.shape)\n",
    "        data_layers[i].reshape(BATCH_SIZE, X_list[i].shape[1]) # TODO: only works for 2-D inputs\n",
    "        #print 'data_layers shape: {}'.format(data_layers[i].data.shape)\n",
    "    \n",
    "     \n",
    "    net.reshape()            \n",
    "    #print 'Extracting features from data...'\n",
    "    \n",
    "    for i in xrange(iters):\n",
    "        #print '.',\n",
    "        for m, X in enumerate(X_list):\n",
    "            X_b = X[i * BATCH_SIZE: (i+1) * BATCH_SIZE,:]\n",
    "            batch_sampx = X_b.shape[0]\n",
    "            # Pad last batch with zeros\n",
    "            if X_b.shape[0] < BATCH_SIZE:\n",
    "                #print 'Zero-padding last batch with {} rows'.format(BATCH_SIZE-X_b.shape[0])\n",
    "                X_b = np.vstack((X_b,np.zeros((BATCH_SIZE-X_b.shape[0],X_b.shape[1]))))                       \n",
    "            \n",
    "            data_layers[m].data[...] = X_b\n",
    "            \n",
    "        net.forward()\n",
    "        \n",
    "        if not multi_task:\n",
    "            X_out[i * BATCH_SIZE: min((i+1) * BATCH_SIZE, N)] = code_layer.data[0:batch_sampx,:].copy()\n",
    "        else:\n",
    "            X_out_adas13[i * BATCH_SIZE: min((i+1) * BATCH_SIZE, N)] = code_layer_adas13.data[0:batch_sampx,:].copy()\n",
    "            X_out_mmse[i * BATCH_SIZE: min((i+1) * BATCH_SIZE, N)] = code_layer_mmse.data[0:batch_sampx,:].copy()\n",
    "            X_out = {'adas13':X_out_adas13,'mmse':X_out_mmse}\n",
    "    return {'X_out':X_out, 'wt_dict':wt_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from caffe import layers as L\n",
    "from caffe import params as P\n",
    "\n",
    "def adninet_ff_HC(hdf5, batch_size, node_sizes, dr, lr, tr, Clinical_Scale):\n",
    "    n = caffe.NetSpec()\n",
    "    \n",
    "    #------- Input -----------------#\n",
    "    if Clinical_Scale == 'ADAS13':\n",
    "        n.X_L_HC,n.X_R_HC,n.adas  = L.HDF5Data(name='data',batch_size=batch_size, source=hdf5,ntop=3) #orig\n",
    "    elif Clinical_Scale == 'MMSE':\n",
    "        n.X_L_HC,n.X_R_HC,n.mmse  = L.HDF5Data(name='data',batch_size=batch_size, source=hdf5,ntop=3) #orig\n",
    "    elif Clinical_Scale == 'BOTH':\n",
    "        n.X_L_HC,n.X_R_HC,n.adas,n.mmse  = L.HDF5Data(name='data',batch_size=batch_size, source=hdf5,ntop=4) #orig\n",
    "    else:\n",
    "        print 'Unknow Clinical Scale: {}'.format(Clinical_Scale)\n",
    "        \n",
    "    #-------Hidden Layers-----------#\n",
    "    #ff layers Left HC\n",
    "    #n.L_ff1 = L.InnerProduct(n.X_L_HC, num_output=node_sizes['L_ff1'], param=dict(lr_mult=2), weight_filler=dict(type='gaussian',std=0.008))\n",
    "    n.L_ff1 = L.InnerProduct(n.X_L_HC, num_output=node_sizes['HC_L_ff'], param=dict(lr_mult=lr['HC']), weight_filler=dict(type='xavier'))\n",
    "    n.NLinEnL1 = L.ReLU(n.L_ff1, in_place=True)\n",
    "    n.dropL1 = L.Dropout(n.L_ff1, in_place=True,dropout_param=dict(dropout_ratio=dr['HC']))\n",
    "    \n",
    "    #ff layers Right HC\n",
    "    #n.R_ff1 = L.InnerProduct(n.X_R_HC, num_output=node_sizes['R_ff1'], param=dict(lr_mult=2), weight_filler=dict(type='gaussian',std=0.008))\n",
    "    n.R_ff1 = L.InnerProduct(n.X_R_HC, num_output=node_sizes['HC_R_ff'], param=dict(lr_mult=lr['HC']), weight_filler=dict(type='xavier'))\n",
    "    n.NLinEnR1 = L.ReLU(n.R_ff1, in_place=True)\n",
    "    n.dropR1 = L.Dropout(n.R_ff1, in_place=True,dropout_param=dict(dropout_ratio=dr['HC']))\n",
    "    \n",
    "    #ff layers Concat\n",
    "    n.concat = L.Concat(n.L_ff1,n.R_ff1, concat_param=dict(axis=1))\n",
    "    n.ff3 = L.InnerProduct(n.concat, num_output=node_sizes['COMB_ff'], param=dict(lr_mult=1), weight_filler=dict(type='xavier'))\n",
    "    n.NLinEn3 = L.ReLU(n.ff3, in_place=True)\n",
    "  \n",
    "    #Task layers    \n",
    "    if Clinical_Scale == 'BOTH': ## Split layers (multitask)\n",
    "        n.ff1_ADAS13 = L.InnerProduct(n.ff3, num_output=node_sizes['ADAS_ff'], param=dict(lr_mult=1), weight_filler=dict(type='xavier'))\n",
    "        n.NLin1ADAS13 = L.ReLU(n.ff1_ADAS13, in_place=True)\n",
    "        \n",
    "        n.ff1_MMSE = L.InnerProduct(n.ff3, num_output=node_sizes['MMSE_ff'], param=dict(lr_mult=1), weight_filler=dict(type='xavier'))\n",
    "        n.NLin1MMSE = L.ReLU(n.ff1_MMSE, in_place=True)\n",
    "    else:\n",
    "        #n.ff4 = L.InnerProduct(n.ff3, num_output=node_sizes['ff4'], param=dict(lr_mult=1), weight_filler=dict(type='gaussian',std=0.177))\n",
    "        n.ff4 = L.InnerProduct(n.ff3, num_output=node_sizes['COMB_ff'], param=dict(lr_mult=1), weight_filler=dict(type='xavier'))\n",
    "        n.NLinEn4 = L.ReLU(n.ff4, in_place=True)\n",
    "    \n",
    "    #--------Output--------------#\n",
    "    #n.output = L.InnerProduct(n.ff4, num_output=1, weight_filler=dict(type='gaussian',std=0.177))          \n",
    "    if Clinical_Scale == 'ADAS13':\n",
    "        n.output = L.InnerProduct(n.ff3, num_output=1, weight_filler=dict(type='xavier'))\n",
    "        n.loss = L.EuclideanLoss(n.output, n.adas)            \n",
    "    elif Clinical_Scale == 'MMSE':\n",
    "        n.output = L.InnerProduct(n.ff3, num_output=1, weight_filler=dict(type='xavier'))\n",
    "        n.loss = L.EuclideanLoss(n.output, n.mmse)\n",
    "    elif Clinical_Scale == 'BOTH':\n",
    "        n.output_ADAS13 = L.InnerProduct(n.ff1_ADAS13, num_output=1, weight_filler=dict(type='xavier'))\n",
    "        n.ADAS13_loss = L.EuclideanLoss(n.output_ADAS13, n.adas,loss_weight=tr['ADAS'])          \n",
    "        n.output_MMSE = L.InnerProduct(n.ff1_MMSE, num_output=1, weight_filler=dict(type='xavier'))\n",
    "        n.MMSE_loss = L.EuclideanLoss(n.output_MMSE, n.mmse,loss_weight=tr['MMSE'])  \n",
    "    else:\n",
    "        print 'Unknow Clinical Scale: {}'.format(Clinical_Scale)\n",
    "    \n",
    "    return n.to_proto()\n",
    "\n",
    "def adninet_ff_CT(hdf5, batch_size, node_sizes, dr, lr, tr, Clinical_Scale):\n",
    "    n = caffe.NetSpec()\n",
    "    \n",
    "    #------- Input -----------------#\n",
    "    if Clinical_Scale == 'ADAS13':\n",
    "        n.X_CT_SpecCluster_dyn,n.adas  = L.HDF5Data(name='data',batch_size=batch_size, source=hdf5,ntop=2) #orig\n",
    "    elif Clinical_Scale == 'MMSE':\n",
    "        n.X_CT_SpecCluster_dyn,n.mmse  = L.HDF5Data(name='data',batch_size=batch_size, source=hdf5,ntop=2) #orig\n",
    "    elif Clinical_Scale == 'BOTH':\n",
    "        n.X_CT_SpecCluster_dyn,n.adas,n.mmse  = L.HDF5Data(name='data',batch_size=batch_size, source=hdf5,ntop=3) #orig\n",
    "    else:\n",
    "        print 'Unknow Clinical Scale: {}'.format(Clinical_Scale)\n",
    "        \n",
    "    #-------Hidden Layers-----------#\n",
    "    n.ff1 = L.InnerProduct(n.X_CT_SpecCluster_dyn, num_output=node_sizes['CT_ff'], param=dict(lr_mult=lr['CT']), weight_filler=dict(type='xavier'))\n",
    "    n.NLinEnL1 = L.ReLU(n.ff1, in_place=True)\n",
    "    n.dropL1 = L.Dropout(n.ff1, in_place=True,dropout_param=dict(dropout_ratio=dr['CT'])) \n",
    "\n",
    "    #Task Layers\n",
    "    if Clinical_Scale == 'BOTH': ## Split layers (multitask)\n",
    "        n.ff1_ADAS13 = L.InnerProduct(n.ff1, num_output=node_sizes['ADAS_ff'], param=dict(lr_mult=1), weight_filler=dict(type='xavier'))\n",
    "        n.NLin1ADAS13 = L.ReLU(n.ff1_ADAS13, in_place=True)\n",
    "        \n",
    "        n.ff1_MMSE = L.InnerProduct(n.ff1, num_output=node_sizes['MMSE_ff'], param=dict(lr_mult=1), weight_filler=dict(type='xavier'))\n",
    "        n.NLin1MMSE = L.ReLU(n.ff1_MMSE, in_place=True)        \n",
    "    else:\n",
    "        n.ff2 = L.InnerProduct(n.ff1, num_output=node_sizes['CT_ff'], param=dict(lr_mult=lr['CT']), weight_filler=dict(type='xavier'))\n",
    "        n.NLinEnL2 = L.ReLU(n.ff2, in_place=True)\n",
    "        n.dropL2 = L.Dropout(n.ff2, in_place=True,dropout_param=dict(dropout_ratio=dr['CT']))\n",
    "    \n",
    "    #--------Output--------------#\n",
    "    #n.output = L.InnerProduct(n.ff4, num_output=1, weight_filler=dict(type='gaussian',std=0.177))          \n",
    "    if Clinical_Scale == 'ADAS13':\n",
    "        n.output = L.InnerProduct(n.ff2, num_output=1, weight_filler=dict(type='xavier'))\n",
    "        n.loss = L.EuclideanLoss(n.output, n.adas)            \n",
    "    elif Clinical_Scale == 'MMSE':\n",
    "        n.output = L.InnerProduct(n.ff2, num_output=1, weight_filler=dict(type='xavier'))\n",
    "        n.loss = L.EuclideanLoss(n.output, n.mmse)\n",
    "    elif Clinical_Scale == 'BOTH':\n",
    "        n.output_ADAS13 = L.InnerProduct(n.ff1_ADAS13, num_output=1, weight_filler=dict(type='xavier'))\n",
    "        n.ADAS13_loss = L.EuclideanLoss(n.output_ADAS13, n.adas,loss_weight=tr['ADAS'])          \n",
    "        n.output_MMSE = L.InnerProduct(n.ff1_MMSE, num_output=1, weight_filler=dict(type='xavier'))\n",
    "        n.MMSE_loss = L.EuclideanLoss(n.output_MMSE, n.mmse,loss_weight=tr['MMSE'])  \n",
    "    else:\n",
    "        print 'Unknow Clinical Scale: {}'.format(Clinical_Scale)\n",
    "    return n.to_proto()\n",
    "\n",
    "def adninet_ff_HC_CT_unified(hdf5, batch_size, node_sizes, dr, lr, tr, Clinical_Scale):\n",
    "    n = caffe.NetSpec()\n",
    "    \n",
    "    #------- Input -----------------#\n",
    "    if Clinical_Scale == 'ADAS13':\n",
    "        n.X_HC_CT,n.adas  = L.HDF5Data(name='data',batch_size=batch_size, source=hdf5,ntop=2) #orig\n",
    "    elif Clinical_Scale == 'MMSE':\n",
    "        n.X_HC_CT,n.mmse  = L.HDF5Data(name='data',batch_size=batch_size, source=hdf5,ntop=2) #orig\n",
    "    elif Clinical_Scale == 'DX':\n",
    "        n.X_HC_CT,n.dx_cat3  = L.HDF5Data(name='data',batch_size=batch_size, source=hdf5,ntop=2) #orig\n",
    "    elif Clinical_Scale == 'BOTH':\n",
    "        n.X_HC_CT,n.adas,n.mmse  = L.HDF5Data(name='data',batch_size=batch_size, source=hdf5,ntop=3) #orig\n",
    "    else:\n",
    "        print 'Unknow Clinical Scale: {}'.format(Clinical_Scale)\n",
    "        \n",
    "    #-------Hidden Layers-----------#\n",
    "    n.ff1 = L.InnerProduct(n.X_HC_CT, num_output=node_sizes['HC_CT_ff'], param=dict(lr_mult=lr['HC_CT']), weight_filler=dict(type='xavier'))\n",
    "    n.NLinEnL1 = L.ReLU(n.ff1, in_place=True)\n",
    "    n.dropL1 = L.Dropout(n.ff1, in_place=True,dropout_param=dict(dropout_ratio=dr['HC_CT'])) \n",
    "\n",
    "    #Task Layers\n",
    "    if Clinical_Scale == 'BOTH': ## Split layers (multitask)\n",
    "        n.ff1_ADAS13 = L.InnerProduct(n.ff1, num_output=node_sizes['ADAS_ff'], param=dict(lr_mult=1), weight_filler=dict(type='xavier'))\n",
    "        n.NLin1ADAS13 = L.ReLU(n.ff1_ADAS13, in_place=True)\n",
    "        \n",
    "        n.ff1_MMSE = L.InnerProduct(n.ff1, num_output=node_sizes['MMSE_ff'], param=dict(lr_mult=1), weight_filler=dict(type='xavier'))\n",
    "        n.NLin1MMSE = L.ReLU(n.ff1_MMSE, in_place=True)        \n",
    "    else:\n",
    "        n.ff2 = L.InnerProduct(n.ff1, num_output=node_sizes['HC_CT_ff'], param=dict(lr_mult=lr['HC_CT']), weight_filler=dict(type='xavier'))\n",
    "        n.NLinEnL2 = L.ReLU(n.ff2, in_place=True)\n",
    "        n.dropL2 = L.Dropout(n.ff2, in_place=True,dropout_param=dict(dropout_ratio=dr['HC_CT']))\n",
    "    \n",
    "    #--------Output--------------#\n",
    "    #n.output = L.InnerProduct(n.ff4, num_output=1, weight_filler=dict(type='gaussian',std=0.177))          \n",
    "    if Clinical_Scale == 'ADAS13':\n",
    "        n.output = L.InnerProduct(n.ff2, num_output=1, weight_filler=dict(type='xavier'))\n",
    "        n.loss = L.EuclideanLoss(n.output, n.adas)            \n",
    "    elif Clinical_Scale == 'MMSE':\n",
    "        n.output = L.InnerProduct(n.ff2, num_output=1, weight_filler=dict(type='xavier'))\n",
    "        n.loss = L.EuclideanLoss(n.output, n.mmse)\n",
    "    elif Clinical_Scale == 'DX':\n",
    "        n.output = L.InnerProduct(n.ff2, num_output=4, weight_filler=dict(type='xavier'))\n",
    "        n.loss = L.SoftmaxWithLoss(n.output, n.dx_cat3)\n",
    "    elif Clinical_Scale == 'BOTH':\n",
    "        n.output_ADAS13 = L.InnerProduct(n.ff1_ADAS13, num_output=1, weight_filler=dict(type='xavier'))\n",
    "        n.ADAS13_loss = L.EuclideanLoss(n.output_ADAS13, n.adas,loss_weight=tr['ADAS'])          \n",
    "        n.output_MMSE = L.InnerProduct(n.ff1_MMSE, num_output=1, weight_filler=dict(type='xavier'))\n",
    "        n.MMSE_loss = L.EuclideanLoss(n.output_MMSE, n.mmse,loss_weight=tr['MMSE'])  \n",
    "    else:\n",
    "        print 'Unknow Clinical Scale: {}'.format(Clinical_Scale)\n",
    "    return n.to_proto()\n",
    "\n",
    "def adninet_ff_HC_CT(hdf5, batch_size, node_sizes, dr, lr, tr, Clinical_Scale):\n",
    "    n = caffe.NetSpec()\n",
    "    \n",
    "    #------- Input -----------------#\n",
    "    if Clinical_Scale == 'ADAS13':\n",
    "        n.X_L_HC,n.X_R_HC,n.X_CT_SpecCluster_dyn,n.adas  = L.HDF5Data(name='data',batch_size=batch_size, source=hdf5,ntop=4) #orig\n",
    "    elif Clinical_Scale == 'MMSE':\n",
    "        n.X_L_HC,n.X_R_HC,n.X_CT_SpecCluster_dyn,n.mmse  = L.HDF5Data(name='data',batch_size=batch_size, source=hdf5,ntop=4) #orig\n",
    "    elif Clinical_Scale == 'BOTH':\n",
    "        n.X_L_HC,n.X_R_HC,n.X_CT_SpecCluster_dyn,n.adas,n.mmse  = L.HDF5Data(name='data',batch_size=batch_size, source=hdf5,ntop=5) #orig\n",
    "    elif Clinical_Scale == 'DX':\n",
    "        n.X_L_HC,n.X_R_HC,n.X_CT_SpecCluster_dyn,n.dx_cat3  = L.HDF5Data(name='data',batch_size=batch_size, source=hdf5,ntop=4) #orig\n",
    "    elif Clinical_Scale == 'ADAS13_DX':\n",
    "        n.X_L_HC,n.X_R_HC,n.X_CT_SpecCluster_dyn,n.adas, n.dx_cat3  = L.HDF5Data(name='data',batch_size=batch_size, source=hdf5,ntop=5) #orig\n",
    "    else:\n",
    "        print 'Unknow Clinical Scale: {}'.format(Clinical_Scale)\n",
    "        \n",
    "    #-------Hidden Layers-----------#\n",
    "    #ff layers Left HC\n",
    "    #n.L_ff1 = L.InnerProduct(n.X_L_HC, num_output=node_sizes['L_ff1'], param=dict(lr_mult=2), weight_filler=dict(type='gaussian',std=0.008))\n",
    "    n.L_ff1 = L.InnerProduct(n.X_L_HC, num_output=node_sizes['HC_L_ff'], param=dict(lr_mult=lr['HC']), weight_filler=dict(type='xavier'))\n",
    "    n.NLinEnL1 = L.ReLU(n.L_ff1, in_place=True)\n",
    "    n.dropL1 = L.Dropout(n.L_ff1, in_place=True,dropout_param=dict(dropout_ratio=dr['HC']))\n",
    "    #n.L_ff2 = L.InnerProduct(n.L_ff1, num_output=node_sizes['L_ff2'], param=dict(lr_mult=2), weight_filler=dict(type='gaussian',std=0.177))\n",
    "#     n.L_ff2 = L.InnerProduct(n.L_ff1, num_output=node_sizes['HC_L_ff'], param=dict(lr_mult=lr['HC']), weight_filler=dict(type='xavier'))\n",
    "#     n.NLinEnL2 = L.ReLU(n.L_ff2, in_place=True)\n",
    "#     n.dropL2 = L.Dropout(n.L_ff2, in_place=True,dropout_param=dict(dropout_ratio=dr['HC']))\n",
    "    \n",
    "    #ff layers Right HC\n",
    "    #n.R_ff1 = L.InnerProduct(n.X_R_HC, num_output=node_sizes['R_ff1'], param=dict(lr_mult=2), weight_filler=dict(type='gaussian',std=0.008))\n",
    "    n.R_ff1 = L.InnerProduct(n.X_R_HC, num_output=node_sizes['HC_R_ff'], param=dict(lr_mult=lr['HC']), weight_filler=dict(type='xavier'))\n",
    "    n.NLinEnR1 = L.ReLU(n.R_ff1, in_place=True)\n",
    "    n.dropR1 = L.Dropout(n.R_ff1, in_place=True,dropout_param=dict(dropout_ratio=dr['HC']))\n",
    "    #n.R_ff2 = L.InnerProduct(n.R_ff1, num_output=node_sizes['R_ff2'], param=dict(lr_mult=2), weight_filler=dict(type='gaussian',std=0.177))\n",
    "#     n.R_ff2 = L.InnerProduct(n.R_ff1, num_output=node_sizes['HC_R_ff'], param=dict(lr_mult=lr['HC']), weight_filler=dict(type='xavier'))\n",
    "#     n.NLinEnR2 = L.ReLU(n.R_ff2, in_place=True)\n",
    "#     n.dropR2 = L.Dropout(n.R_ff2, in_place=True,dropout_param=dict(dropout_ratio=dr['HC']))\n",
    "    \n",
    "    #ff layers CT\n",
    "    #n.ff1 = L.InnerProduct(n.X_CT, num_output=node_sizes['ff1'], param=dict(lr_mult=2), weight_filler=dict(type='gaussian',std=0.008))\n",
    "    n.ff1 = L.InnerProduct(n.X_CT_SpecCluster_dyn, num_output=node_sizes['CT_ff'], param=dict(lr_mult=lr['CT']), weight_filler=dict(type='xavier'))\n",
    "    n.NLinEn1 = L.ReLU(n.ff1, in_place=True)\n",
    "    n.drop1 = L.Dropout(n.ff1, in_place=True,dropout_param=dict(dropout_ratio=dr['CT']))\n",
    "    #n.ff2 = L.InnerProduct(n.ff1, num_output=node_sizes['ff2'], param=dict(lr_mult=), weight_filler=dict(type='gaussian',std=0.177))\n",
    "#     n.ff2 = L.InnerProduct(n.ff1, num_output=node_sizes['CT_ff'], param=dict(lr_mult=lr['CT']), weight_filler=dict(type='xavier'))\n",
    "#     n.NLinEn2 = L.ReLU(n.ff2, in_place=True)\n",
    "#     n.drop2 = L.Dropout(n.ff2, in_place=True,dropout_param=dict(dropout_ratio=dr['CT']))\n",
    "    \n",
    "     #ff layers Concat\n",
    "    n.concat = L.Concat(n.L_ff1,n.R_ff1,n.ff1, concat_param=dict(axis=1))\n",
    "    #n.concat = L.Concat(n.X_L_HC,n.X_R_HC,n.X_CT, concat_param=dict(axis=1))\n",
    "    \n",
    "    #n.ff3 = L.InnerProduct(n.concat, num_output=node_sizes['ff3'], param=dict(lr_mult=1), weight_filler=dict(type='gaussian',std=0.177))\n",
    "    n.ff3 = L.InnerProduct(n.concat, num_output=node_sizes['COMB_ff'], param=dict(lr_mult=lr['COMB']), weight_filler=dict(type='xavier'))\n",
    "    n.NLinEn3 = L.ReLU(n.ff3, in_place=True)\n",
    "    n.dropC1 = L.Dropout(n.ff3, in_place=True,dropout_param=dict(dropout_ratio=dr['COMB']))\n",
    "\n",
    "    #Task layers    \n",
    "    if Clinical_Scale == 'BOTH': ## Split layers (multitask)\n",
    "        #n.ff1_ADAS13, n.ff1_MMSE = L.Split(n.ff3,num_output=2) #This is done automatically by caffe! \n",
    "        n.ff1_ADAS13 = L.InnerProduct(n.ff3, num_output=node_sizes['ADAS_ff'], param=dict(lr_mult=1), weight_filler=dict(type='xavier'))\n",
    "        n.NLin1ADAS13 = L.ReLU(n.ff1_ADAS13, in_place=True)\n",
    "        #n.ff2_ADAS13 = L.InnerProduct(n.ff1_ADAS13, num_output=node_sizes['ADAS_ff'], param=dict(lr_mult=1), weight_filler=dict(type='xavier'))\n",
    "        #n.NLin2ADAS13 = L.ReLU(n.ff2_ADAS13, in_place=True)\n",
    "        \n",
    "        n.ff1_MMSE = L.InnerProduct(n.ff3, num_output=node_sizes['MMSE_ff'], param=dict(lr_mult=1), weight_filler=dict(type='xavier'))\n",
    "        n.NLin1MMSE = L.ReLU(n.ff1_MMSE, in_place=True)\n",
    "        #n.ff2_MMSE = L.InnerProduct(n.ff1_MMSE, num_output=node_sizes['MMSE_ff'], param=dict(lr_mult=1), weight_filler=dict(type='xavier'))\n",
    "        #n.NLin2MMSE = L.ReLU(n.ff2_MMSE, in_place=True)\n",
    "        \n",
    "    elif Clinical_Scale == 'ADAS13_DX':\n",
    "        n.ff1_ADAS13 = L.InnerProduct(n.ff3, num_output=node_sizes['ADAS_ff'], param=dict(lr_mult=1), weight_filler=dict(type='xavier'))\n",
    "        n.NLin1ADAS13 = L.ReLU(n.ff1_ADAS13, in_place=True)\n",
    "        n.ff1_DX = L.InnerProduct(n.ff3, num_output=node_sizes['DX_ff'], param=dict(lr_mult=1), weight_filler=dict(type='xavier'))\n",
    "        n.NLin1DX = L.ReLU(n.ff1_DX, in_place=True)\n",
    "        \n",
    "    else:\n",
    "        #n.ff4 = L.InnerProduct(n.ff3, num_output=node_sizes['ff4'], param=dict(lr_mult=1), weight_filler=dict(type='gaussian',std=0.177))\n",
    "        n.ff4 = L.InnerProduct(n.ff3, num_output=node_sizes['COMB_ff'], param=dict(lr_mult=1), weight_filler=dict(type='xavier'))\n",
    "        n.NLinEn4 = L.ReLU(n.ff4, in_place=True)\n",
    "    \n",
    "    #--------Output--------------#\n",
    "    #n.output = L.InnerProduct(n.ff4, num_output=1, weight_filler=dict(type='gaussian',std=0.177))          \n",
    "    if Clinical_Scale == 'ADAS13':\n",
    "        n.output = L.InnerProduct(n.ff4, num_output=1, weight_filler=dict(type='xavier'))\n",
    "        n.loss = L.EuclideanLoss(n.output, n.adas)            \n",
    "    elif Clinical_Scale == 'MMSE':\n",
    "        n.output = L.InnerProduct(n.ff4, num_output=1, weight_filler=dict(type='xavier'))\n",
    "        n.loss = L.EuclideanLoss(n.output, n.mmse)\n",
    "    elif Clinical_Scale == 'BOTH':\n",
    "        n.output_ADAS13 = L.InnerProduct(n.ff1_ADAS13, num_output=1, weight_filler=dict(type='xavier'))\n",
    "        n.ADAS13_loss = L.EuclideanLoss(n.output_ADAS13, n.adas,loss_weight=tr['ADAS'])          \n",
    "        n.output_MMSE = L.InnerProduct(n.ff1_MMSE, num_output=1, weight_filler=dict(type='xavier'))\n",
    "        n.MMSE_loss = L.EuclideanLoss(n.output_MMSE, n.mmse,loss_weight=tr['MMSE'])  \n",
    "    elif Clinical_Scale == 'DX':\n",
    "        n.output = L.InnerProduct(n.ff4, num_output=3, weight_filler=dict(type='xavier'))\n",
    "        n.loss = L.SoftmaxWithLoss(n.output, n.dx_cat3)\n",
    "        \n",
    "    elif Clinical_Scale == 'ADAS13_DX':\n",
    "        n.output_ADAS13 = L.InnerProduct(n.ff1_ADAS13, num_output=1, weight_filler=dict(type='xavier'))\n",
    "        n.ADAS13_loss = L.EuclideanLoss(n.output_ADAS13, n.adas,loss_weight=tr['ADAS'])          \n",
    "        n.output_DX = L.InnerProduct(n.ff1_DX, num_output=3, weight_filler=dict(type='xavier'))\n",
    "        n.DX_loss = L.SoftmaxWithLoss(n.output_DX, n.dx_cat3,loss_weight=tr['DX'])  \n",
    "    \n",
    "    else:\n",
    "        print 'Unknow Clinical Scale: {}'.format(Clinical_Scale)\n",
    "    \n",
    "    return n.to_proto()\n",
    "\n",
    "def adninet_ae(hdf5, batch_size,node_sizes,modality):\n",
    "    # logistic regression: data, matrix multiplication, and 2-class softmax loss\n",
    "    n = caffe.NetSpec()\n",
    "    \n",
    "    if modality == 'CT':\n",
    "        n.X_CT = L.HDF5Data(name='data',batch_size=batch_size, source=hdf5)\n",
    "        n.code = L.InnerProduct(n.X_CT, num_output=node_sizes['code'], weight_filler=dict(type='gaussian',std=.1, sparse=int(0.1*node_sizes['code'])))\n",
    "        n.NLinEn1 = L.ReLU(n.code, in_place=True)\n",
    "        n.dropC1 = L.Dropout(n.code, in_place=True,dropout_param=dict(dropout_ratio=dr['CT']))\n",
    "        \n",
    "    elif modality =='R_HC':\n",
    "        n.X_R_HC = L.HDF5Data(name='data',batch_size=batch_size, source=hdf5)\n",
    "        n.code = L.InnerProduct(n.X_R_HC, num_output=node_sizes['code'], weight_filler=dict(type='gaussian',std=.1, sparse=int(0.1*node_sizes['code'])))\n",
    "        n.NLinEn1 = L.ReLU(n.code, in_place=True)\n",
    "        n.drop1 = L.Dropout(n.code, in_place=True,dropout_param=dict(dropout_ratio=dr['HC']))\n",
    "        \n",
    "    elif modality =='L_HC':\n",
    "        n.X_L_HC = L.HDF5Data(name='data',batch_size=batch_size, source=hdf5)\n",
    "        n.code = L.InnerProduct(n.X_L_HC, num_output=node_sizes['code'], weight_filler=dict(type='gaussian',std=.1, sparse=int(0.1*node_sizes['code'])))       \n",
    "        n.NLinEn1 = L.ReLU(n.code, in_place=True)\n",
    "        n.drop1 = L.Dropout(n.code, in_place=True,dropout_param=dict(dropout_ratio=dr['HC']))\n",
    "        \n",
    "    elif modality =='HC_CT': #multimodal AE - experimental stage\n",
    "        HC_node_split = 0.8\n",
    "        n.X_L_HC = L.HDF5Data(name='data',batch_size=batch_size, source=hdf5)\n",
    "        n.encoder_L_HC = L.InnerProduct(n.X_L_HC, num_output=int(HC_node_split*node_sizes['En1']), weight_filler=dict(type='gaussian',std=.1, sparse=int(0.2*0.9*node_sizes['En1'])))        \n",
    "        n.NLinEn_L_HC = L.ReLU(n.encoder_L_HC, in_place=True)\n",
    "        \n",
    "        n.X_CT = L.HDF5Data(name='data',batch_size=batch_size, source=hdf5)\n",
    "        n.encoder_CT = L.InnerProduct(n.X_CT, num_output=int((1-HC_node_split)*node_sizes['En1']), weight_filler=dict(type='gaussian',std=.1, sparse=int(0.2*0.1*node_sizes['En1'])))        \n",
    "        n.NLinEn_CT = L.ReLU(n.encoder_CT, in_place=True)\n",
    "        \n",
    "        #Concat         \n",
    "        n.encoder1 = L.Concat(n.encoder_L_HC,n.encoder_CT, concat_param=dict(axis=1))\n",
    "        \n",
    "    else:\n",
    "        print \"wrong modality\"\n",
    "    \n",
    "    #Encoder layers (or common encoder layers for multimodal) \n",
    "    \n",
    "#     n.encoder2 = L.InnerProduct(n.encoder1, num_output=node_sizes['En2'], weight_filler=dict(type='xavier'))\n",
    "#     n.NLinEn2 = L.Sigmoid(n.encoder2, in_place=True)\n",
    "    #code layer\n",
    "#    n.code = L.InnerProduct(n.encoder1, num_output=node_sizes['code'], weight_filler=dict(type='xavier'))  \n",
    "    \n",
    "#     n.decoder1 = L.InnerProduct(n.code, num_output=node_sizes['En2'], weight_filler=dict(type='xavier'))\n",
    "#     n.NLinDe1 = L.ReLU(n.decoder1, in_place=True)\n",
    "    \n",
    "    #Decoder layers\n",
    "    if modality == 'CT':\n",
    "#         n.decoder1 = L.InnerProduct(n.code, num_output=node_sizes['En1'], weight_filler=dict(type='xavier'))\n",
    "#         n.NLinDe1 = L.ReLU(n.decoder1, in_place=True)\n",
    "        n.output = L.InnerProduct(n.code, num_output=node_sizes['out'], weight_filler=dict(type='xavier'))    \n",
    "        n.loss = L.EuclideanLoss(n.output, n.X_CT)                    \n",
    "    \n",
    "    elif modality =='R_HC':\n",
    "#         n.decoder1 = L.InnerProduct(n.code, num_output=node_sizes['En1'], weight_filler=dict(type='xavier'))\n",
    "#         n.NLinDe1 = L.ReLU(n.decoder1, in_place=True)\n",
    "        n.output = L.InnerProduct(n.code, num_output=node_sizes['out'], weight_filler=dict(type='xavier'))    \n",
    "        n.loss = L.SigmoidCrossEntropyLoss(n.output, n.X_R_HC)\n",
    "    elif modality =='L_HC':\n",
    "#         n.decoder1 = L.InnerProduct(n.code, num_output=node_sizes['En1'], weight_filler=dict(type='xavier'))\n",
    "#         n.NLinDe1 = L.ReLU(n.decoder1, in_place=True)\n",
    "        n.output = L.InnerProduct(n.code, num_output=node_sizes['out'], weight_filler=dict(type='xavier'))    \n",
    "        n.loss = L.SigmoidCrossEntropyLoss(n.output, n.X_L_HC)\n",
    "    elif modality =='HC_CT':        \n",
    "        n.decoder_L_HC = L.InnerProduct(n.code, num_output=int(HC_node_split*node_sizes['En1']), weight_filler=dict(type='xavier'))  \n",
    "        n.NLinDe_L_CT = L.ReLU(n.decoder_L_HC, in_place=True)\n",
    "        n.decoder_CT = L.InnerProduct(n.code, num_output=int((1-HC_node_split)*node_sizes['En1']), weight_filler=dict(type='xavier'))  \n",
    "        n.NLinDe_CT = L.ReLU(n.decoder_CT, in_place=True)\n",
    "        \n",
    "        n.output_L_HC = L.InnerProduct(n.decoder_L_HC, num_output=node_sizes['out_HC'], weight_filler=dict(type='xavier'))\n",
    "        n.loss_HC = L.SigmoidCrossEntropyLoss(n.output_L_HC, n.X_L_HC)\n",
    "        \n",
    "        n.output_CT = L.InnerProduct(n.decoder_CT, num_output=node_sizes['out_CT'], weight_filler=dict(type='xavier'))\n",
    "        n.loss_CT = L.EuclideanLoss(n.output_CT, n.X_CT)\n",
    "    else:\n",
    "        print \"wrong modality\"\n",
    "    \n",
    "    return n.to_proto()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 5.01 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def run_caffe(solver,niter,batch_size,multi_task,multi_label,multimodal_autoencode):\n",
    "    # each output is (batch size, feature dim, spatial dim)\n",
    "    #print [(k, v.data.shape) for k, v in solver.net.blobs.items()]\n",
    "    test_interval = 500\n",
    "    test_iter = 20\n",
    "    \n",
    "    if multimodal_autoencode:\n",
    "        train_loss_HC = zeros(niter)\n",
    "        test_loss_HC = zeros(int(np.ceil(niter / test_interval)))\n",
    "        train_loss_CT = zeros(niter)\n",
    "        test_loss_CT = zeros(int(np.ceil(niter / test_interval)))\n",
    "        \n",
    "        for it in range(niter):            \n",
    "            solver.step(1)  # SGD by Caffe \n",
    "            train_loss_HC[it] = solver.net.blobs['loss_HC'].data\n",
    "            train_loss_CT[it] = solver.net.blobs['loss_CT'].data\n",
    "            \n",
    "            if it % test_interval == 0:                        \n",
    "                t_loss_HC = 0\n",
    "                t_loss_CT = 0                                \n",
    "                for test_it in range(test_iter):\n",
    "                    solver.test_nets[0].forward()   \n",
    "                    t_loss_HC += solver.test_nets[0].blobs['loss_HC'].data\n",
    "                    t_loss_CT += solver.test_nets[0].blobs['loss_CT'].data\n",
    "                \n",
    "                test_loss_HC[it // test_interval] = t_loss_HC/(test_iter)\n",
    "                test_loss_CT[it // test_interval] = t_loss_CT/(test_iter)\n",
    "                print 'HC Loss Iteration: {}, train loss(batch, sum): ({},{}), test loss: {}'.format(\n",
    "                            it, train_loss_HC[it], np.sum(train_loss_HC)/it, test_loss_HC[it // test_interval])\n",
    "                print 'CT Loss Iteration: {}, train loss(batch, sum): ({},{}), test loss: {}'.format(\n",
    "                            it, train_loss_CT[it], np.sum(train_loss_CT)/it, test_loss_CT[it // test_interval])\n",
    "                \n",
    "        perf = {'train_loss':[train_loss_HC, train_loss_CT],'test_loss':[test_loss_HC,test_loss_CT]}\n",
    "    else: \n",
    "        \n",
    "        #n_feat = solver.test_nets[0].blobs['data'].data.shape[1]\n",
    "        # losses will also be stored in the log\n",
    "        test_acc = zeros(int(np.ceil(niter / test_interval)))\n",
    "        if not multi_task:\n",
    "            train_loss = zeros(niter)\n",
    "            test_loss = zeros(int(np.ceil(niter / test_interval)))  \n",
    "\n",
    "        else: \n",
    "            if multi_label:\n",
    "                train_ADAS13_loss = zeros(niter)\n",
    "                test_ADAS13_loss = zeros(int(np.ceil(niter / test_interval)))\n",
    "                train_DX_loss = zeros(niter)\n",
    "                test_DX_loss = zeros(int(np.ceil(niter / test_interval)))\n",
    "            else:\n",
    "                train_ADAS13_loss = zeros(niter)\n",
    "                test_ADAS13_loss = zeros(int(np.ceil(niter / test_interval)))\n",
    "                train_MMSE_loss = zeros(niter)\n",
    "                test_MMSE_loss = zeros(int(np.ceil(niter / test_interval)))\n",
    "\n",
    "        #output = zeros((niter, batch_size))\n",
    "        #solver.restore()\n",
    "        #the main solver loop\n",
    "        for it in range(niter):\n",
    "            #solver.net.forward()\n",
    "            solver.step(1)  # SGD by Caffe    \n",
    "            # store the train loss\n",
    "            if not multi_task:\n",
    "                train_loss[it] = solver.net.blobs['loss'].data        \n",
    "            else: \n",
    "                if multi_label:\n",
    "                    train_ADAS13_loss[it] = solver.net.blobs['ADAS13_loss'].data\n",
    "                    train_DX_loss[it] = solver.net.blobs['DX_loss'].data\n",
    "                else:\n",
    "                    train_ADAS13_loss[it] = solver.net.blobs['ADAS13_loss'].data\n",
    "                    train_MMSE_loss[it] = solver.net.blobs['MMSE_loss'].data\n",
    "\n",
    "            # store the output on the first test batch\n",
    "            # (start the forward pass at conv1 to avoid loading new data)\n",
    "            #solver.test_nets[0].forward()\n",
    "            #output[it] = solver.test_nets[0].blobs['output'].data\n",
    "\n",
    "            # run a full test every so often\n",
    "            # (Caffe can also do this for us and write to a log, but we show here\n",
    "            #  how to do it directly in Python, where more complicated things are easier.)\n",
    "            if it % test_interval == 0:        \n",
    "                t_loss = 0\n",
    "                t_ADAS13_loss = 0\n",
    "                t_MMSE_loss = 0\n",
    "                t_DX_loss = 0\n",
    "                correct = 0\n",
    "                for test_it in range(test_iter):\n",
    "                    solver.test_nets[0].forward()                \n",
    "                    if not multi_task:\n",
    "                        t_loss += solver.test_nets[0].blobs['loss'].data\n",
    "                        if multi_label:\n",
    "                            correct += sum(solver.test_nets[0].blobs['output'].data.argmax(1)\n",
    "                               == solver.test_nets[0].blobs['dx_cat3'].data)\n",
    "                    else: \n",
    "                        if multi_label:\n",
    "                            t_ADAS13_loss += solver.test_nets[0].blobs['ADAS13_loss'].data\n",
    "                            t_DX_loss += solver.test_nets[0].blobs['DX_loss'].data\n",
    "                            correct += sum(solver.test_nets[0].blobs['output_DX'].data.argmax(1)\n",
    "                               == solver.test_nets[0].blobs['dx_cat3'].data)\n",
    "\n",
    "                        else:\n",
    "                            t_ADAS13_loss += solver.test_nets[0].blobs['ADAS13_loss'].data\n",
    "                            t_MMSE_loss += solver.test_nets[0].blobs['MMSE_loss'].data\n",
    "\n",
    "                if not multi_task:\n",
    "                    test_loss[it // test_interval] = t_loss/(test_iter)\n",
    "                    if multi_label:\n",
    "                        test_acc[it // test_interval] = float(correct)/(test_iter*batch_size)\n",
    "                    print 'Iteration: {}, train loss(batch, sum): ({},{}), test loss: {}, test acc: {}'.format(\n",
    "                        it, train_loss[it], np.sum(train_loss)/it, test_loss[it // test_interval], test_acc[it // test_interval])\n",
    "                else:\n",
    "                    if multi_label:\n",
    "                        test_ADAS13_loss[it // test_interval] = t_ADAS13_loss/(test_iter)\n",
    "                        test_DX_loss[it // test_interval] = t_DX_loss/(test_iter) \n",
    "                        test_acc[it // test_interval] = float(correct)/(test_iter*batch_size)\n",
    "                        print 'ADAS Loss Iteration: {}, train loss(batch, sum): ({},{}), test loss: {}'.format(\n",
    "                            it, train_ADAS13_loss[it], np.sum(train_ADAS13_loss)/it, test_ADAS13_loss[it // test_interval])\n",
    "                        print 'DX Loss Iteration: {}, train loss(batch, sum): ({},{}), test loss: {}, test acc: {}'.format(\n",
    "                            it, train_DX_loss[it], np.sum(train_DX_loss)/it, test_DX_loss[it // test_interval],test_acc[it // test_interval])\n",
    "                    else:\n",
    "                        test_ADAS13_loss[it // test_interval] = t_ADAS13_loss/(test_iter)\n",
    "                        test_MMSE_loss[it // test_interval] = t_MMSE_loss/(test_iter)             \n",
    "\n",
    "                        print 'ADAS Loss Iteration: {}, train loss(batch, sum): ({},{}), test loss: {}'.format(\n",
    "                            it, train_ADAS13_loss[it], np.sum(train_ADAS13_loss)/it, test_ADAS13_loss[it // test_interval])\n",
    "                        print 'MMSE Loss Iteration: {}, train loss(batch, sum): ({},{}), test loss: {}'.format(\n",
    "                            it, train_MMSE_loss[it], np.sum(train_MMSE_loss)/it, test_MMSE_loss[it // test_interval])\n",
    "\n",
    "        if not multi_task:\n",
    "            perf = {'train_loss':[train_loss],'test_loss':[test_loss],'test_acc':[test_acc]}\n",
    "        else:\n",
    "            if multi_label:\n",
    "                perf = {'train_loss':[train_ADAS13_loss,train_DX_loss],'test_loss':[test_ADAS13_loss,test_DX_loss],'test_acc':[test_acc]}\n",
    "            else:\n",
    "                perf = {'train_loss':[train_ADAS13_loss,train_MMSE_loss],'test_loss':[test_ADAS13_loss,test_MMSE_loss]}\n",
    "                \n",
    "    return perf\n",
    "\n",
    "def pickleIt(my_data,save_path):\n",
    "    f = open(save_path, 'wb')\n",
    "    pickle.dump(my_data, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from caffe.proto import caffe_pb2\n",
    "### define solver\n",
    "def adni_solver(train_net_path, test_net_path,solver_configs,snap_prefix):    \n",
    "    s = caffe_pb2.SolverParameter()\n",
    "    \n",
    "    # Set a seed for reproducible experiments:\n",
    "    # this controls for randomization in training.\n",
    "    s.random_seed = 0xCAFFE\n",
    "\n",
    "    # Specify locations of the train and (maybe) test networks.\n",
    "    s.train_net = train_net_path\n",
    "    s.test_net.append(test_net_path)\n",
    "    s.test_interval = 500  # Test after every 500 training iterations.\n",
    "    s.test_iter.append(30) # Test on 100 batches each time we test.\n",
    "\n",
    "    s.max_iter = 10000     # no. of times to update the net (training iterations)\n",
    "\n",
    "    # EDIT HERE to try different solvers\n",
    "    # solver types include \"SGD\", \"Adam\", and \"Nesterov\" among others.\n",
    "    #s.solver_type = \"Nesterov\"\n",
    "\n",
    "    # Set the initial learning rate for SGD.\n",
    "    #s.base_lr = 0.00001  # EDIT HERE to try different learning rates\n",
    "    s.base_lr = solver_configs['base_lr']\n",
    "    # Set momentum to accelerate learning by\n",
    "    # taking weighted average of current and previous updates.\n",
    "    #if not s.type == \"AdaGrad\":\n",
    "    #    s.momentum = 0.9\n",
    "    # Set `lr_policy` to define how the learning rate changes during training.\n",
    "    # This is the same policy as our default LeNet.\n",
    "    s.lr_policy = \"step\"\n",
    "    s.stepsize = 100000\n",
    "    s.gamma = 0.5\n",
    "    #s.power = 0.75\n",
    "    # EDIT HERE to try the fixed rate (and compare with adaptive solvers)\n",
    "    # `fixed` is the simplest policy that keeps the learning rate constant.\n",
    "    # s.lr_policy = 'fixed'\n",
    "    \n",
    "    # Set weight decay to regularize and prevent overfitting\n",
    "    #s.weight_decay = 1e-3\n",
    "    s.weight_decay = solver_configs['wt_decay']\n",
    "    \n",
    "    # Display the current training loss and accuracy every 1000 iterations.\n",
    "    s.display = 1000\n",
    "\n",
    "    # Snapshots are files used to store networks we've trained.\n",
    "    # We'll snapshot every 5K iterations -- twice during training.\n",
    "    s.snapshot = 4000\n",
    "    s.snapshot_prefix = snap_prefix\n",
    "\n",
    "    # Train on the GPU\n",
    "    s.solver_mode = caffe_pb2.SolverParameter.GPU\n",
    "    \n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MC # 1, Hype # hyp1, Fold # 1\n",
      "\n",
      "MC # 1, Hype # hyp1, Fold # 2\n",
      "\n",
      "MC # 1, Hype # hyp1, Fold # 3\n",
      "\n",
      "MC # 1, Hype # hyp1, Fold # 4\n",
      "\n",
      "MC # 1, Hype # hyp1, Fold # 5\n",
      "\n",
      "MC # 1, Hype # hyp1, Fold # 6\n",
      "\n",
      "MC # 1, Hype # hyp1, Fold # 7\n",
      "\n",
      "MC # 1, Hype # hyp1, Fold # 8\n",
      "\n",
      "MC # 1, Hype # hyp1, Fold # 9\n",
      "\n",
      "MC # 1, Hype # hyp1, Fold # 10\n",
      "run time for single CV loop: 171.103167057\n",
      "\n",
      "MC # 2, Hype # hyp1, Fold # 1\n",
      "\n",
      "MC # 2, Hype # hyp1, Fold # 2\n",
      "\n",
      "MC # 2, Hype # hyp1, Fold # 3\n",
      "\n",
      "MC # 2, Hype # hyp1, Fold # 4\n",
      "\n",
      "MC # 2, Hype # hyp1, Fold # 5\n",
      "\n",
      "MC # 2, Hype # hyp1, Fold # 6\n",
      "\n",
      "MC # 2, Hype # hyp1, Fold # 7\n",
      "\n",
      "MC # 2, Hype # hyp1, Fold # 8\n",
      "\n",
      "MC # 2, Hype # hyp1, Fold # 9\n",
      "\n",
      "MC # 2, Hype # hyp1, Fold # 10\n",
      "run time for single CV loop: 168.838726997\n"
     ]
    }
   ],
   "source": [
    "# Deign Net Architecutre and Run Caffe\n",
    "exp_name = 'Exp13_MC'\n",
    "cohort = 'ADNI1and2'\n",
    "#preproc = 'ae_preproc_sparse_HC_10k_CT_100k_hyp1'\n",
    "preproc = 'no_preproc'\n",
    "modality = 'HC'\n",
    "Clinical_Scale = 'BOTH'    \n",
    "multi_label = False\n",
    "start_MC=1\n",
    "n_MC=2\n",
    "MC_list = np.arange(start_MC,n_MC+1,1)\n",
    "start_fold = 1\n",
    "n_folds = 10\n",
    "fid_list = np.arange(start_fold,n_folds+1,1)\n",
    "niter = 40000\n",
    "batch_size = 256\n",
    "\n",
    "pretrain = False\n",
    "multimodal_autoencode = False\n",
    "load_pretrained_weights = False\n",
    "\n",
    "if Clinical_Scale in ['BOTH','ADAS13_DX'] :\n",
    "    multi_task = True\n",
    "else:\n",
    "    multi_task = False\n",
    "\n",
    "#Hyperparameter Search\n",
    "#CT': 128, 'L_HC': 64, 'R_HC': 64, 'concat': 16\n",
    "#hyp1 and 2 work for ADNI1+2 MMSE\n",
    "# dr: Dropout rate, lr: learning rate of each modality, tr: loss-weight for each task\n",
    "hype_configs = {\n",
    "               'hyp1':{'node_sizes':{'HC_L_ff':50,'HC_R_ff':50,'CT_ff':50,'HC_CT_ff':25,'COMB_ff':50,\n",
    "                                       'ADAS_ff':25,'MMSE_ff':25,'DX_ff':25,\n",
    "                                       'En1':10000,'En2':2000,'code':600,'out':686},\n",
    "                      'dr':{'HC':0,'CT':0,'HC_CT':0,'COMB':0},'lr':{'HC':2,'CT':2,'COMB':1},\n",
    "                      'tr':{'ADAS':1,'MMSE':2,'DX':1},'solver_conf':{'base_lr':5e-6, 'wt_decay':1e-3}}, \n",
    "    \n",
    "#                 'hyp2':{'node_sizes':{'HC_L_ff':50,'HC_R_ff':50,'CT_ff':50,'HC_CT_ff':25,'COMB_ff':50,\n",
    "#                                        'ADAS_ff':25,'MMSE_ff':25,'DX_ff':25,\n",
    "#                                        'En1':10000,'En2':2000,'code':600,'out':686},\n",
    "#                       'dr':{'HC':0,'CT':0,'HC_CT':0,'COMB':0},'lr':{'HC':0.1,'CT':0.1,'COMB':1},\n",
    "#                       'tr':{'ADAS':1,'MMSE':4,'DX':1},'solver_conf':{'base_lr':5e-6, 'wt_decay':1e-3}}, \n",
    "\n",
    "#                 'hyp3':{'node_sizes':{'HC_L_ff':50,'HC_R_ff':50,'CT_ff':200,'HC_CT_ff':25,'COMB_ff':50,\n",
    "#                                        'ADAS_ff':25,'MMSE_ff':25,'DX_ff':25,\n",
    "#                                        'En1':10000,'En2':2000,'code':600,'out':686},\n",
    "#                       'dr':{'HC':0,'CT':0,'HC_CT':0,'COMB':0},'lr':{'HC':0,'CT':0,'COMB':1},\n",
    "#                       'tr':{'ADAS':1,'MMSE':4,'DX':1},'solver_conf':{'base_lr':3e-6, 'wt_decay':1e-3}},   \n",
    "                    \n",
    "                }\n",
    "\n",
    "CV_perf_MC = {}\n",
    "for mc in MC_list:\n",
    "    CV_perf_hype = {}\n",
    "    for hype in hype_configs.keys():    \n",
    "        node_sizes = hype_configs[hype]['node_sizes']\n",
    "        dr = hype_configs[hype]['dr']\n",
    "        lr = hype_configs[hype]['lr']\n",
    "        tr = hype_configs[hype]['tr']\n",
    "        solver_configs = hype_configs[hype]['solver_conf']\n",
    "        \n",
    "        if hype in ['hyp1','hyp4']:\n",
    "            HC_snap = 20000 #5000 for ADNI1\n",
    "            CT_snap = 20000 #5000 for ADNI1\n",
    "            pre_hype = 'hyp1'\n",
    "        elif hype in ['hyp2','hyp5']:\n",
    "            HC_snap = 8000 #5000 for ADNI1\n",
    "            CT_snap = 28000 #5000 for ADNI1\n",
    "            pre_hype = 'hyp2'\n",
    "        else:\n",
    "            print 'unknown hyp config'\n",
    "            \n",
    "        CV_perf = {}\n",
    "        start_time = time.time()\n",
    "        for fid in fid_list:            \n",
    "            print ''\n",
    "            print 'MC # {}, Hype # {}, Fold # {}'.format(mc, hype, fid)\n",
    "            snap_prefix = baseline_dir + 'API/data/MC_{}/fold{}/train_snaps/{}_{}_{}'.format(mc,fid,exp_name,hype,modality)\n",
    "\n",
    "            train_filename_txt = baseline_dir + 'API/data/MC_{}/fold{}/train_C688.txt'.format(mc,fid)\n",
    "            test_filename_txt = baseline_dir + 'API/data/MC_{}/fold{}/test_C688.txt'.format(mc,fid)\n",
    "\n",
    "            train_filename_hdf = baseline_dir + 'API/data/MC_{}/fold{}/inner_train/{}.h5'.format(mc,fid,exp_name)\n",
    "            test_filename_hdf = baseline_dir + 'API/data/MC_{}/fold{}/inner_test/{}.h5'.format(mc,fid,exp_name)\n",
    "            with open(train_filename_txt, 'w') as f:\n",
    "                    f.write(train_filename_hdf + '\\n')    \n",
    "\n",
    "            with open(test_filename_txt, 'w') as f:\n",
    "                    f.write(test_filename_hdf + '\\n')  \n",
    "\n",
    "            # Define Net (examples: 'ADNI_AE_train.prototxt', 'ADNI_FF_train.prototxt')\n",
    "            if pretrain:\n",
    "                train_net_path = baseline_dir + 'API/data/MC_{}/fold{}/ADNI_AE_train.prototxt'.format(mc,fid)\n",
    "                with open(train_net_path, 'w') as f:\n",
    "                    f.write(str(adninet_ae(train_filename_txt, batch_size, node_sizes, modality)))            \n",
    "            else:\n",
    "                train_net_path = baseline_dir + 'API/data/MC_{}/fold{}/ADNI_FF_train_{}_{}.prototxt'.format(mc,fid,hype,modality)\n",
    "                with open(train_net_path, 'w') as f:            \n",
    "                    if modality == 'HC':\n",
    "                          f.write(str(adninet_ff_HC(train_filename_txt, batch_size, node_sizes,dr, lr, tr, Clinical_Scale)))\n",
    "                    elif modality == 'CT':\n",
    "                          f.write(str(adninet_ff_CT(train_filename_txt, batch_size, node_sizes,dr, lr, tr, Clinical_Scale)))\n",
    "                    elif modality == 'HC_CT':\n",
    "                          f.write(str(adninet_ff_HC_CT(train_filename_txt, batch_size, node_sizes,dr, lr, tr, Clinical_Scale )))\n",
    "                    elif modality == 'HC_CT_unified_hyp1':\n",
    "                          f.write(str(adninet_ff_HC_CT_unified(train_filename_txt, batch_size, node_sizes,dr, lr, tr, Clinical_Scale )))\n",
    "                    else:\n",
    "                          print 'Wrong modality'\n",
    "\n",
    "            if pretrain:\n",
    "                test_net_path = baseline_dir + 'API/data/MC_{}/fold{}/ADNI_AE_test.prototxt'.format(mc,fid)\n",
    "                with open(test_net_path, 'w') as f:\n",
    "                    f.write(str(adninet_ae(test_filename_txt, batch_size, node_sizes,modality)))\n",
    "            else:\n",
    "                test_net_path = baseline_dir + 'API/data/MC_{}/fold{}/ADNI_FF_test_{}_{}.prototxt'.format(mc,fid,hype,modality)\n",
    "                with open(test_net_path, 'w') as f:\n",
    "                    if modality == 'HC':\n",
    "                          f.write(str(adninet_ff_HC(test_filename_txt, batch_size, node_sizes,dr, lr, tr, Clinical_Scale)))\n",
    "                    elif modality == 'CT':\n",
    "                          f.write(str(adninet_ff_CT(test_filename_txt, batch_size, node_sizes,dr, lr, tr, Clinical_Scale)))\n",
    "                    elif modality == 'HC_CT':\n",
    "                          f.write(str(adninet_ff_HC_CT(test_filename_txt, batch_size, node_sizes,dr, lr, tr, Clinical_Scale)))\n",
    "                    elif modality == 'HC_CT_unified_hyp1':\n",
    "                          f.write(str(adninet_ff_HC_CT_unified(test_filename_txt, batch_size, node_sizes,dr, lr, tr, Clinical_Scale )))\n",
    "                    else:\n",
    "                          print 'Wrong modality'\n",
    "\n",
    "            # Define Solver\n",
    "            solver_path = baseline_dir + 'API/model_configs/adninet_solver.prototxt'\n",
    "            with open(solver_path, 'w') as f:\n",
    "                f.write(str(adni_solver(train_net_path, test_net_path, solver_configs, snap_prefix)))\n",
    "\n",
    "            ### load the solver and create train and test nets\n",
    "            #solver = None  # ignore this workaround for lmdb data (can't instantiate two solvers on the same data)\n",
    "            #solver = caffe.get_solver(solver_path)\n",
    "            #solver = caffe.NesterovSolver(solver_path)\n",
    "            solver = caffe.NesterovSolver(solver_path)\n",
    "\n",
    "            if load_pretrained_weights:                    \n",
    "                net_name = 'API/data/MC_{}/fold{}/pretrained_models/{}_ff_{}_HC_CT_HC_snap_{}_CT_snap_{}_Sup_Concat.caffemodel'\n",
    "                snap_path = baseline_dir + net_name.format(mc,fid,cohort,pre_hype,HC_snap,CT_snap)\n",
    "                print \"loading pretrained weights from {}\".format(snap_path)        \n",
    "                solver.net.copy_from(snap_path)\n",
    "\n",
    "#             #run caffe\n",
    "#             results = run_caffe(solver,niter,batch_size,multi_task,multi_label,multimodal_autoencode)\n",
    "#             CV_perf[fid] = results\n",
    "            \n",
    "        print('run time for single CV loop: {}'.format(time.time() - start_time))\n",
    "\n",
    "        CV_perf_hype[hype] = CV_perf\n",
    "        \n",
    "CV_perf_MC[mc] = CV_perf_hype\n",
    "\n",
    "# pickleIt(CV_perf_MC, baseline_dir + 'API/CV_perf/train_loss_{}'.format(modality))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.4444444444\n",
      "3.54166666667\n"
     ]
    }
   ],
   "source": [
    "#Time for training \n",
    "#HC_CT fold 9,10, number of iterations: 40k, two hyper-params\n",
    "#start time: 14:47\n",
    "#end time: 15:31\n",
    "#runtime_mean = (13+31)/4\n",
    "#print runtime_mean\n",
    "\n",
    "tx=140 #time for 10k iters\n",
    "itx=5 # num of 10k iters\n",
    "hx=2 #hyp choices\n",
    "fx=10 #k-folds\n",
    "mx=5 #mc-folds\n",
    "\n",
    "num_hrs = (tx*itx*hx*fx*mx)/(3600.0)\n",
    "print num_hrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABdEAAAJoCAYAAACJN6g5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/H9ED5ytS7CoSwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8115fbac10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot train loss and acc\n",
    "plt.rcParams['figure.figsize'] = (25, 10)\n",
    "#niter = 30000\n",
    "test_interval = 500\n",
    "n_mc = len(CV_perf_MC.keys())\n",
    "\n",
    "for m, mc in enumerate(CV_perf_MC.keys()): \n",
    "    CV_perf_hype = CV_perf_MC[mc]\n",
    "    \n",
    "    for hype in CV_perf_hype.keys(): \n",
    "        CV_perf = CV_perf_hype[hype]\n",
    "        n_CV_configs = len(CV_perf)\n",
    "        pid = m*n_CV_configs + 1\n",
    "        \n",
    "        for f, fid in enumerate(fid_list):  \n",
    "            train_loss_list = CV_perf[fid]['train_loss']\n",
    "            test_loss_list = CV_perf[fid]['test_loss']\n",
    "            \n",
    "            for train_loss, test_loss in zip(train_loss_list,test_loss_list):\n",
    "                #plt.figure()\n",
    "                ax1 = plt.subplot(n_mc,n_CV_configs,pid)            \n",
    "                ax1.plot(arange(niter), train_loss, label='train',linewidth='.5',alpha=0.25)\n",
    "                ax1.plot(test_interval * arange(len(test_loss)), test_loss, label='test_{}'.format(hype), linewidth='3')                            \n",
    "                ax1.set_xlabel('iteration')\n",
    "                ax1.set_ylabel('loss')\n",
    "                ax1.set_title('fid: {}, hyp: {}, Test loss: {:.2f}'.format(fid, hype, test_loss[-1]))\n",
    "                ax1.legend(loc=1)\n",
    "                ax1.set_ylim(0,100)\n",
    "            pid += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp_name = 'Exp11'\n",
    "preproc = 'no_preproc'\n",
    "modality = 'R_HC'\n",
    "batch_size = 256\n",
    "encoding_layer = 'code'\n",
    "weight_layers = 'code'\n",
    "multi_task = False\n",
    "\n",
    "if modality in ['L_HC', 'R_HC']:\n",
    "    snap_iter = 10000\n",
    "    \n",
    "    if modality == 'R_HC':\n",
    "        output_node_size = 16471\n",
    "    else: \n",
    "        output_node_size = 16086\n",
    "        \n",
    "    hype_configs = {\n",
    "                   'hyp1':{'node_sizes':{'En1':10000,'En2':2000,'code':8000,'out':output_node_size},\n",
    "                  'dr':{'HC':0,'CT':0,'COMB':0},'lr':{'HC':2,'CT':2},\n",
    "                  'solver_conf':{'base_lr':1e-5, 'wt_decay':1e-3}}\n",
    "    }\n",
    "\n",
    "elif modality in ['CT']:  \n",
    "    snap_iter = 100000\n",
    "    \n",
    "    hype_configs = {\n",
    "                    'hyp1':{'node_sizes':{'code':600,'out':686},\n",
    "                      'dr':{'HC':0,'CT':0,'HC_CT':0,'COMB':0},'lr':{'HC':2,'CT':2,'HC_CT':2},'tr':{'ADAS':1,'MMSE':2,'DX':1},\n",
    "                      'solver_conf':{'base_lr':1e-4, 'wt_decay':1e-3}}\n",
    "    }\n",
    "    \n",
    "elif modality in ['HC_CT']:  \n",
    "    snap_iter = 20000\n",
    "    hype_configs = {\n",
    "                 'hyp1':{'node_sizes':{'En1':10000,'En2':2000,'code':500,'out_HC':16086,'out_CT':686},\n",
    "                  'dr':{'HC':0,'CT':0,'COMB':0},'lr':{'HC':2,'CT':2},\n",
    "                  'solver_conf':{'base_lr':1e-5, 'wt_decay':1e-3}}\n",
    "    }\n",
    "    \n",
    "hype = 'hyp1'\n",
    "pretrain_preproc = 'ae_preproc_sparse_HC_10k_CT_100k_{}'.format(hype)\n",
    "fid = 1\n",
    "node_sizes = hype_configs[hype]['node_sizes']\n",
    "dr = hype_configs[hype]['dr']\n",
    "lr = hype_configs[hype]['lr']\n",
    "\n",
    "# Save either L or R HC encodings. Turn on CT + CS save only for one of these. \n",
    "# (Also decide if you want to copy CT raw scores or encodings)\n",
    "save_encodings = True\n",
    "save_scores = False\n",
    "CT_encodings = True\n",
    "\n",
    "for cohort in ['inner_train', 'inner_test','outer_test']:\n",
    "    data_path = baseline_dir + 'API/data/fold{}/{}/{}_{}.h5'.format(fid,cohort,exp_name,preproc)\n",
    "    test_filename_txt = baseline_dir + 'API/data/fold{}/test_C688.txt'.format(fid)\n",
    "    test_net_path = baseline_dir + 'API/data/fold{}/ADNI_AE_test.prototxt'.format(fid)       \n",
    "    input_nodes = ['X_{}'.format(modality)]\n",
    "    #input_nodes = ['X_L_HC','X_CT']\n",
    "    net_file = baseline_dir + 'API/data/fold{}/ADNI_AE_test.prototxt'.format(fid)\n",
    "    with open(net_file, 'w') as f:\n",
    "        f.write(str(adninet_ae(test_filename_txt, 256, node_sizes,modality)))\n",
    "\n",
    "    test_filename_hdf = baseline_dir + 'API/data/fold{}/{}/{}_{}.h5'.format(fid,cohort,exp_name,preproc)\n",
    "    test_filename_txt = baseline_dir + 'API/data/fold{}/{}_C688.txt'.format(fid,cohort)\n",
    "    with open(test_filename_txt, 'w') as f:\n",
    "        f.write(test_filename_hdf + '\\n') \n",
    "\n",
    "    sub.call([\"cp\", baseline_dir + 'API/data/fold{}/{}_C688.txt'.format(fid,cohort), baseline_dir + 'API/data/fold{}/test_C688.txt'.format(fid)])\n",
    "\n",
    "    if modality == 'CT':\n",
    "        model_file = baseline_dir + 'API/data/fold{}/train_snaps/{}_{}_{}_iter_{}.caffemodel'.format(fid,exp_name,hype,modality,snap_iter)  \n",
    "    else:\n",
    "        model_file = baseline_dir + 'API/data/fold{}/train_snaps/{}_{}_{}_iter_{}.caffemodel'.format(fid,exp_name,hype,modality,snap_iter)  \n",
    "        \n",
    "    print 'Check Sparsity for model: {}'.format(model_file)\n",
    "    \n",
    "    results = extract_features(net_file, model_file, data_path, input_nodes, batch_size, encoding_layer, weight_layers,multi_task)\n",
    "    encodings = np.squeeze(results['X_out'])      \n",
    "    \n",
    "    encodings_hdf_file = baseline_dir + 'API/data/fold{}/{}/{}_{}.h5'.format(fid,cohort,exp_name,pretrain_preproc)\n",
    "    \n",
    "    if save_encodings:    \n",
    "        input_data = h5py.File(encodings_hdf_file, 'a')\n",
    "        input_data.create_dataset(input_nodes[0],data=encodings)           \n",
    "        input_data.close()\n",
    "        \n",
    "    if save_scores:\n",
    "        input_data = h5py.File(encodings_hdf_file, 'a')\n",
    "        if not CT_encodings: #copy raw scores for CT instead of encodings\n",
    "            CT_data = load_data(data_path, 'X_CT','no_preproc')                    \n",
    "            input_data.create_dataset('X_CT', data=CT_data)    \n",
    "            \n",
    "        adas_scores = load_data(data_path, 'y','no_preproc')\n",
    "        mmse_scores = load_data(data_path, 'y3','no_preproc')\n",
    "        dx_labels = load_data(data_path, 'dx_cat3','no_preproc')\n",
    "        input_data.create_dataset('y', data=adas_scores)           \n",
    "        input_data.create_dataset('y3', data=mmse_scores)    \n",
    "        input_data.create_dataset('dx_cat3', data=dx_labels)\n",
    "        input_data.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting TSNE embeddings \n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "exp_name = 'Exp11'\n",
    "#preproc = 'no_preproc'\n",
    "#preproc = 'ae_preproc_sparse_HC_10k_CT_100k_hyp1'\n",
    "Clinical_Scale = 'ADAS13_DX' \n",
    "batch_size = 256\n",
    "snap_interval = 2000\n",
    "snap_start = 2000\n",
    "encoding_layer = 'ff3'\n",
    "weight_layers = 'ff3'\n",
    "cohort = 'outer_test'\n",
    "multi_task = False\n",
    "\n",
    "modality = 'HC_CT'\n",
    "snap_end = 21000\n",
    "\n",
    "\n",
    "hype_configs = {\n",
    "            'hyp1':{'node_sizes':{'HC_L_ff':25,'HC_R_ff':25,'CT_ff':25,'HC_CT_ff':25,'COMB_ff':25,'ADAS_ff':25,'MMSE_ff':25,'DX_ff':25,\n",
    "                                       'En1':10000,'En2':2000,'code':600,'out':686},\n",
    "                      'dr':{'HC':0,'CT':0,'HC_CT':0,'COMB':0},'lr':{'HC':2,'CT':2,'HC_CT':2},'tr':{'ADAS':1,'MMSE':2,'DX':1},\n",
    "                      'solver_conf':{'base_lr':1e-6, 'wt_decay':1e-2}},\n",
    "}\n",
    "\n",
    "hype = 'hyp1'\n",
    "fid = 1\n",
    "node_sizes = hype_configs[hype]['node_sizes']\n",
    "dr = hype_configs[hype]['dr']\n",
    "lr = hype_configs[hype]['lr']\n",
    "tr = hype_configs[hype]['tr']\n",
    "\n",
    "data_path = baseline_dir + 'API/data/fold{}/{}/{}_{}.h5'.format(fid,cohort,exp_name,preproc)\n",
    "test_filename_txt = baseline_dir + 'API/data/fold{}/test_C688.txt'.format(fid)\n",
    "test_net_path = baseline_dir + 'API/data/fold{}/ADNI_ff_test.prototxt'.format(fid)       \n",
    "#input_node = 'X_{}'.format(modality)\n",
    "\n",
    "net_file = baseline_dir + 'API/data/fold{}/ADNI_ff_test.prototxt'.format(fid)\n",
    "with open(net_file, 'w') as f:\n",
    "    #f.write(str(adninet_ae(test_filename_txt, 256, node_sizes,modality)))\n",
    "    f.write(str(adninet_ff_HC_CT(test_filename_txt, 256, node_sizes,dr,lr,tr,Clinical_Scale)))\n",
    "    input_nodes = ['X_L_HC','X_R_HC','X_CT']\n",
    "\n",
    "test_filename_hdf = baseline_dir + 'API/data/fold{}/{}/{}_{}.h5'.format(fid,cohort,exp_name,preproc)\n",
    "test_filename_txt = baseline_dir + 'API/data/fold{}/{}_C688.txt'.format(fid,cohort)\n",
    "with open(test_filename_txt, 'w') as f:\n",
    "    f.write(test_filename_hdf + '\\n') \n",
    "\n",
    "sub.call([\"cp\", baseline_dir + 'API/data/fold{}/{}_C688.txt'.format(fid,cohort), baseline_dir + 'API/data/fold{}/test_C688.txt'.format(fid)])\n",
    "\n",
    "n_snaps = len(np.arange(snap_start,snap_end,snap_interval))\n",
    "tsne_encodings = {}\n",
    "net_weights = {}\n",
    "for sn, snap_iter in enumerate(np.arange(snap_start,snap_end,snap_interval)):\n",
    "    print sn, snap_iter\n",
    "    model_file = baseline_dir + 'API/data/fold{}/train_snaps/{}_{}_{}_iter_{}.caffemodel'.format(fid,exp_name,hype,modality,snap_iter)        \n",
    "    results = extract_features(net_file, model_file, data_path, input_nodes, batch_size, encoding_layer, weight_layers,multi_task)\n",
    "    encodings = np.squeeze(results['X_out'])      \n",
    "    net_weights[snap_iter] = results['wt_dict']\n",
    "    print encodings.shape\n",
    "\n",
    "    adas_scores = load_data(data_path, 'y','no_preproc')\n",
    "    mmse_scores = load_data(data_path, 'y3','no_preproc')\n",
    "    dx_labels = load_data(data_path, 'dx_cat3','no_preproc')\n",
    "    tsne_model = TSNE(n_components=2, random_state=0, init='pca')\n",
    "    tsne_encodings[snap_iter] = tsne_model.fit_transform(encodings) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (20, 20)\n",
    "plot_encodings = True\n",
    "plot_wts = False\n",
    "\n",
    "color_scores = dx_labels\n",
    "cm = plt.get_cmap('RdYlBu') \n",
    "marker_size = 100\n",
    "marker_size = (np.mod(color_scores+1,2)+1)*50\n",
    "\n",
    "for sn, snap_iter in enumerate(np.arange(snap_start,snap_end,snap_interval)):\n",
    "    plt.subplot(np.ceil(n_snaps/2.0),2,sn+1)\n",
    "    if plot_encodings:\n",
    "        plt.scatter(tsne_encodings[snap_iter][:,0],tsne_encodings[snap_iter][:,1],c=color_scores,s=marker_size,cmap=cm)\n",
    "    if plot_wts:\n",
    "        plt.imshow(net_weights[snap_iter][weight_layers])\n",
    "        \n",
    "    plt.title(snap_iter)\n",
    "    plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exp13_MC 1 HC\n",
      "Weights Tuned for: both\n",
      "Clinical_Scale: BOTH\n",
      "ADAS corr: [0.54406000313806924, 0.54560523578529063, 0.4372843423311214, 0.61992111073867262, 0.58947870471460995, 0.66553232831036147, 0.36680928902938753, 0.48864912744345623, 0.55187475560361055, 0.51589872395238223]\n",
      "ADAS mse: [63.966946844388168, 62.487979233456969, 72.295800099522609, 60.896080650849136, 51.503799996591546, 43.895859429719906, 95.830896247947933, 67.974543525135303, 53.779403711744926, 72.342211502552516]\n",
      "ADAS means: 0.532511362105, 64.4973521242\n",
      "\n",
      "MMSE corr: [0.48085545186748596, 0.46072877924673727, 0.4576762726218831, 0.45657565887311136, 0.45516869779664976, 0.44546524724649522, 0.26952780500860996, 0.42059680391658666, 0.47235630106116577, 0.37215395416036906]\n",
      "MMSE mse: [5.6812780784361516, 5.5268505273065589, 5.3315840348314998, 6.2717487010627107, 5.8659336014421486, 5.8587104805557617, 7.9611724175712011, 5.5613612708417728, 5.0962414624342012, 6.5483450078306911]\n",
      "MMSE means: 0.42911049718, 5.97032255823\n",
      "\n",
      "opt_hyp: {1: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 2: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 3: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 4: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 5: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 6: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 7: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 8: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 9: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 10: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}}\n",
      "\n",
      "opt_snap: {1: 4, 2: 4, 3: 3, 4: 3, 5: 4, 6: 4, 7: 2, 8: 4, 9: 5, 10: 4}\n",
      "Weights Tuned for: adas\n",
      "Clinical_Scale: BOTH\n",
      "ADAS corr: [0.54406000313806924, 0.54560523578529063, 0.4372843423311214, 0.61992111073867262, 0.58947870471460995, 0.66553232831036147, 0.36680928902938753, 0.48864912744345623, 0.55187475560361055, 0.51589872395238223]\n",
      "ADAS mse: [63.966946844388168, 62.487979233456969, 72.295800099522609, 60.896080650849136, 51.503799996591546, 43.895859429719906, 95.830896247947933, 67.974543525135303, 53.779403711744926, 72.342211502552516]\n",
      "ADAS means: 0.532511362105, 64.4973521242\n",
      "\n",
      "MMSE corr: [0.48085545186748596, 0.46072877924673727, 0.4576762726218831, 0.45657565887311136, 0.45516869779664976, 0.44546524724649522, 0.26952780500860996, 0.42059680391658666, 0.47235630106116577, 0.37215395416036906]\n",
      "MMSE mse: [5.6812780784361516, 5.5268505273065589, 5.3315840348314998, 6.2717487010627107, 5.8659336014421486, 5.8587104805557617, 7.9611724175712011, 5.5613612708417728, 5.0962414624342012, 6.5483450078306911]\n",
      "MMSE means: 0.42911049718, 5.97032255823\n",
      "\n",
      "opt_hyp: {1: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 2: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 3: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 4: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 5: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 6: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 7: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 8: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 9: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 10: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}}\n",
      "\n",
      "opt_snap: {1: 4, 2: 4, 3: 3, 4: 3, 5: 4, 6: 4, 7: 2, 8: 4, 9: 5, 10: 4}\n",
      "Weights Tuned for: mmse\n",
      "Clinical_Scale: BOTH\n",
      "ADAS corr: [0.51965352518093022, 0.54560523578529063, 0.44208592161952404, 0.58295392398607526, 0.58947870471460995, 0.65072537722342538, 0.36680928902938753, 0.47254523365021445, 0.5165227867903287, 0.45618026785461124]\n",
      "ADAS mse: [66.404970546932091, 62.487979233456969, 73.857967396746602, 66.422805641785558, 51.503799996591546, 47.175043582872355, 95.830896247947933, 68.795557145889518, 59.533119277317454, 82.99110865696413]\n",
      "ADAS means: 0.514256026583, 67.5003247727\n",
      "\n",
      "MMSE corr: [0.47716801783493662, 0.46072877924673727, 0.48700191829844874, 0.48528818951552272, 0.45516869779664976, 0.46131475413440104, 0.26952780500860996, 0.40967224245503236, 0.51073756638859003, 0.39937037594449065]\n",
      "MMSE mse: [5.5849059632133278, 5.5268505273065589, 5.164828378265657, 6.0618772266932295, 5.8659336014421486, 5.8252656369021789, 7.9611724175712011, 5.4716744156146397, 4.8189353169725653, 6.4049587740331013]\n",
      "MMSE means: 0.441597834662, 5.8686402258\n",
      "\n",
      "opt_hyp: {1: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 2: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 3: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 4: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 5: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 6: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 7: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 8: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 9: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 10: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}}\n",
      "\n",
      "opt_snap: {1: 2, 2: 4, 3: 5, 4: 7, 5: 4, 6: 8, 7: 2, 8: 3, 9: 9, 10: 9}\n",
      "Exp13_MC 2 HC\n",
      "Weights Tuned for: both\n",
      "Clinical_Scale: BOTH\n",
      "ADAS corr: [0.53057019618129342, 0.56425192089183274, 0.60658461324949153, 0.51923175416957978, 0.61970631177513791, 0.57062292743011389, 0.47118487245732132, 0.50229105723061973, 0.43954115090136991, 0.51899966620783033]\n",
      "ADAS mse: [64.551849250248694, 67.724178249885313, 60.263046511581138, 54.417746291067814, 49.531852278140285, 69.059075783456478, 78.144385161120127, 67.397359396618867, 75.875891393064123, 64.834320234813134]\n",
      "ADAS means: 0.534298447049, 65.179970455\n",
      "\n",
      "MMSE corr: [0.41858785062839565, 0.43041448554552503, 0.46086036120750734, 0.40035291196255768, 0.49336457806093675, 0.4323805330607019, 0.31310969073588224, 0.3782602262741368, 0.48213792461996502, 0.29667583495441952]\n",
      "MMSE mse: [6.439125258379149, 6.2501284864559672, 5.6346079291143871, 6.3393218812290177, 4.6777181652633528, 5.5252390277962471, 7.3507232269022813, 6.5457628816151443, 6.2011930694620272, 7.1127980801621948]\n",
      "MMSE means: 0.410614439705, 6.20766180064\n",
      "\n",
      "opt_hyp: {1: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 2: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 3: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 4: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 5: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 6: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 7: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 8: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 9: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 10: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}}\n",
      "\n",
      "opt_snap: {1: 1, 2: 2, 3: 2, 4: 2, 5: 2, 6: 2, 7: 1, 8: 2, 9: 2, 10: 2}\n",
      "Weights Tuned for: adas\n",
      "Clinical_Scale: BOTH\n",
      "ADAS corr: [0.53057019618129342, 0.56425192089183274, 0.60658461324949153, 0.51923175416957978, 0.61970631177513791, 0.57062292743011389, 0.47908993217879925, 0.50229105723061973, 0.44228628152099508, 0.53329588903021885]\n",
      "ADAS mse: [64.551849250248694, 67.724178249885313, 60.263046511581138, 54.417746291067814, 49.531852278140285, 69.059075783456478, 77.460600307217518, 67.397359396618867, 75.552219612943347, 64.735901610405577]\n",
      "ADAS means: 0.536793088366, 65.0693829292\n",
      "\n",
      "MMSE corr: [0.41858785062839565, 0.43041448554552503, 0.46086036120750734, 0.40035291196255768, 0.49336457806093675, 0.4323805330607019, 0.16421637653002963, 0.3782602262741368, 0.43776529833825656, 0.21120954187612592]\n",
      "MMSE mse: [6.439125258379149, 6.2501284864559672, 5.6346079291143871, 6.3393218812290177, 4.6777181652633528, 5.5252390277962471, 8.2056137455244578, 6.5457628816151443, 6.5869656525207567, 7.8636622906610993]\n",
      "MMSE means: 0.382741216348, 6.40681453186\n",
      "\n",
      "opt_hyp: {1: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 2: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 3: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 4: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 5: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 6: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 7: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 8: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 9: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 10: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}}\n",
      "\n",
      "opt_snap: {1: 1, 2: 2, 3: 2, 4: 2, 5: 2, 6: 2, 7: 0, 8: 2, 9: 1, 10: 1}\n",
      "Weights Tuned for: mmse\n",
      "Clinical_Scale: BOTH\n",
      "ADAS corr: [0.49345629312294481, 0.53549087888731117, 0.56831117919666241, 0.51146607431010049, 0.62017643437598158, 0.55049599523034409, 0.40423556145644257, 0.47957427834645722, 0.42561463913858777, 0.51115717740211486]\n",
      "ADAS mse: [72.137021127700265, 73.134581382086495, 65.485187321032555, 60.310189917191998, 50.952717336652142, 72.24963994902015, 88.164823461086925, 74.480779456464518, 86.553993791710042, 74.388010996516542]\n",
      "ADAS means: 0.509997851147, 71.7856944739\n",
      "\n",
      "MMSE corr: [0.45895686009703912, 0.43168285186209937, 0.48108933951102262, 0.49254196215620188, 0.4914592844302888, 0.43904423146514848, 0.35844412004264992, 0.41514351655794218, 0.4973441259263468, 0.40486589003020712]\n",
      "MMSE mse: [6.1224064353470347, 6.2452233090045697, 5.5188817968897057, 5.2419986435456547, 4.6458288442162265, 5.5168819744071165, 6.7737383742179231, 6.4496327604436159, 6.2006463029120047, 6.3257426411570821]\n",
      "MMSE means: 0.447057218208, 5.90409810821\n",
      "\n",
      "opt_hyp: {1: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 2: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 3: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 4: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 5: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 6: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 7: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 8: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 9: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 10: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}}\n",
      "\n",
      "opt_snap: {1: 3, 2: 3, 3: 4, 4: 7, 5: 1, 6: 3, 7: 4, 8: 8, 9: 3, 10: 9}\n",
      "Exp13_MC 3 HC\n",
      "Weights Tuned for: both\n",
      "Clinical_Scale: BOTH\n",
      "ADAS corr: [0.54451865158047674, 0.63307347297587202, 0.54365009332768821, 0.49685899095818797, 0.51797859549005965, 0.52395928635771394, 0.48896828279430277, 0.47509949936543849, 0.60970793567255699, 0.62542099958875519]\n",
      "ADAS mse: [50.989401300706383, 46.559250996980886, 64.878123260747657, 74.869045429378232, 67.776773602204855, 70.056640213542423, 75.257369172713467, 69.760249348595622, 70.840417279642793, 47.413612584380381]\n",
      "ADAS means: 0.545923580811, 63.8400883189\n",
      "\n",
      "MMSE corr: [0.53928337011106309, 0.47731995791136145, 0.39880283135927652, 0.41991098279256789, 0.37430728721696077, 0.5711862812895947, 0.36359958465854281, 0.38979195142612011, 0.43073797717487644, 0.47304298535747369]\n",
      "MMSE mse: [5.5613273775285421, 5.5859201677422536, 6.1157949882609515, 5.8160966373587302, 6.31393527356781, 5.0170887157736725, 6.7063457406597111, 6.503444134455596, 6.0936817470358626, 5.1043121974823471]\n",
      "MMSE means: 0.44379832093, 5.88179469799\n",
      "\n",
      "opt_hyp: {1: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 2: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 3: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 4: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 5: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 6: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 7: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 8: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 9: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 10: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}}\n",
      "\n",
      "opt_snap: {1: 3, 2: 4, 3: 3, 4: 4, 5: 3, 6: 7, 7: 7, 8: 5, 9: 4, 10: 3}\n",
      "Weights Tuned for: adas\n",
      "Clinical_Scale: BOTH\n",
      "ADAS corr: [0.54451865158047674, 0.63307347297587202, 0.54365009332768821, 0.49685899095818797, 0.51797859549005965, 0.52395928635771394, 0.48582350031974053, 0.47509949936543849, 0.60970793567255699, 0.62542099958875519]\n",
      "ADAS mse: [50.989401300706383, 46.559250996980886, 64.878123260747657, 74.869045429378232, 67.776773602204855, 70.056640213542423, 75.184357997067565, 69.760249348595622, 70.840417279642793, 47.413612584380381]\n",
      "ADAS means: 0.545609102564, 63.8327872013\n",
      "\n",
      "MMSE corr: [0.53928337011106309, 0.47731995791136145, 0.39880283135927652, 0.41991098279256789, 0.37430728721696077, 0.5711862812895947, 0.35752101185829749, 0.38979195142612011, 0.43073797717487644, 0.47304298535747369]\n",
      "MMSE mse: [5.5613273775285421, 5.5859201677422536, 6.1157949882609515, 5.8160966373587302, 6.31393527356781, 5.0170887157736725, 6.8048080928456605, 6.503444134455596, 6.0936817470358626, 5.1043121974823471]\n",
      "MMSE means: 0.44319046365, 5.89164093321\n",
      "\n",
      "opt_hyp: {1: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 2: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 3: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 4: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 5: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 6: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 7: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 8: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 9: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 10: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}}\n",
      "\n",
      "opt_snap: {1: 3, 2: 4, 3: 3, 4: 4, 5: 3, 6: 7, 7: 6, 8: 5, 9: 4, 10: 3}\n",
      "Weights Tuned for: mmse\n",
      "Clinical_Scale: BOTH\n",
      "ADAS corr: [0.54729605247479352, 0.59643225190883142, 0.54365009332768821, 0.49942375423413327, 0.50641201278557224, 0.52395928635771394, 0.48723176333510504, 0.48062502993206441, 0.60970793567255699, 0.61490917783574561]\n",
      "ADAS mse: [51.506463175651916, 52.401924770177253, 64.878123260747657, 78.191534613057456, 70.31343666721088, 70.056640213542423, 76.238715198147176, 77.257460862292376, 70.840417279642793, 49.189988877909677]\n",
      "ADAS means: 0.540964735786, 66.0874704918\n",
      "\n",
      "MMSE corr: [0.53422878429255971, 0.50933153260818909, 0.39880283135927652, 0.45082144988547174, 0.38006566988484775, 0.5711862812895947, 0.36650175930967938, 0.42392918333603602, 0.43073797717487644, 0.5008529656823103]\n",
      "MMSE mse: [5.5457021051275506, 5.3961764845297546, 6.1157949882609515, 5.6932299610476802, 6.28175448179074, 5.0170887157736725, 6.6631944528268034, 6.1762281706039595, 6.0936817470358626, 4.9537497304250939]\n",
      "MMSE means: 0.456645843482, 5.79366008374\n",
      "\n",
      "opt_hyp: {1: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 2: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 3: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 4: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 5: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 6: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 7: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 8: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 9: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 10: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}}\n",
      "\n",
      "opt_snap: {1: 4, 2: 8, 3: 3, 4: 8, 5: 4, 6: 7, 7: 8, 8: 8, 9: 4, 10: 5}\n",
      "Exp13_MC 4 HC\n",
      "Weights Tuned for: both\n",
      "Clinical_Scale: BOTH\n",
      "ADAS corr: [0.53435150163254841, 0.55826220061671583, 0.53317569338226167, 0.46798048443853674, 0.57729020100261164, 0.49734587063016666, 0.60163094852297649, 0.58944748679464443, 0.56568744178039543, 0.50430422835488087]\n",
      "ADAS mse: [69.399689241159393, 54.697436166468194, 76.073741610017976, 75.812778636712252, 59.237364896149785, 66.585483701116686, 56.316951452694035, 59.435010059835498, 55.566585522653845, 61.496670508493516]\n",
      "ADAS means: 0.542947605716, 63.4621711795\n",
      "\n",
      "MMSE corr: [0.54403473662696866, 0.45324754916684623, 0.40848051972336308, 0.31883124308498939, 0.45977931407041878, 0.40795918418473887, 0.47819670678539006, 0.48430703146469284, 0.38784922427201529, 0.41188865051609497]\n",
      "MMSE mse: [5.1867888963631801, 5.0204073485006315, 5.999909869251101, 6.4823759565490544, 6.2805613284334116, 6.6235500876062572, 6.2727018993433887, 6.2672989081925623, 5.8115829790355811, 5.5541581899379615]\n",
      "MMSE means: 0.43545741599, 5.94993354632\n",
      "\n",
      "opt_hyp: {1: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 2: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 3: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 4: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 5: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 6: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 7: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 8: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 9: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 10: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}}\n",
      "\n",
      "opt_snap: {1: 4, 2: 4, 3: 7, 4: 2, 5: 4, 6: 3, 7: 3, 8: 4, 9: 4, 10: 6}\n",
      "Weights Tuned for: adas\n",
      "Clinical_Scale: BOTH\n",
      "ADAS corr: [0.53435150163254841, 0.55826220061671583, 0.53317569338226167, 0.46798048443853674, 0.57729020100261164, 0.49734587063016666, 0.60163094852297649, 0.58944748679464443, 0.56568744178039543, 0.50430422835488087]\n",
      "ADAS mse: [69.399689241159393, 54.697436166468194, 76.073741610017976, 75.812778636712252, 59.237364896149785, 66.585483701116686, 56.316951452694035, 59.435010059835498, 55.566585522653845, 61.496670508493516]\n",
      "ADAS means: 0.542947605716, 63.4621711795\n",
      "\n",
      "MMSE corr: [0.54403473662696866, 0.45324754916684623, 0.40848051972336308, 0.31883124308498939, 0.45977931407041878, 0.40795918418473887, 0.47819670678539006, 0.48430703146469284, 0.38784922427201529, 0.41188865051609497]\n",
      "MMSE mse: [5.1867888963631801, 5.0204073485006315, 5.999909869251101, 6.4823759565490544, 6.2805613284334116, 6.6235500876062572, 6.2727018993433887, 6.2672989081925623, 5.8115829790355811, 5.5541581899379615]\n",
      "MMSE means: 0.43545741599, 5.94993354632\n",
      "\n",
      "opt_hyp: {1: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 2: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 3: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 4: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 5: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 6: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 7: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 8: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 9: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 10: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}}\n",
      "\n",
      "opt_snap: {1: 4, 2: 4, 3: 7, 4: 2, 5: 4, 6: 3, 7: 3, 8: 4, 9: 4, 10: 6}\n",
      "Weights Tuned for: mmse\n",
      "Clinical_Scale: BOTH\n",
      "ADAS corr: [0.53668838352282844, 0.55826220061671583, 0.52953205911501788, 0.40371809787613766, 0.57471560379600928, 0.43232247452842171, 0.58782108515974851, 0.57767331508015618, 0.56568744178039543, 0.50430422835488087]\n",
      "ADAS mse: [69.763368859645055, 54.697436166468194, 76.275048137330415, 87.446411760027047, 59.359587308368837, 72.25568214903312, 61.509062534317515, 61.349152272330223, 55.566585522653845, 61.496670508493516]\n",
      "ADAS means: 0.527072488983, 65.9719005219\n",
      "\n",
      "MMSE corr: [0.54913013497204366, 0.45324754916684623, 0.40323702265778255, 0.38029277619132318, 0.46124721695776622, 0.42457079292025884, 0.5033212141529656, 0.49204976993172134, 0.38784922427201529, 0.41188865051609497]\n",
      "MMSE mse: [5.1843430810702351, 5.0204073485006315, 5.9469688370010534, 6.1185650425218991, 6.2741037399617889, 6.4188712440781384, 6.1215928934254213, 6.1762503902455546, 5.8115829790355811, 5.5541581899379615]\n",
      "MMSE means: 0.446683435174, 5.86268437458\n",
      "\n",
      "opt_hyp: {1: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 2: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 3: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 4: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 5: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 6: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 7: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 8: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 9: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 10: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}}\n",
      "\n",
      "opt_snap: {1: 5, 2: 4, 3: 6, 4: 8, 5: 5, 6: 1, 7: 7, 8: 5, 9: 4, 10: 6}\n",
      "Exp13_MC 5 HC\n",
      "Weights Tuned for: both\n",
      "Clinical_Scale: BOTH\n",
      "ADAS corr: [0.55508080118397141, 0.54407987947363912, 0.59023946606156463, 0.55946293346438014, 0.4504625600116216, 0.48168929365174035, 0.47626726370019662, 0.52180268443537636, 0.53426870226911749, 0.63226094017583145]\n",
      "ADAS mse: [59.292663498598664, 59.134158145067147, 58.198056238375123, 69.737717973220242, 57.266427069407335, 80.162406915598268, 69.865987118067324, 68.702974408842906, 70.496273642831895, 53.644393212695064]\n",
      "ADAS means: 0.534561452443, 64.6501058223\n",
      "\n",
      "MMSE corr: [0.50468767881723464, 0.47563326427941222, 0.45908913588229794, 0.48428561015078514, 0.42213089419630484, 0.3140252527211867, 0.38465909251160196, 0.44401080780830104, 0.47315012432053072, 0.34983330879242808]\n",
      "MMSE mse: [5.7518039663384197, 5.5143454048662219, 5.1585991131346614, 5.6202102953676549, 5.67516612379075, 7.1573127852378038, 6.0542466964607637, 6.1777359655002533, 6.7208781560384656, 6.3680288899144815]\n",
      "MMSE means: 0.431150516948, 6.01983273966\n",
      "\n",
      "opt_hyp: {1: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 2: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 3: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 4: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 5: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 6: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 7: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 8: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 9: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 10: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}}\n",
      "\n",
      "opt_snap: {1: 3, 2: 3, 3: 3, 4: 6, 5: 2, 6: 5, 7: 6, 8: 5, 9: 5, 10: 5}\n",
      "Weights Tuned for: adas\n",
      "Clinical_Scale: BOTH\n",
      "ADAS corr: [0.53933248673010725, 0.54407987947363912, 0.59023946606156463, 0.55946293346438014, 0.4504625600116216, 0.48168929365174035, 0.47626726370019662, 0.52180268443537636, 0.53426870226911749, 0.63226094017583145]\n",
      "ADAS mse: [59.262057359412459, 59.134158145067147, 58.198056238375123, 69.737717973220242, 57.266427069407335, 80.162406915598268, 69.865987118067324, 68.702974408842906, 70.496273642831895, 53.644393212695064]\n",
      "ADAS means: 0.532986620997, 64.6470452084\n",
      "\n",
      "MMSE corr: [0.44291453909098843, 0.47563326427941222, 0.45908913588229794, 0.48428561015078514, 0.42213089419630484, 0.3140252527211867, 0.38465909251160196, 0.44401080780830104, 0.47315012432053072, 0.34983330879242808]\n",
      "MMSE mse: [6.0167042767406196, 5.5143454048662219, 5.1585991131346614, 5.6202102953676549, 5.67516612379075, 7.1573127852378038, 6.0542466964607637, 6.1777359655002533, 6.7208781560384656, 6.3680288899144815]\n",
      "MMSE means: 0.424973202975, 6.04632277071\n",
      "\n",
      "opt_hyp: {1: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 2: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 3: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 4: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 5: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 6: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 7: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 8: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 9: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 10: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}}\n",
      "\n",
      "opt_snap: {1: 2, 2: 3, 3: 3, 4: 6, 5: 2, 6: 5, 7: 6, 8: 5, 9: 5, 10: 5}\n",
      "Weights Tuned for: mmse\n",
      "Clinical_Scale: BOTH\n",
      "ADAS corr: [0.51374042936305331, 0.55408146542518599, 0.59023946606156463, 0.56298869099072413, 0.4504625600116216, 0.47556504060099714, 0.47109346771914329, 0.50779235765728281, 0.51576305819257529, 0.5732541166546764]\n",
      "ADAS mse: [68.053152131152004, 59.346361633260763, 58.198056238375123, 70.288923238725801, 57.266427069407335, 82.949305081399871, 71.554784584056989, 78.74203041372661, 71.368785602125712, 61.496735849199112]\n",
      "ADAS means: 0.521498065268, 67.9264561841\n",
      "\n",
      "MMSE corr: [0.53835468783274198, 0.49098054537623886, 0.45908913588229794, 0.48519683756562271, 0.42213089419630484, 0.33737272630808185, 0.38661765289512762, 0.46794288547318935, 0.47861254633303763, 0.33652895199783389]\n",
      "MMSE mse: [5.4891576591315161, 5.4194542108732051, 5.1585991131346614, 5.5768626881567895, 5.67516612379075, 7.0852474747995231, 6.0296103835263146, 5.8681747222295026, 6.5864069654475914, 6.312368131880925]\n",
      "MMSE means: 0.440282686386, 5.9201047473\n",
      "\n",
      "opt_hyp: {1: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 2: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 3: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 4: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 5: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 6: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 7: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 8: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 9: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 10: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}}\n",
      "\n",
      "opt_snap: {1: 6, 2: 4, 3: 3, 4: 5, 5: 2, 6: 7, 7: 7, 8: 8, 9: 3, 10: 9}\n",
      "Exp13_MC 6 HC\n",
      "Weights Tuned for: both\n",
      "Clinical_Scale: BOTH\n",
      "ADAS corr: [0.46448993475015105, 0.52698060681107906, 0.56430550372316723, 0.5972631633489377, 0.55896336283656789, 0.54958083197158003, 0.54471987081973794, 0.54415614220173947, 0.61043709518284639, 0.45653721238654815]\n",
      "ADAS mse: [74.125379541912864, 64.500054321721009, 49.548507533487516, 58.193674166858308, 73.030273215938422, 63.946814129707676, 69.57714289928866, 70.305636067751237, 46.16392524989719, 68.854929061664848]\n",
      "ADAS means: 0.541743372403, 63.8246336188\n",
      "\n",
      "MMSE corr: [0.34536868104643098, 0.39483783608366091, 0.33867488608945828, 0.47275022377072667, 0.45339732352547324, 0.51244100260482595, 0.43512065917227477, 0.41733762555749787, 0.51694042378485361, 0.46610885795837709]\n",
      "MMSE mse: [6.3615263801341522, 5.82398750222118, 6.2321912541420996, 5.9206889177289703, 6.6709387051395135, 5.0125485266573966, 5.8853191613152243, 6.7474490466224166, 5.3987613231269949, 5.3814882730211027]\n",
      "MMSE means: 0.435297751959, 5.94348990901\n",
      "\n",
      "opt_hyp: {1: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 2: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 3: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 4: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 5: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 6: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 7: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 8: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 9: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 10: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}}\n",
      "\n",
      "opt_snap: {1: 2, 2: 5, 3: 2, 4: 5, 5: 5, 6: 3, 7: 4, 8: 5, 9: 5, 10: 4}\n",
      "Weights Tuned for: adas\n",
      "Clinical_Scale: BOTH\n",
      "ADAS corr: [0.46448993475015105, 0.52698060681107906, 0.56430550372316723, 0.5972631633489377, 0.55896336283656789, 0.54958083197158003, 0.54471987081973794, 0.54415614220173947, 0.61043709518284639, 0.45653721238654815]\n",
      "ADAS mse: [74.125379541912864, 64.500054321721009, 49.548507533487516, 58.193674166858308, 73.030273215938422, 63.946814129707676, 69.57714289928866, 70.305636067751237, 46.16392524989719, 68.854929061664848]\n",
      "ADAS means: 0.541743372403, 63.8246336188\n",
      "\n",
      "MMSE corr: [0.34536868104643098, 0.39483783608366091, 0.33867488608945828, 0.47275022377072667, 0.45339732352547324, 0.51244100260482595, 0.43512065917227477, 0.41733762555749787, 0.51694042378485361, 0.46610885795837709]\n",
      "MMSE mse: [6.3615263801341522, 5.82398750222118, 6.2321912541420996, 5.9206889177289703, 6.6709387051395135, 5.0125485266573966, 5.8853191613152243, 6.7474490466224166, 5.3987613231269949, 5.3814882730211027]\n",
      "MMSE means: 0.435297751959, 5.94348990901\n",
      "\n",
      "opt_hyp: {1: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 2: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 3: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 4: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 5: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 6: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 7: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 8: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 9: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 10: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}}\n",
      "\n",
      "opt_snap: {1: 2, 2: 5, 3: 2, 4: 5, 5: 5, 6: 3, 7: 4, 8: 5, 9: 5, 10: 4}\n",
      "Weights Tuned for: mmse\n",
      "Clinical_Scale: BOTH\n",
      "ADAS corr: [0.46448993475015105, 0.52698060681107906, 0.54175685775281124, 0.58459205190138075, 0.54577628670941769, 0.55255079885563951, 0.53971500187645172, 0.55167722077605497, 0.61043709518284639, 0.42420165269513727]\n",
      "ADAS mse: [74.125379541912864, 64.500054321721009, 53.013976893038915, 60.208244996635436, 75.725686270450581, 64.759537674109026, 70.910419460142137, 72.205518878392425, 46.16392524989719, 77.415446353109616]\n",
      "ADAS means: 0.534217750731, 65.9028189639\n",
      "\n",
      "MMSE corr: [0.34536868104643098, 0.39483783608366091, 0.36815256113946671, 0.47697814710510139, 0.45480166204566624, 0.5185898410176738, 0.45516959331583734, 0.43420452956506689, 0.51694042378485361, 0.50855050525145318]\n",
      "MMSE mse: [6.3615263801341522, 5.82398750222118, 6.1736228761853811, 5.8917604498361786, 6.6031005173076833, 4.9857323102675553, 5.763402513111969, 6.6906112835038778, 5.3987613231269949, 4.9022897567987718]\n",
      "MMSE means: 0.447359378036, 5.85947949125\n",
      "\n",
      "opt_hyp: {1: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 2: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 3: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 4: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 5: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 6: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 7: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 8: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 9: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 10: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}}\n",
      "\n",
      "opt_snap: {1: 2, 2: 5, 3: 4, 4: 6, 5: 7, 6: 4, 7: 6, 8: 8, 9: 5, 10: 9}\n",
      "Exp13_MC 7 HC\n",
      "Weights Tuned for: both\n",
      "Clinical_Scale: BOTH\n",
      "ADAS corr: [0.59143790997964629, 0.5575720958188477, 0.55091860723339381, 0.56096406699094248, 0.53008735702265752, 0.53747521824619315, 0.51494760235676129, 0.53091910196083936, 0.45594512920693958, 0.55207676273684358]\n",
      "ADAS mse: [53.38775228287686, 60.150767193189495, 62.755955535976909, 67.876663608035955, 61.12836133575972, 65.140952339008408, 66.560424560124403, 66.788807129230719, 71.829056374289721, 65.11768088304629]\n",
      "ADAS means: 0.538234385155, 64.0736421242\n",
      "\n",
      "MMSE corr: [0.49293337139612697, 0.40755763682413781, 0.46930051143824475, 0.4167511822635741, 0.49337980418554095, 0.41869538689715469, 0.48734913054026574, 0.42184382251308744, 0.42230139085502028, 0.38727927269926116]\n",
      "MMSE mse: [4.7197062551198767, 6.3961625415314316, 5.7231078357046128, 6.5684862620586051, 5.0897501151200242, 6.5165122080428883, 4.8946863626879074, 6.5381881753083189, 5.7760568700895849, 6.7528038981407388]\n",
      "MMSE means: 0.441739150961, 5.89754605238\n",
      "\n",
      "opt_hyp: {1: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 2: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 3: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 4: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 5: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 6: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 7: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 8: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 9: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 10: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}}\n",
      "\n",
      "opt_snap: {1: 4, 2: 4, 3: 2, 4: 4, 5: 4, 6: 5, 7: 4, 8: 4, 9: 3, 10: 5}\n",
      "Weights Tuned for: adas\n",
      "Clinical_Scale: BOTH\n",
      "ADAS corr: [0.59143790997964629, 0.5575720958188477, 0.55091860723339381, 0.56096406699094248, 0.53008735702265752, 0.53334953178797628, 0.51494760235676129, 0.53091910196083936, 0.45594512920693958, 0.55207676273684358]\n",
      "ADAS mse: [53.38775228287686, 60.150767193189495, 62.755955535976909, 67.876663608035955, 61.12836133575972, 65.120964294279119, 66.560424560124403, 66.788807129230719, 71.829056374289721, 65.11768088304629]\n",
      "ADAS means: 0.537821816509, 64.0716433197\n",
      "\n",
      "MMSE corr: [0.49293337139612697, 0.40755763682413781, 0.46930051143824475, 0.4167511822635741, 0.49337980418554095, 0.39722148145185704, 0.48734913054026574, 0.42184382251308744, 0.42230139085502028, 0.38727927269926116]\n",
      "MMSE mse: [4.7197062551198767, 6.3961625415314316, 5.7231078357046128, 6.5684862620586051, 5.0897501151200242, 6.6541342750207582, 4.8946863626879074, 6.5381881753083189, 5.7760568700895849, 6.7528038981407388]\n",
      "MMSE means: 0.439591760417, 5.91130825908\n",
      "\n",
      "opt_hyp: {1: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 2: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 3: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 4: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 5: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 6: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 7: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 8: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 9: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 10: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}}\n",
      "\n",
      "opt_snap: {1: 4, 2: 4, 3: 2, 4: 4, 5: 4, 6: 4, 7: 4, 8: 4, 9: 3, 10: 5}\n",
      "Weights Tuned for: mmse\n",
      "Clinical_Scale: BOTH\n",
      "ADAS corr: [0.59143790997964629, 0.55752247515668951, 0.55091860723339381, 0.55372644152483264, 0.48710458000607082, 0.525015883652312, 0.51494760235676129, 0.51221557082985758, 0.46145139796891327, 0.55207676273684358]\n",
      "ADAS mse: [53.38775228287686, 61.954333436277089, 62.755955535976909, 68.80804656456263, 68.205288474817053, 67.115277874360501, 66.560424560124403, 71.582149869505059, 72.845371395157969, 65.11768088304629]\n",
      "ADAS means: 0.530641723145, 65.8332280877\n",
      "\n",
      "MMSE corr: [0.49293337139612697, 0.42747866046763772, 0.46930051143824475, 0.4263346512560483, 0.52871318111128207, 0.44088212264839305, 0.48734913054026574, 0.43214026983403669, 0.43250039800609974, 0.38727927269926116]\n",
      "MMSE mse: [4.7197062551198767, 6.3245606040287328, 5.7231078357046128, 6.5234766055625197, 4.8075590247230613, 6.3770758011471704, 4.8946863626879074, 6.5347911991068113, 5.7539612966673825, 6.7528038981407388]\n",
      "MMSE means: 0.45249115694, 5.84117288829\n",
      "\n",
      "opt_hyp: {1: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 2: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 3: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 4: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 5: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 6: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 7: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 8: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 9: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 10: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}}\n",
      "\n",
      "opt_snap: {1: 4, 2: 6, 3: 2, 4: 5, 5: 8, 6: 7, 7: 4, 8: 7, 9: 4, 10: 5}\n",
      "Exp13_MC 8 HC\n",
      "Weights Tuned for: both\n",
      "Clinical_Scale: BOTH\n",
      "ADAS corr: [0.52717326059951986, 0.61367343045776446, 0.57084279986713971, 0.57969549092362782, 0.28147601669931793, 0.58944611805299552, 0.52392754907460548, 0.62477101523834577, 0.50660106169720998, 0.36954109878938829]\n",
      "ADAS mse: [68.929238352501145, 52.045040971193274, 69.125493895164595, 67.65466336948171, 64.772998082585019, 60.257589972579993, 63.407056385118537, 60.968303438385298, 57.791103157563917, 79.502779899538851]\n",
      "ADAS means: 0.51871478414, 64.4454267524\n",
      "\n",
      "MMSE corr: [0.46384163917960675, 0.52537798148505788, 0.39294817418159755, 0.47039965481246893, 0.25335652436765638, 0.47694722422628483, 0.32783346180497924, 0.54758374987297387, 0.483075204839158, 0.34925929805993106]\n",
      "MMSE mse: [6.0058828096444952, 5.2795802581261251, 6.7722925136807044, 6.597499574335834, 6.4470580035733134, 5.8220297257081954, 6.4254705371893222, 4.9552296686399213, 5.5675692300128299, 5.3495876050824576]\n",
      "MMSE means: 0.429062291283, 5.9222199926\n",
      "\n",
      "opt_hyp: {1: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 2: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 3: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 4: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 5: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 6: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 7: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 8: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 9: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 10: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}}\n",
      "\n",
      "opt_snap: {1: 5, 2: 5, 3: 6, 4: 5, 5: 1, 6: 4, 7: 3, 8: 5, 9: 4, 10: 3}\n",
      "Weights Tuned for: adas\n",
      "Clinical_Scale: BOTH\n",
      "ADAS corr: [0.52717326059951986, 0.61367343045776446, 0.57084279986713971, 0.57969549092362782, 0.28147601669931793, 0.58944611805299552, 0.52392754907460548, 0.62477101523834577, 0.50660106169720998, 0.35739184446830596]\n",
      "ADAS mse: [68.929238352501145, 52.045040971193274, 69.125493895164595, 67.65466336948171, 64.772998082585019, 60.257589972579993, 63.407056385118537, 60.968303438385298, 57.791103157563917, 79.385698832164167]\n",
      "ADAS means: 0.517499858708, 64.4337186457\n",
      "\n",
      "MMSE corr: [0.46384163917960675, 0.52537798148505788, 0.39294817418159755, 0.47039965481246893, 0.25335652436765638, 0.47694722422628483, 0.32783346180497924, 0.54758374987297387, 0.483075204839158, 0.31038950283826561]\n",
      "MMSE mse: [6.0058828096444952, 5.2795802581261251, 6.7722925136807044, 6.597499574335834, 6.4470580035733134, 5.8220297257081954, 6.4254705371893222, 4.9552296686399213, 5.5675692300128299, 5.5157106051595575]\n",
      "MMSE means: 0.425175311761, 5.93883229261\n",
      "\n",
      "opt_hyp: {1: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 2: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 3: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 4: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 5: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 6: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 7: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 8: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 9: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 10: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}}\n",
      "\n",
      "opt_snap: {1: 5, 2: 5, 3: 6, 4: 5, 5: 1, 6: 4, 7: 3, 8: 5, 9: 4, 10: 2}\n",
      "Weights Tuned for: mmse\n",
      "Clinical_Scale: BOTH\n",
      "ADAS corr: [0.5285259540157109, 0.5959358478608715, 0.55527136880251671, 0.54940873276315483, 0.33627770588239092, 0.58932365383256113, 0.52392754907460548, 0.62477101523834577, 0.50660106169720998, 0.38265955357201292]\n",
      "ADAS mse: [69.796125209612114, 55.316385592278543, 72.983434699955211, 71.801288945822151, 65.142750797736966, 60.530703488407454, 63.407056385118537, 60.968303438385298, 57.791103157563917, 82.212962056724933]\n",
      "ADAS means: 0.519270244274, 65.9950113772\n",
      "\n",
      "MMSE corr: [0.46824835827945865, 0.55360626357323106, 0.42494854702054413, 0.47299432861262664, 0.31962383849574105, 0.47714072338566538, 0.32783346180497924, 0.54758374987297387, 0.483075204839158, 0.39372122832259127]\n",
      "MMSE mse: [5.9753625596724644, 5.077863948975879, 6.57934295766134, 6.5689283260421254, 6.2125661595078503, 5.8059718207914024, 6.4254705371893222, 4.9552296686399213, 5.5675692300128299, 5.1664727281252665]\n",
      "MMSE means: 0.446877570421, 5.83347779366\n",
      "\n",
      "opt_hyp: {1: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 2: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 3: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 4: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 5: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 6: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 7: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 8: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 9: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 10: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}}\n",
      "\n",
      "opt_snap: {1: 6, 2: 8, 3: 9, 4: 8, 5: 2, 6: 5, 7: 3, 8: 5, 9: 4, 10: 6}\n",
      "Exp13_MC 9 HC\n",
      "Weights Tuned for: both\n",
      "Clinical_Scale: BOTH\n",
      "ADAS corr: [0.53999660196387889, 0.4936876808482733, 0.46956623746052073, 0.57338532626521099, 0.61954434762113508, 0.54217454018156863, 0.55112298928830095, 0.49332240265811311, 0.58740601802761472, 0.51622263910643362]\n",
      "ADAS mse: [62.564440644478154, 80.394190492242743, 80.478741259292363, 50.333331440328656, 43.468889133666025, 77.074172105204326, 52.791075822224073, 63.849839669032008, 62.510255527714442, 67.155730724601042]\n",
      "ADAS means: 0.538642878342, 64.0620666819\n",
      "\n",
      "MMSE corr: [0.40599715217845855, 0.39144217236481821, 0.42126680249065551, 0.52366121339338123, 0.43193811917765457, 0.48875743429296947, 0.36537651432757617, 0.40603554037556422, 0.4986176214933648, 0.46462495254533709]\n",
      "MMSE mse: [5.7285852870407314, 8.0467179892831702, 6.2862209072467046, 4.1781308591298574, 5.2555754192748232, 5.871309210443167, 6.1796945380822343, 6.131050548386658, 5.6925846707415619, 5.5563413842604028]\n",
      "MMSE means: 0.439771752264, 5.89262108139\n",
      "\n",
      "opt_hyp: {1: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 2: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 3: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 4: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 5: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 6: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 7: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 8: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 9: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 10: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}}\n",
      "\n",
      "opt_snap: {1: 7, 2: 8, 3: 4, 4: 4, 5: 3, 6: 4, 7: 3, 8: 2, 9: 5, 10: 4}\n",
      "Weights Tuned for: adas\n",
      "Clinical_Scale: BOTH\n",
      "ADAS corr: [0.53999660196387889, 0.4936876808482733, 0.46956623746052073, 0.57338532626521099, 0.61954434762113508, 0.54217454018156863, 0.55112298928830095, 0.51168118262780937, 0.58740601802761472, 0.51622263910643362]\n",
      "ADAS mse: [62.564440644478154, 80.394190492242743, 80.478741259292363, 50.333331440328656, 43.468889133666025, 77.074172105204326, 52.791075822224073, 63.841809506338024, 62.510255527714442, 67.155730724601042]\n",
      "ADAS means: 0.540478756339, 64.0612636656\n",
      "\n",
      "MMSE corr: [0.40599715217845855, 0.39144217236481821, 0.42126680249065551, 0.52366121339338123, 0.43193811917765457, 0.48875743429296947, 0.36537651432757617, 0.41014318583607706, 0.4986176214933648, 0.46462495254533709]\n",
      "MMSE mse: [5.7285852870407314, 8.0467179892831702, 6.2862209072467046, 4.1781308591298574, 5.2555754192748232, 5.871309210443167, 6.1796945380822343, 6.1408932124020845, 5.6925846707415619, 5.5563413842604028]\n",
      "MMSE means: 0.44018251681, 5.89360534779\n",
      "\n",
      "opt_hyp: {1: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 2: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 3: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 4: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 5: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 6: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 7: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 8: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 9: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 10: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}}\n",
      "\n",
      "opt_snap: {1: 7, 2: 8, 3: 4, 4: 4, 5: 3, 6: 4, 7: 3, 8: 3, 9: 5, 10: 4}\n",
      "Weights Tuned for: mmse\n",
      "Clinical_Scale: BOTH\n",
      "ADAS corr: [0.44122710936202653, 0.4936876808482733, 0.46956623746052073, 0.57338532626521099, 0.61954434762113508, 0.53465103080644738, 0.55112298928830095, 0.49332240265811311, 0.53797729483575751, 0.52584962038100413]\n",
      "ADAS mse: [69.764660316824504, 80.394190492242743, 80.478741259292363, 50.333331440328656, 43.468889133666025, 77.359591532753043, 52.791075822224073, 63.849839669032008, 70.271352893178175, 70.991414792371472]\n",
      "ADAS means: 0.524033403953, 65.9703087352\n",
      "\n",
      "MMSE corr: [0.37471144278503205, 0.39144217236481821, 0.42126680249065551, 0.52366121339338123, 0.43193811917765457, 0.50458929113923134, 0.36537651432757617, 0.40603554037556422, 0.50468079175639835, 0.54795342801017388]\n",
      "MMSE mse: [5.6137366926890566, 8.0467179892831702, 6.2862209072467046, 4.1781308591298574, 5.2555754192748232, 5.7467362541981801, 6.1796945380822343, 6.131050548386658, 5.643277720045706, 4.911997186852731]\n",
      "MMSE means: 0.447165531582, 5.79931381152\n",
      "\n",
      "opt_hyp: {1: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 2: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 3: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 4: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 5: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 6: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 7: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 8: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 9: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}, 10: {'tr': {'ADAS': 1, 'DX': 1, 'MMSE': 2}, 'node_sizes': {'COMB_ff': 50, 'HC_L_ff': 50, 'code': 600, 'DX_ff': 25, 'ADAS_ff': 25, 'En2': 2000, 'CT_ff': 50, 'HC_CT_ff': 25, 'out': 686, 'MMSE_ff': 25, 'En1': 10000, 'HC_R_ff': 50}, 'dr': {'HC': 0, 'HC_CT': 0, 'COMB': 0, 'CT': 0}, 'solver_conf': {'base_lr': 5e-06, 'wt_decay': 0.001}, 'lr': {'HC': 2, 'COMB': 1, 'CT': 2}}}\n",
      "\n",
      "opt_snap: {1: 2, 2: 8, 3: 4, 4: 4, 5: 3, 6: 5, 7: 3, 8: 2, 9: 8, 10: 9}\n",
      "Exp13_MC 10 HC\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Could not open file /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_10/fold6/train_snaps/Exp13_MC_hyp1_HC_iter_4000.caffemodel",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ee01f0e56f18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0msnap_iter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msnap_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mniter\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msnap_interval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                     \u001b[0mmodel_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseline_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'API/data/MC_{}/fold{}/train_snaps/{}_{}_{}_iter_{}.caffemodel'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexp_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodality\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msnap_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmulti_task\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m                     \u001b[0mencodings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X_out'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                     \u001b[0mencodings_adas13\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencodings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'adas13'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-b83434d9394f>\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(net_file, model_file, data_path, input_nodes, batch_size, encoding_layer, weight_layers, multi_task)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_task\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcaffe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaffe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m#print net.blobs.items()[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Could not open file /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_10/fold6/train_snaps/Exp13_MC_hyp1_HC_iter_4000.caffemodel"
     ]
    }
   ],
   "source": [
    "#Get encodings after training\n",
    "#train_filename_hdf = baseline_dir + 'data/train_CT_C688_normed.h5'\n",
    "#test_filename_hdf = baseline_dir + 'data/test_CT_C688_normed.h5'\n",
    "#fid=2\n",
    "#exp_name = 'Exp11'\n",
    "#niter = 40000\n",
    "# modality = 'HC_CT'\n",
    "start_fold = 1\n",
    "n_folds = 10\n",
    "fid_list = np.arange(start_fold,n_folds+1,1)\n",
    "#preproc = 'no_preproc'\n",
    "#batch_size = 256\n",
    "snap_interval = 4000\n",
    "snap_start = 4000\n",
    "encoding_layer = 'output'\n",
    "weight_layers = 'output'\n",
    "cohort = 'outer_test'\n",
    "#Clinical_Scale = 'ADAS13'\n",
    "\n",
    "MC_list = np.arange(1,11,1)\n",
    "\n",
    "if Clinical_Scale in ['ADAS13', 'MMSE']:\n",
    "    fold_euLoss = {}\n",
    "    fold_r = {}\n",
    "    fold_act_scores = {}\n",
    "    fold_pred_scores = {}\n",
    "elif Clinical_Scale == 'BOTH':\n",
    "    fold_euLoss_adas13 = {}\n",
    "    fold_r_adas13 = {}\n",
    "    fold_act_scores_adas13 = {}\n",
    "    fold_pred_scores_adas13 = {}\n",
    "    fold_euLoss_mmse = {}\n",
    "    fold_r_mmse = {}\n",
    "    fold_act_scores_mmse = {}\n",
    "    fold_pred_scores_mmse = {}\n",
    "    \n",
    "idx = 0  \n",
    "df_perf_dict_adas = {}\n",
    "df_perf_dict_mmse = {}\n",
    "df_perf_dict_adas_tuned = {}\n",
    "df_perf_dict_mmse_tuned = {}\n",
    "df_perf_dict_opt = {}\n",
    "\n",
    "for mc in MC_list:\n",
    "    print exp_name, mc, modality\n",
    "\n",
    "    for hype in hype_configs.keys():      \n",
    "        node_sizes = hype_configs[hype]['node_sizes']\n",
    "        dr = hype_configs[hype]['dr']\n",
    "        lr = hype_configs[hype]['lr']\n",
    "\n",
    "        for fid in fid_list:\n",
    "            test_filename_txt = baseline_dir + 'API/data/MC_{}/fold{}/test_C688.txt'.format(mc,fid)\n",
    "            #test_filename_hdf = baseline_dir + 'API/data/fold{}/outer_test/{}_{}.h5'.format(fid,exp_name,preproc)\n",
    "            #with open(test_filename_txt, 'w') as f:\n",
    "            #        f.write(test_filename_hdf + '\\n')  \n",
    "\n",
    "            test_net_path = baseline_dir + 'API/data/MC_{}/fold{}/ADNI_FF_test.prototxt'.format(mc,fid)\n",
    "            with open(test_net_path, 'w') as f:\n",
    "                if modality == 'HC':\n",
    "                    f.write(str(adninet_ff_HC(test_filename_txt, batch_size, node_sizes,dr,lr,tr,Clinical_Scale)))\n",
    "                    input_nodes = ['X_L_HC','X_R_HC']\n",
    "                elif modality == 'CT':\n",
    "                    f.write(str(adninet_ff_CT(test_filename_txt, batch_size, node_sizes,dr,lr,tr,Clinical_Scale)))\n",
    "                    input_nodes = ['X_CT_SpecCluster_dyn']\n",
    "                elif modality == 'HC_CT':\n",
    "                    f.write(str(adninet_ff_HC_CT(test_filename_txt, batch_size, node_sizes,dr,lr,tr,Clinical_Scale)))\n",
    "                    input_nodes = ['X_L_HC','X_R_HC','X_CT_SpecCluster_dyn']\n",
    "                elif modality == 'HC_CT_unified_hyp1':\n",
    "                    f.write(str(adninet_ff_HC_CT_unified(test_filename_txt, batch_size, node_sizes,dr,lr,tr,Clinical_Scale)))\n",
    "                    input_nodes = ['X_HC_CT']\n",
    "                else:\n",
    "                    print 'Wrong modality'\n",
    "\n",
    "            #print 'Hype # {}, MC # {}, Fold # {}, Clinical_Scale {}'.format(hype, mc, fid, Clinical_Scale)\n",
    "            data_path = baseline_dir + 'API/data/MC_{}/fold{}/{}/{}.h5'.format(mc,fid,cohort,exp_name)\n",
    "            if Clinical_Scale == 'ADAS13':\n",
    "                act_scores = load_data(data_path, 'adas','no_preproc')\n",
    "            elif Clinical_Scale == 'MMSE': \n",
    "                act_scores = load_data(data_path, 'mmse','no_preproc')\n",
    "            elif Clinical_Scale == 'BOTH':\n",
    "                act_scores_adas13 = load_data(data_path, 'adas','no_preproc')\n",
    "                act_scores_mmse = load_data(data_path, 'mmse','no_preproc')\n",
    "            else:\n",
    "                print 'unknown clinical scale'\n",
    "\n",
    "            net_file = baseline_dir + 'API/data/MC_{}/fold{}/ADNI_FF_test.prototxt'.format(mc,fid)\n",
    "            test_filename_hdf = baseline_dir + 'API/data/MC_{}/fold{}/{}/{}.h5'.format(mc,fid,cohort,exp_name)\n",
    "            test_filename_txt = baseline_dir + 'API/data/MC_{}/fold{}/{}_C688.txt'.format(mc,fid,cohort)\n",
    "            with open(test_filename_txt, 'w') as f:\n",
    "                    f.write(test_filename_hdf + '\\n')  \n",
    "\n",
    "            sub.call([\"cp\", baseline_dir + 'API/data/MC_{}/fold{}/{}_C688.txt'.format(mc,fid,cohort), baseline_dir + \n",
    "                      'API/data/MC_{}/fold{}/test_C688.txt'.format(mc,fid)])\n",
    "            #data_path = '/projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/CV_Exp4_ADNI1_ADAS13_NN_valid.h5'\n",
    "            #adas_scores = load_data(data_path, 'Fold_{}_y'.format(fid),'no_preproc')\n",
    "\n",
    "            if Clinical_Scale in ['ADAS13', 'MMSE']:                \n",
    "                multi_task = False\n",
    "                cs_list = ['opt']\n",
    "                iter_euLoss = []\n",
    "                iter_r = []        \n",
    "                iter_pred_scores = []\n",
    "                for snap_iter in np.arange(snap_start,niter+1,snap_interval):\n",
    "                    model_file = baseline_dir + 'API/data/MC_{}/fold{}/train_snaps/{}_{}_{}_iter_{}.caffemodel'.format(mc,fid,exp_name,hype,modality,snap_iter)        \n",
    "                    results = extract_features(net_file, model_file, data_path, input_nodes, batch_size, encoding_layer, weight_layers,multi_task)\n",
    "                    encodings = np.squeeze(results['X_out'])            \n",
    "                    iter_pred_scores.append(np.squeeze(results['X_out']))            \n",
    "                    iter_euLoss.append(0.5*mse(encodings,act_scores))  #This is to be consistent with the caffe loss funtion\n",
    "                    iter_r.append(stats.pearsonr(encodings,act_scores)[0])\n",
    "\n",
    "                config_idx = '{}_{}'.format(hype,fid)\n",
    "                fold_euLoss[config_idx] = np.array(iter_euLoss)\n",
    "                fold_r[config_idx] = np.array(iter_r)\n",
    "                fold_act_scores[fid] = act_scores\n",
    "                fold_pred_scores[config_idx] = np.array(iter_pred_scores)        \n",
    "\n",
    "            elif Clinical_Scale == 'BOTH':\n",
    "                multi_task = True\n",
    "                cs_list = ['adas','mmse']\n",
    "                iter_euLoss_adas13 = []\n",
    "                iter_r_adas13 = []        \n",
    "                iter_pred_scores_adas13 = []\n",
    "                iter_euLoss_mmse = []\n",
    "                iter_r_mmse = []        \n",
    "                iter_pred_scores_mmse = []\n",
    "\n",
    "                for snap_iter in np.arange(snap_start,niter+1,snap_interval):\n",
    "                    model_file = baseline_dir + 'API/data/MC_{}/fold{}/train_snaps/{}_{}_{}_iter_{}.caffemodel'.format(mc,fid,exp_name,hype,modality,snap_iter)        \n",
    "                    results = extract_features(net_file, model_file, data_path, input_nodes, batch_size, encoding_layer, weight_layers,multi_task)\n",
    "                    encodings = results['X_out']   \n",
    "                    encodings_adas13 = np.squeeze(encodings['adas13'])\n",
    "                    encodings_mmse = np.squeeze(encodings['mmse'])\n",
    "                    iter_pred_scores_adas13.append(encodings_adas13)            \n",
    "                    iter_pred_scores_mmse.append(encodings_mmse)                 \n",
    "                    iter_euLoss_adas13.append(0.5*mse(encodings_adas13,act_scores_adas13))  #This is to be consistent with the caffe loss funtion\n",
    "                    iter_euLoss_mmse.append(0.5*mse(encodings_mmse,act_scores_mmse))  #This is to be consistent with the caffe loss funtion\n",
    "                    iter_r_adas13.append(stats.pearsonr(encodings_adas13,act_scores_adas13)[0])                                \n",
    "                    iter_r_mmse.append(stats.pearsonr(encodings_mmse,act_scores_mmse)[0])\n",
    "\n",
    "                config_idx = '{}_{}'.format(hype,fid)\n",
    "                fold_euLoss_adas13[config_idx] = np.array(iter_euLoss_adas13)\n",
    "                fold_r_adas13[config_idx] = np.array(iter_r_adas13)\n",
    "                fold_act_scores_adas13[fid] = act_scores_adas13\n",
    "                fold_pred_scores_adas13[config_idx] = np.array(iter_pred_scores_adas13)        \n",
    "                fold_euLoss_mmse[config_idx] = np.array(iter_euLoss_mmse)\n",
    "                fold_r_mmse[config_idx] = np.array(iter_r_mmse)\n",
    "                fold_act_scores_mmse[fid] = act_scores_mmse\n",
    "                fold_pred_scores_mmse[config_idx] = np.array(iter_pred_scores_mmse)        \n",
    "\n",
    "    \n",
    "    if Clinical_Scale in ['ADAS13', 'MMSE']:\n",
    "        fold_perf_dict = {'fold_r':fold_r,'fold_euLoss':fold_euLoss,'fold_act_scores':fold_act_scores,'fold_pred_scores':fold_pred_scores}\n",
    "    else: \n",
    "        fold_perf_dict = {'fold_r_adas13':fold_r_adas13,'fold_r_mmse':fold_r_mmse,'fold_euLoss_adas13':fold_euLoss_adas13,'fold_euLoss_mmse':fold_euLoss_mmse,\n",
    "                         'fold_act_scores_adas13':fold_act_scores_adas13,'fold_act_scores_mmse':fold_act_scores_mmse,\n",
    "                          'fold_pred_scores_adas13':fold_pred_scores_adas13,'fold_pred_scores_mmse':fold_pred_scores_mmse}\n",
    "        \n",
    "    opt_metric = 'euLoss' #euLoss or corr or both\n",
    "    #task_weights = {'ADAS':1,'MMSE':0} \n",
    "    save_multitask_results = False\n",
    "    CV_model_dir = '/projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/output/'  \n",
    "    save_path = '{}{}_{}_NN_{}'.format(CV_model_dir,exp_name,mc,modality)\n",
    "    \n",
    "    # Create dictionaries of perfromance based on differnt task weights \n",
    "    for key, task_weights in {'adas':{'ADAS':1,'MMSE':0},'mmse':{'ADAS':0,'MMSE':1},'both':{'ADAS':1,'MMSE':1}}.items():\n",
    "        print 'Weights Tuned for: {}'.format(key)                              \n",
    "        results = compute_MC_results(fold_perf_dict, multi_task, opt_metric, task_weights, save_multitask_results, save_path)  \n",
    "\n",
    "        # populate the perf dictionary for 10 MC x 10 folds\n",
    "        model_choice = 'APANN'    \n",
    "        for f, fid in enumerate(fid_list): \n",
    "            if key in ['adas','mmse']:\n",
    "                r_valid = results['{}_r'.format(key)][f]\n",
    "                MSE_valid = results['{}_mse'.format(key)][f]\n",
    "                RMSE_valid = results['{}_rmse'.format(key)][f]\n",
    "\n",
    "                if key == 'adas':\n",
    "                    df_perf_dict_adas_tuned[idx] = {'MC':mc,'modality':modality,'model_choice':model_choice,'KF':fid,\n",
    "                                         'CV_MSE':MSE_valid,'CV_RMSE':RMSE_valid,'CV_r':r_valid,'CV_R2':0}\n",
    "                elif key == 'mmse':\n",
    "                    df_perf_dict_mmse_tuned[idx] = {'MC':mc,'modality':modality,'model_choice':model_choice,'KF':fid,\n",
    "                                         'CV_MSE':MSE_valid,'CV_RMSE':RMSE_valid,'CV_r':r_valid,'CV_R2':0}\n",
    "                else: \n",
    "                    print 'unknown key'\n",
    "\n",
    "            elif key == 'both':                    \n",
    "                for cs in cs_list:            \n",
    "                    r_valid = results['{}_r'.format(cs)][f]\n",
    "                    MSE_valid = results['{}_mse'.format(cs)][f]\n",
    "                    RMSE_valid = results['{}_rmse'.format(cs)][f]\n",
    "\n",
    "                    if cs == 'adas':\n",
    "                        df_perf_dict_adas[idx] = {'MC':mc,'modality':modality,'model_choice':model_choice,'KF':fid,\n",
    "                                         'CV_MSE':MSE_valid,'CV_RMSE':RMSE_valid,'CV_r':r_valid,'CV_R2':0}\n",
    "                    elif cs == 'mmse':\n",
    "                        df_perf_dict_mmse[idx] = {'MC':mc,'modality':modality,'model_choice':model_choice,'KF':fid,\n",
    "                                         'CV_MSE':MSE_valid,'CV_RMSE':RMSE_valid,'CV_r':r_valid,'CV_R2':0}                    \n",
    "                    else: \n",
    "                        print 'unknown key'\n",
    "\n",
    "\n",
    "            else: #single task dictionary\n",
    "                df_perf_dict_opt[idx] = {'MC':mc,'modality':modality,'model_choice':model_choice,'KF':fid,\n",
    "                                         'CV_MSE':MSE_valid,'CV_RMSE':RMSE_valid,'CV_r':r_valid,'CV_R2':0}\n",
    "\n",
    "            idx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving results at: /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/output/\n"
     ]
    }
   ],
   "source": [
    "#Save df style dictionaly for seaborn plots\n",
    "cohort = 'ADNI1and2'\n",
    "df_perf_dict_path = CV_model_dir + 'df_perf_dict_{}_{}_{}_ADAS13.pkl'.format(exp_name, cohort,modality)                \n",
    "pickleIt(df_perf_dict_adas,df_perf_dict_path)\n",
    "df_perf_dict_path = CV_model_dir + 'df_perf_dict_{}_{}_{}_MMSE.pkl'.format(exp_name, cohort,modality)  \n",
    "pickleIt(df_perf_dict_mmse,df_perf_dict_path)\n",
    "\n",
    "df_perf_dict_path = CV_model_dir + 'df_perf_dict_{}_{}_{}_ADAS13_tuned.pkl'.format(exp_name,cohort,modality)                \n",
    "pickleIt(df_perf_dict_adas_tuned,df_perf_dict_path)\n",
    "df_perf_dict_path = CV_model_dir + 'df_perf_dict_{}_{}_{}_MMSE_tuned.pkl'.format(exp_name, cohort,modality)  \n",
    "pickleIt(df_perf_dict_mmse_tuned,df_perf_dict_path)\n",
    "\n",
    "\n",
    "print 'saving results at: {}'.format(CV_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (20, 25)\n",
    "n_rows = n_folds\n",
    "n_cols = 2\n",
    "pid = 1\n",
    "plot_perf = False\n",
    "\n",
    "if multi_task:\n",
    "    euLosses = [fold_euLoss_adas13,fold_euLoss_mmse]\n",
    "    corrs = [fold_r_adas13,fold_r_mmse]\n",
    "else:\n",
    "    euLosses = [fold_euLoss]\n",
    "    corrs = [fold_r]\n",
    "    \n",
    "for fold_euLoss, fold_r in zip(euLosses, corrs):\n",
    "    for hype_fid in fold_euLoss.keys():\n",
    "        hype = int(hype_fid.split('_')[0][3])\n",
    "        fid = int(hype_fid.split('_')[1])    \n",
    "        \n",
    "        if plot_perf:\n",
    "            plt.figure(fid)\n",
    "            plt.subplot(n_rows,n_cols,1)\n",
    "            plt.plot(np.arange(snap_start,niter+1,snap_interval),fold_euLoss[hype_fid],label=hype_fid)\n",
    "            plt.title('Euclidean loss , fid: {}'.format(fid))\n",
    "            plt.legend()\n",
    "            plt.subplot(n_rows,n_cols,2)\n",
    "            plt.plot(np.arange(snap_start,niter+1,snap_interval),fold_r[hype_fid],label=hype_fid)\n",
    "            plt.title('correlation, fid: {}'.format(fid))\n",
    "            plt.legend(loc=2)\n",
    "\n",
    "print preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def compute_MC_results(fold_perf_dict, multi_task, opt_metric, task_weights, save_multitask_results, save_path):\n",
    "    fold_r_dict = {}\n",
    "    fold_euLoss_dict = {}\n",
    "    fold_act_scores_dict = {}\n",
    "    fold_pred_scores_dict = {}\n",
    "\n",
    "    if multi_task:\n",
    "        fold_r_dict['ADAS'] = fold_perf_dict['fold_r_adas13']\n",
    "        fold_r_dict['MMSE'] = fold_perf_dict['fold_r_mmse']\n",
    "        fold_euLoss_dict['ADAS'] = fold_perf_dict['fold_euLoss_adas13']\n",
    "        fold_euLoss_dict['MMSE'] = fold_perf_dict['fold_euLoss_mmse']\n",
    "        fold_act_scores_dict['ADAS'] = fold_perf_dict['fold_act_scores_adas13']\n",
    "        fold_act_scores_dict['MMSE'] = fold_perf_dict['fold_act_scores_mmse']\n",
    "        fold_pred_scores_dict['ADAS'] = fold_perf_dict['fold_pred_scores_adas13']\n",
    "        fold_pred_scores_dict['MMSE'] = fold_perf_dict['fold_pred_scores_mmse']\n",
    "        \n",
    "        NN_results = computePerfMetrics(fold_r_dict, fold_euLoss_dict, fold_act_scores_dict, fold_pred_scores_dict, opt_metric, hype_configs, \n",
    "                                        Clinical_Scale,task_weights)\n",
    "        adas_r = NN_results['opt_ADAS']['CV_r'].values()\n",
    "        mmse_r = NN_results['opt_MMSE']['CV_r'].values()\n",
    "        adas_mse = NN_results['opt_ADAS']['CV_MSE'].values()\n",
    "        mmse_mse = NN_results['opt_MMSE']['CV_MSE'].values()\n",
    "        adas_rmse = NN_results['opt_ADAS']['CV_RMSE'].values()\n",
    "        mmse_rmse = NN_results['opt_MMSE']['CV_RMSE'].values()\n",
    "        opt_hyp = NN_results['opt_hype']\n",
    "        opt_snap = NN_results['opt_snap']\n",
    "        predicted_CV_scores = NN_results['opt_ADAS']['predicted_CV_scores']\n",
    "        actual_CV_scores = NN_results['opt_ADAS']['actual_CV_scores']\n",
    "        \n",
    "        print 'ADAS corr: {}'.format(adas_r)\n",
    "        print 'ADAS mse: {}'.format(adas_mse)\n",
    "        print 'ADAS means: {}, {}'.format(np.mean(adas_r),np.mean(adas_mse))\n",
    "        print ''\n",
    "        print 'MMSE corr: {}'.format(mmse_r)\n",
    "        print 'MMSE mse: {}'.format(mmse_mse)\n",
    "        print 'MMSE means: {}, {}'.format(np.mean(mmse_r),np.mean(mmse_mse))\n",
    "        print ''\n",
    "        print 'opt_hyp: {}'.format(opt_hyp)\n",
    "        print ''\n",
    "        print 'opt_snap: {}'.format(opt_snap)\n",
    "        \n",
    "        return {'adas_r':adas_r, 'adas_mse':adas_mse, 'adas_rmse':adas_rmse, 'mmse_r':mmse_r, 'mmse_mse':mmse_mse, 'mmse_rmse':mmse_rmse,\n",
    "               'predicted_CV_scores':predicted_CV_scores,'actual_CV_scores':actual_CV_scores}\n",
    "\n",
    "    else:    \n",
    "        \n",
    "        NN_results = computeSingleTaskPerfMetrics(fold_perf_dict, opt_metric, hype_configs)\n",
    "        opt_r = NN_results['opt_r'].values()        \n",
    "        opt_mse = NN_results['opt_mse'].values()        \n",
    "        opt_rmse = NN_results['opt_rmse'].values()        \n",
    "        opt_hyp = NN_results['opt_hype']\n",
    "        opt_snap = NN_results['opt_snap']\n",
    "        predicted_CV_scores = NN_results['predicted_CV_scores']\n",
    "        actual_CV_scores = NN_results['actual_CV_scores']\n",
    "        print 'opt corr: {}'.format(opt_r)\n",
    "        print 'opt mse: {}'.format(opt_mse)\n",
    "        print 'means: {}, {}'.format(np.mean(opt_r),np.mean(opt_mse))\n",
    "        print ''\n",
    "        print 'opt_snap: {}'.format(opt_snap)\n",
    "        print ''\n",
    "    \n",
    "        return {'opt_r':opt_r, 'opt_mse':opt_mse, 'opt_rmse':opt_rmse,'predicted_CV_scores':predicted_CV_scores,'actual_CV_scores':actual_CV_scores}\n",
    "    \n",
    "\n",
    "\n",
    "    if save_multitask_results:\n",
    "        ts = time.time()\n",
    "        st = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d-%H-%M-%S')        \n",
    "        save_path = save_path + '_' + st + '.pkl' \n",
    "        print 'saving results at: {}'.format(save_path)\n",
    "        output = open(save_path, 'wb')\n",
    "        pickle.dump(NN_results, output)\n",
    "        output.close()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'predicted_CV_scores'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-6f668dc9c41d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predicted_CV_scores'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'actual_CV_scores'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpearsonr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'predicted_CV_scores'"
     ]
    }
   ],
   "source": [
    "a = np.squeeze(results['predicted_CV_scores'][7])\n",
    "b = np.squeeze(results['actual_CV_scores'][7])\n",
    "\n",
    "print a , b                               \n",
    "print stats.pearsonr(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute ptimal hyp_config for each fold(based on inner_test)\n",
    "# if multi_task is set then compute hyp_config based on ADAS+MMSE perf (mse, r values)\n",
    "# if multi_task is set then ADAS and MMSE act_scores and pred_scores are wrapped in dictionaries \n",
    "# task_weights: dict of weights for each task --> only used in Clinical_Scale = BOTH\n",
    "# opt_metric = mse or corr\n",
    "def computePerfMetrics(fold_r, fold_euLoss, fold_act_scores, fold_pred_scores, opt_metric, hype_configs, Clinical_Scale,task_weights):\n",
    "    # First generate lists per fold with all hyp results\n",
    "    fid_hype_map = defaultdict(list)\n",
    "    fid_euLoss_perf= defaultdict(list)\n",
    "    fid_r_perf= defaultdict(list)\n",
    "    \n",
    "     # find optimal hyp_snp combination for each fold based on corr and euLoss\n",
    "    opt_hype = {}\n",
    "    opt_snap = {}\n",
    "\n",
    "    opt_r_adas = {}\n",
    "    opt_mse_adas = {}\n",
    "    opt_rmse_adas = {}\n",
    "    actual_scores_adas = defaultdict(list)\n",
    "    opt_pred_scores_adas = defaultdict(list)\n",
    "\n",
    "    opt_r_mmse = {}\n",
    "    opt_mse_mmse = {}\n",
    "    opt_rmse_mmse = {}\n",
    "    actual_scores_mmse = defaultdict(list)\n",
    "    opt_pred_scores_mmse = defaultdict(list)\n",
    "\n",
    "    print 'Clinical_Scale: {}'.format(Clinical_Scale)\n",
    "    if not Clinical_Scale == 'BOTH':  #Does not produce all the metrics yet..\n",
    "        print 'This function does not work for single clinical scale models. Use the code from the next cell'\n",
    "    \n",
    "    else:\n",
    "        fold_r_ADAS = fold_r['ADAS']\n",
    "        fold_r_MMSE = fold_r['MMSE']\n",
    "        fold_euLoss_ADAS = fold_euLoss['ADAS']\n",
    "        fold_euLoss_MMSE = fold_euLoss['MMSE']\n",
    "        fid_r_perf_ADAS = defaultdict(list)\n",
    "        fid_r_perf_MMSE = defaultdict(list)\n",
    "        fid_euLoss_perf_ADAS = defaultdict(list)\n",
    "        fid_euLoss_perf_MMSE = defaultdict(list)\n",
    "        for hype_fid in fold_euLoss_ADAS.keys():\n",
    "            hype = int(hype_fid.split('_')[0][3])\n",
    "            fid = int(hype_fid.split('_')[1]) \n",
    "            \n",
    "            fid_r_perf_ADAS[fid].append(fold_r_ADAS[hype_fid])\n",
    "            fid_r_perf_MMSE[fid].append(fold_r_MMSE[hype_fid])\n",
    "            fid_euLoss_perf_ADAS[fid].append(fold_euLoss_ADAS[hype_fid])\n",
    "            fid_euLoss_perf_MMSE[fid].append(fold_euLoss_MMSE[hype_fid])\n",
    "            fid_hype_map[fid].append(hype)\n",
    "            \n",
    "            #Joint scores (weighted addition)\n",
    "            fid_r_perf[fid].append(task_weights['ADAS']*fold_r_ADAS[hype_fid] + task_weights['MMSE']*fold_r_MMSE[hype_fid])\n",
    "            fid_euLoss_perf[fid].append(task_weights['ADAS']*fold_euLoss_ADAS[hype_fid] + task_weights['MMSE']*fold_euLoss_MMSE[hype_fid])\n",
    "\n",
    "        fold_act_scores_adas = fold_act_scores['ADAS']\n",
    "        fold_act_scores_mmse = fold_act_scores['MMSE']\n",
    "        fold_pred_scores_adas = fold_pred_scores['ADAS']\n",
    "        fold_pred_scores_mmse = fold_pred_scores['MMSE']\n",
    "\n",
    "        for fid in fid_hype_map.keys():\n",
    "            r_perf_array_adas = np.array(fid_r_perf_ADAS[fid])\n",
    "            r_perf_array_mmse = np.array(fid_r_perf_MMSE[fid])\n",
    "            r_perf_array = np.array(fid_r_perf[fid])\n",
    "            euLoss_perf_array_adas = np.array(fid_euLoss_perf_ADAS[fid])\n",
    "            euLoss_perf_array_mmse = np.array(fid_euLoss_perf_MMSE[fid])\n",
    "            euLoss_perf_array = np.array(fid_euLoss_perf[fid])\n",
    "\n",
    "            if opt_metric == 'euLoss':\n",
    "                h,snp = np.unravel_index(euLoss_perf_array.argmin(), euLoss_perf_array.shape)\n",
    "            else:\n",
    "                h,snp = np.unravel_index(r_perf_array.argmax(), r_perf_array.shape)\n",
    "\n",
    "            opt_hype[fid] = hype_configs['hyp{}'.format(fid_hype_map[fid][h])]\n",
    "            opt_snap[fid] = snp\n",
    "\n",
    "            opt_r_adas[fid] = r_perf_array_adas[h,snp]\n",
    "            opt_mse_adas[fid] = 2*euLoss_perf_array_adas[h,snp] #Convert back to MSE\n",
    "            opt_rmse_adas[fid] = np.sqrt(2*euLoss_perf_array_adas[h,snp]) #RMSE\n",
    "            opt_r_mmse[fid] = r_perf_array_mmse[h,snp] \n",
    "            opt_mse_mmse[fid] = 2*euLoss_perf_array_mmse[h,snp] #Convert back to MSE\n",
    "            opt_rmse_mmse[fid] = np.sqrt(2*euLoss_perf_array_mmse[h,snp]) #RMSE\n",
    "\n",
    "            actual_scores_adas[fid].append(fold_act_scores_adas[fid])\n",
    "            opt_pred_scores_adas[fid].append(fold_pred_scores_adas['hyp{}_{}'.format(fid_hype_map[fid][h],fid)][snp])\n",
    "            actual_scores_mmse[fid].append(fold_act_scores_mmse[fid])\n",
    "            opt_pred_scores_mmse[fid].append(fold_pred_scores_mmse['hyp{}_{}'.format(fid_hype_map[fid][h],fid)][snp])\n",
    "\n",
    "        opt_ADAS = {'CV_r':opt_r_adas,'CV_MSE':opt_mse_adas,'CV_RMSE':opt_rmse_adas,'actual_CV_scores':actual_scores_adas,'predicted_CV_scores':opt_pred_scores_adas}\n",
    "        opt_MMSE = {'CV_r':opt_r_mmse,'CV_MSE':opt_mse_mmse,'CV_RMSE':opt_rmse_mmse,'actual_CV_scores':actual_scores_mmse,'predicted_CV_scores':opt_pred_scores_mmse}\n",
    "    \n",
    "    return {'opt_hype':opt_hype, 'opt_snap':opt_snap, 'opt_ADAS':opt_ADAS, 'opt_MMSE':opt_MMSE}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Find optimal config based on inner_test\n",
    "def computeSingleTaskPerfMetrics(fold_perf_dict,opt_metric,hype_configs):\n",
    "    corrs = fold_perf_dict['fold_r']\n",
    "    euLosses = fold_perf_dict['fold_euLoss']\n",
    "    act_scores = fold_perf_dict['fold_act_scores']\n",
    "    pred_scores = fold_perf_dict['fold_pred_scores']\n",
    "\n",
    "    \n",
    "    NN_multitask_results = {}\n",
    "   \n",
    "    snap_array = np.arange(snap_start,niter+1,snap_start)\n",
    "\n",
    "    fid_hype_map = defaultdict(list)\n",
    "    fid_euLoss_perf= defaultdict(list)\n",
    "    fid_r_perf= defaultdict(list)\n",
    "    for hype_fid in fold_euLoss.keys():\n",
    "        hype = int(hype_fid.split('_')[0][3])\n",
    "        fid = int(hype_fid.split('_')[1])\n",
    "        fid_euLoss_perf[fid].append(fold_euLoss[hype_fid])\n",
    "        fid_r_perf[fid].append(fold_r[hype_fid])\n",
    "        fid_hype_map[fid].append(hype)\n",
    "\n",
    "    opt_r = {}\n",
    "    opt_mse = {}\n",
    "    opt_rmse = {}\n",
    "    opt_hype = {}\n",
    "    opt_snap = {}\n",
    "    actual_scores = {}\n",
    "    opt_pred_scores = {}\n",
    "\n",
    "    for fid in fid_hype_map.keys():\n",
    "        r_perf_array = np.array(fid_r_perf[fid])\n",
    "        euLoss_perf_array = np.array(fid_euLoss_perf[fid])\n",
    "\n",
    "        # if want to find best hyp from mse values\n",
    "        if opt_metric == 'euLoss':\n",
    "            h,snp = np.unravel_index(euLoss_perf_array.argmin(), euLoss_perf_array.shape)\n",
    "        else:\n",
    "            h,snp = np.unravel_index(r_perf_array.argmax(), r_perf_array.shape)\n",
    "            \n",
    "        eu_loss = euLoss_perf_array[h,snp]\n",
    "        r = r_perf_array[h,snp]        \n",
    "        opt_r[fid] = r\n",
    "        opt_mse[fid] = 2*eu_loss\n",
    "        opt_rmse[fid] = np.sqrt(2*eu_loss)\n",
    "        #print 'fid:{}, best hype:{}, snap: {}, euLoss:{}'.format(fid, fid_hype_map[fid][h],snap_array[snp],eu_loss)        \n",
    "        opt_snap[fid] = snp\n",
    "        opt_hype[fid] = hype_configs['hyp{}'.format(fid_hype_map[fid][h])]\n",
    "        actual_scores[fid] = fold_act_scores[fid]\n",
    "        opt_pred_scores[fid] = fold_pred_scores['hyp{}_{}'.format(fid_hype_map[fid][h],fid)][snp]\n",
    "\n",
    "    #print 'CV Perf: r:{}, mse:{}'.format(np.mean(opt_r.values()), np.mean(opt_mse.values()))\n",
    "    #print opt_r\n",
    "    #print opt_mse\n",
    "    return {'opt_r':opt_r,'opt_mse':opt_mse,'opt_rmse':opt_rmse,'opt_hype':opt_hype,'opt_snap':opt_snap, 'actual_scores':actual_scores,'opt_pred_scores':opt_pred_scores}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "boxplots_dir = '/projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/montage_data/'\n",
    "\n",
    "model_file = 'Exp6_ADNI1_ADAS13_NN_HC_CT_2016-05-06-17-14-49.pkl'\n",
    "print model_file\n",
    "CV_data = pickle.load(open(boxplots_dir + model_file,'rb'))\n",
    "\n",
    "print 'old CV_r: {}'.format(CV_data['CV_r'])\n",
    "print ''\n",
    "print 'old mean(CV_r): {}, mean(MSE): {}'.format(np.mean(CV_data['CV_r']),np.mean(CV_data['CV_MSE']))\n",
    "print ''\n",
    "print 'old CV_mse: {}'.format(CV_data['CV_MSE'])\n",
    "#print CV_data['tid_snap_config_dict']\n",
    "\n",
    "NN_results = {}\n",
    "NN_results['CV_MSE'] = opt_mse\n",
    "NN_results['CV_r'] = opt_r\n",
    "NN_results['predicted_CV_scores'] = opt_pred_scores\n",
    "NN_results['actual_CV_scores'] = actual_scores\n",
    "NN_results['tid_snap_config_dict'] = opt_hype\n",
    "\n",
    "# #Combine second saved perf file with the previous one\n",
    "# model_file_2 = 'Exp11_ADNI2_ADAS13_NN_HC_CT_2016-05-06-00-03-01.pkl'\n",
    "# print model_file\n",
    "# NN_results = pickle.load(open(boxplots_dir + model_file_2,'rb'))\n",
    "\n",
    "idx_pairs = {4:0,5:1}\n",
    "updated_CV_data = update_fold_perf(boxplots_dir + model_file, NN_results, idx_pairs)\n",
    "print ''\n",
    "print 'new CV_r: {}'.format(updated_CV_data['CV_r'])\n",
    "print ''\n",
    "print 'new mean(CV_r): {}, mean(MSE): {}'.format(np.mean(updated_CV_data['CV_r']),np.mean(updated_CV_data['CV_MSE']))\n",
    "print ''\n",
    "print 'new CV_mse: {}'.format(updated_CV_data['CV_MSE'])\n",
    "\n",
    "save_updated_perf = False\n",
    "if save_updated_perf:\n",
    "    ts = time.time()\n",
    "    st = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d-%H-%M-%S')\n",
    "    montage_dir = '/projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/montage_data/'  \n",
    "    save_name = '{}Exp6_ADNI1_ADAS13_NN_{}_{}.pkl'.format(montage_dir,modality,st)\n",
    "    print 'saving results at: {}'.format(save_name)\n",
    "    output = open(save_name, 'wb')\n",
    "    pickle.dump(updated_CV_data, output)\n",
    "    output.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sqrt(5.64658243068)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Update fold performance for multitask\n",
    "print NN_results['opt_ADAS'].keys()\n",
    "\n",
    "boxplots_dir = '/projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/montage_data/'\n",
    "#model_file = 'Exp11_ADNI2_ADAS13_MMSE_NN_HC_CT_2016-06-04-13-15-43.pkl'\n",
    "model_file_soa = 'Exp11_ADNI2_ADAS13_MMSE_NN_HC_CT_2016-08-24-14-23-52.pkl'\n",
    "print 'current state of art: ' + model_file_soa\n",
    "CV_data = pickle.load(open(boxplots_dir + model_file_soa,'rb'))\n",
    "\n",
    "print 'ADAS'\n",
    "print CV_data['opt_ADAS']['CV_r']\n",
    "print CV_data['opt_ADAS']['CV_MSE']\n",
    "print np.mean(CV_data['opt_ADAS']['CV_r'].values())\n",
    "print np.mean(CV_data['opt_ADAS']['CV_MSE'].values())\n",
    "print 'MMSE'\n",
    "print CV_data['opt_MMSE']['CV_r']\n",
    "print CV_data['opt_MMSE']['CV_MSE']\n",
    "print np.mean(CV_data['opt_MMSE']['CV_r'].values())\n",
    "print np.mean(CV_data['opt_MMSE']['CV_MSE'].values())\n",
    "\n",
    "#load old file\n",
    "# model_file = 'Exp11_ADNI2_ADAS13_MMSE_NN_HC_CT_2016-08-24-14-02-48.pkl'\n",
    "# print 'updated fold result file: ' + model_file\n",
    "# NN_results = pickle.load(open(boxplots_dir + model_file,'rb'))\n",
    "\n",
    "idx_pairs = {1:1,3:3}\n",
    "CV_data = update_multifold_perf(boxplots_dir + model_file_soa, NN_results, idx_pairs)\n",
    "\n",
    "print \"\"\n",
    "print 'updated CV_data'\n",
    "print 'ADAS'\n",
    "print CV_data['opt_ADAS']['CV_r']\n",
    "print CV_data['opt_ADAS']['CV_MSE']\n",
    "print np.mean(CV_data['opt_ADAS']['CV_r'].values())\n",
    "print np.mean(CV_data['opt_ADAS']['CV_MSE'].values())\n",
    "print 'MMSE'\n",
    "print CV_data['opt_MMSE']['CV_r']\n",
    "print CV_data['opt_MMSE']['CV_MSE']\n",
    "print np.mean(CV_data['opt_MMSE']['CV_r'].values())\n",
    "print np.mean(CV_data['opt_MMSE']['CV_MSE'].values())\n",
    "\n",
    "save_name = '{}Exp11_ADNI2_ADAS13_MMSE_NN_{}_{}.pkl'.format(montage_dir,modality,st)\n",
    "#print 'saving results at: {}'.format(save_name)\n",
    "\n",
    "save_updated_perf = False\n",
    "if save_updated_perf:\n",
    "    ts = time.time()\n",
    "    st = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d-%H-%M-%S')\n",
    "    montage_dir = '/projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/montage_data/'  \n",
    "    save_name = '{}Exp11_ADNI2_ADAS13_MMSE_NN_{}_{}.pkl'.format(montage_dir,modality,st)\n",
    "    print 'saving results at: {}'.format(save_name)\n",
    "    output = open(save_name, 'wb')\n",
    "    pickle.dump(CV_data, output)\n",
    "    output.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "def update_fold_perf(saved_perf_file, new_perf_dict,idx_pairs): #idx_pairs={'old_idx':new_idx}\n",
    "    CV_data = pickle.load(open(saved_perf_file,'rb'))    \n",
    "    for key in CV_data.keys():        \n",
    "        for idx in idx_pairs.keys():            \n",
    "            CV_data[key][idx] = new_perf_dict[key][idx_pairs[idx]]\n",
    "\n",
    "    return CV_data\n",
    "\n",
    "def update_multifold_perf(saved_perf_file, new_perf_dict, idx_pairs):    \n",
    "    perf_metrics = ['CV_r', 'actual_CV_scores', 'CV_MSE', 'predicted_CV_scores']    \n",
    "    CV_data = pickle.load(open(saved_perf_file,'rb'))    \n",
    "    for key in CV_data.keys():\n",
    "        if key == 'opt_hype':\n",
    "            for idx_key,idx_val in idx_pairs.iteritems():\n",
    "                CV_data[key][idx_key] = new_perf_dict[key][idx_val]\n",
    "                \n",
    "        else:\n",
    "            for pm in perf_metrics:\n",
    "                for idx_key,idx_val in idx_pairs.iteritems():\n",
    "                    CV_data[key][pm][idx_key] = new_perf_dict[key][pm][idx_val]\n",
    "    \n",
    "    return CV_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boxplots_dir = '/projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/montage_data/'\n",
    "model_files = ['Exp11_ADNI2_ADAS13_MMSE_NN_HC_CT_2016-06-04-13-15-43.pkl',             \n",
    "             'Exp11_ADNI2_ADAS13_MMSE_NN_HC_CT_2016-05-23-07-31-29.pkl']\n",
    "\n",
    "#'Exp11_ADNI2_ADAS13_MMSE_NN_HC_CT_2016-06-03-19-29-16_Fold9_10.pkl'\n",
    "\n",
    "Clinical_Scale = 'ADAS'\n",
    "perf_array = []\n",
    "for mf in model_files:\n",
    "    CV_data = pickle.load(open(boxplots_dir + mf,'rb'))['opt_{}'.format(Clinical_Scale)]        \n",
    "    perf_array.append(CV_data['CV_r'].values())\n",
    "\n",
    "print (np.max(np.array(perf_array),axis=0))\n",
    "print np.mean(np.max(np.array(perf_array),axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "#print 'modality: {} mse: {}, r: {}'.format(modality, np.mean(2*np.array(fold_euLoss)[:,-1]),np.mean(np.array(fold_r)[:,-1]))\n",
    "#CV_perf ={'fid_list': fid_hype_map.keys(), 'hype_configs':opt_hype,'fold_mse':opt_mse,'fold_r':opt_r}\n",
    "#pickleIt(CV_perf, baseline_dir + 'API/CV_perf/outer_test_{}.pkl'.format(modality))\n",
    "#print \"Saving opt perf for fids: {} with modality: {}\".format(fid_hype_map.keys(),modality)\n",
    "\n",
    "\n",
    "save_detailed_results = True\n",
    "multi_task = True\n",
    "\n",
    "if save_detailed_results:\n",
    "    # dictionaries for summarized results    \n",
    "    if not multi_task:\n",
    "        NN_results = {}\n",
    "        NN_results['CV_MSE'] = opt_mse\n",
    "        NN_results['CV_r'] = opt_r\n",
    "        NN_results['predicted_CV_scores'] = opt_pred_scores\n",
    "        NN_results['actual_CV_scores'] = actual_scores\n",
    "        NN_results['tid_snap_config_dict'] = opt_hype\n",
    "        print opt_r\n",
    "        print opt_mse\n",
    "        \n",
    "    else:\n",
    "        NN_results = NN_multitask_results\n",
    "        print 'ADAS13, opt_r: {}'.format(NN_multitask_results['ADAS13']['opt_r'])\n",
    "        print 'ADAS13, opt_mse {}: '.format(NN_multitask_results['ADAS13']['opt_mse'])\n",
    "        print 'MMSE, opt_r: {}'.format(NN_multitask_results['MMSE']['opt_r'])\n",
    "        print 'MMSE, opt_mse: {}'.format(NN_multitask_results['MMSE']['opt_mse'])\n",
    "        \n",
    "    ts = time.time()\n",
    "    st = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d-%H-%M-%S')\n",
    "    montage_dir = '/projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/montage_data/'  \n",
    "    save_name = '{}Exp6_ADNI1_BOTH_NN_{}_{}.pkl'.format(montage_dir,modality,st)\n",
    "    print 'saving results at: {}'.format(save_name)\n",
    "    output = open(save_name, 'wb')\n",
    "    pickle.dump(NN_results, output)\n",
    "    output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_APIdata(in_data_path,out_data_path,fid,modalities,preproc):\n",
    "    print in_data_path\n",
    "    #Input config file generation\n",
    "    for modality in modalities:\n",
    "        in_data = load_data(in_data_path, 'Fold_{}_{}'.format(fid,modality), preproc)         \n",
    "\n",
    "        # HDF5 is pretty efficient, but can be further compressed.\n",
    "        comp_kwargs = {'compression': 'gzip', 'compression_opts': 1}\n",
    "        with h5py.File(out_data_path, 'a') as f:      \n",
    "            if modality == 'X_R_CT': #Fix the typo            \n",
    "                modality = 'X_CT'            \n",
    "\n",
    "            f.create_dataset('{}'.format(modality), data=in_data, **comp_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Generate API style data (options: scale / normalize)\n",
    "exp_name = 'Exp6'\n",
    "exp_name_out = 'Exp6_MC'\n",
    "cohorts = ['inner_train','inner_test','outer_test']\n",
    "modalities = ['X_L_HC','X_R_HC','X_R_CT','adas','mmse','dx']\n",
    "dataset = 'ADNI1'\n",
    "preproc = 'no_preproc' #binary labels\n",
    "baseline_dir = '/projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/'\n",
    "\n",
    "for mc in np.arange(1,3,1):\n",
    "    for fid in np.arange(1,11,1):\n",
    "        for cohort in cohorts:            \n",
    "            if cohort == 'inner_train':\n",
    "                in_data_path = baseline_dir + 'caffe_input/CV_{}_{}_NN_OuterFold_MC_{}_fold{}_train_InnerFold_1.h5'.format(exp_name,dataset,mc,fid)\n",
    "            elif cohort == 'inner_test':\n",
    "                in_data_path = baseline_dir + 'caffe_input/CV_{}_{}_NN_OuterFold_MC_{}_fold{}_valid_InnerFold_1.h5'.format(exp_name,dataset,mc,fid)\n",
    "            else:                \n",
    "                in_data_path = baseline_dir + 'CV_{}_{}_ADAS13_NN_valid_MC_{}.h5'.format(exp_name,dataset,mc)\n",
    "\n",
    "            out_data_path = baseline_dir + 'API/data/MC_{}/fold{}/{}/{}.h5'.format(mc,fid,cohort,exp_name_out)\n",
    "            generate_APIdata(in_data_path,out_data_path,fid,modalities,preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HC: fid[1:4] 8000; fid[5,6] 6000, fid[7,8,9]: 8000 fid 10: 6000\n",
    "CT: fid[1:5] 12000 fid[6:10] 6000\n",
    "\n",
    "#spawn net\n",
    "ADNI_FF_train_hyp1_CT.prototxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fid: 1\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_6/fold1/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_6/fold1/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 2\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_6/fold2/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_6/fold2/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 3\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_6/fold3/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_6/fold3/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 4\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_6/fold4/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_6/fold4/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 5\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_6/fold5/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_6/fold5/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 6\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_6/fold6/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_6/fold6/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 7\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_6/fold7/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_6/fold7/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 8\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_6/fold8/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_6/fold8/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 9\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_6/fold9/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_6/fold9/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 10\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_6/fold10/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_6/fold10/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 1\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_7/fold1/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_7/fold1/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 2\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_7/fold2/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_7/fold2/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 3\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_7/fold3/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_7/fold3/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 4\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_7/fold4/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_7/fold4/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 5\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_7/fold5/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_7/fold5/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 6\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_7/fold6/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_7/fold6/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 7\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_7/fold7/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_7/fold7/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 8\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_7/fold8/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_7/fold8/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 9\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_7/fold9/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_7/fold9/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 10\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_7/fold10/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_7/fold10/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 1\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_8/fold1/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_8/fold1/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 2\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_8/fold2/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_8/fold2/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 3\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_8/fold3/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_8/fold3/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 4\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_8/fold4/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_8/fold4/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 5\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_8/fold5/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_8/fold5/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 6\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_8/fold6/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_8/fold6/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 7\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_8/fold7/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_8/fold7/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 8\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_8/fold8/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_8/fold8/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 9\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_8/fold9/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_8/fold9/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 10\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_8/fold10/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_8/fold10/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 1\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_9/fold1/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_9/fold1/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 2\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_9/fold2/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_9/fold2/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 3\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_9/fold3/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_9/fold3/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 4\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_9/fold4/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_9/fold4/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 5\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_9/fold5/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_9/fold5/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 6\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_9/fold6/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_9/fold6/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 7\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_9/fold7/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_9/fold7/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 8\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_9/fold8/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_9/fold8/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 9\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_9/fold9/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_9/fold9/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 10\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_9/fold10/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_9/fold10/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 1\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_10/fold1/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_10/fold1/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 2\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_10/fold2/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_10/fold2/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 3\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_10/fold3/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_10/fold3/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 4\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_10/fold4/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_10/fold4/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 5\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_10/fold5/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_10/fold5/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 6\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_10/fold6/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_10/fold6/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 7\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_10/fold7/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_10/fold7/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 8\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_10/fold8/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_10/fold8/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 9\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_10/fold9/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_10/fold9/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "fid: 10\n",
      "AE_branch: CT\n",
      "Spawning new net\n",
      "target ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "pretrained ff1 weights are (50, 686) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_10/fold10/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n",
      "AE_branch: HC\n",
      "target L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "target R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "pretrained L_ff1 weights are (50, 16086) dimensional and biases are (50,) dimensional\n",
      "pretrained R_ff1 weights are (50, 16471) dimensional and biases are (50,) dimensional\n",
      "Saving net to /projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/API/data/MC_10/fold10/pretrained_models/ADNI2_ff_hyp2_HC_CT_HC_snap_20000_CT_snap_20000_Sup_Concat.caffemodel\n"
     ]
    }
   ],
   "source": [
    "# Net surgery AE --> FF pretrained weights\n",
    "#Review new FF net params\n",
    "cohort = 'ADNI2'\n",
    "modality = 'HC_CT'\n",
    "pretrain_snap_HC = 20000 #ADNI1: 5000\n",
    "pretrain_snap_CT = 20000 #ADNI1: 5000\n",
    "n_folds = 10\n",
    "baseline_dir = '/projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/NN_MC/' \n",
    "#Custom snaps per fold\n",
    "#HC_iter = [8000,8000,8000,8000,6000,6000,8000,8000,8000,6000]\n",
    "#CT_iter = [12000,12000,12000,12000,12000,6000,6000,6000,6000,6000]\n",
    "#mc=1\n",
    "hc_hyp = 'hyp1'\n",
    "ct_hyp = 'hyp1'\n",
    "pretrain_hyp = 'hyp2' #This is hyp generated using optimal combination of hc and ct hyps. Prototxt file is saved with this hyp extension\n",
    "\n",
    "exp_name = 'Exp11_MC'\n",
    "\n",
    "for mc in np.arange(6,11,1):\n",
    "    for fid in np.arange(1,n_folds+1,1):\n",
    "        print 'fid: {}'.format(fid)\n",
    "        #for AE_branch in ['CT','R_HC','L_HC']:\n",
    "        for AE_branch in ['CT','HC']:\n",
    "            print 'AE_branch: {}'.format(AE_branch)\n",
    "\n",
    "            if AE_branch == 'L_HC':\n",
    "                params_FF = ['L_ff1', 'L_ff2']            \n",
    "                AE_iter = 12000\n",
    "            elif AE_branch == 'R_HC':\n",
    "                params_FF = ['R_ff1', 'R_ff2']            \n",
    "                AE_iter = 12000\n",
    "            elif AE_branch == 'HC':\n",
    "                params_FF = ['L_ff1','R_ff1']\n",
    "                AE_iter = pretrain_snap_HC\n",
    "                hyp = hc_hyp\n",
    "            elif AE_branch == 'CT':\n",
    "                #params_FF = ['ff1', 'ff2']\n",
    "                params_FF = ['ff1']\n",
    "                AE_iter = pretrain_snap_CT\n",
    "                hyp = ct_hyp\n",
    "                #fid for pretain is 1 because it's same definition for all the folds.\n",
    "                #Only use this during 1 of the modalities to avoid overwritting\n",
    "                print 'Spawning new net'\n",
    "                pretrain_net = caffe.Net(baseline_dir + 'API/data/MC_{}/fold{}/ADNI_FF_train_{}_{}.prototxt'.format(mc,fid,pretrain_hyp,modality), caffe.TRAIN)\n",
    "            else:\n",
    "                print 'Wrong AE branch'\n",
    "\n",
    "            # conv_params = {name: (weights, biases)}\n",
    "            conv_params = {pr: (pretrain_net.params[pr][0].data, pretrain_net.params[pr][1].data) for pr in params_FF}\n",
    "\n",
    "            for conv in params_FF:\n",
    "                print 'target {} weights are {} dimensional and biases are {} dimensional'.format(conv, conv_params[conv][0].shape, conv_params[conv][1].shape)\n",
    "\n",
    "            # Review AE net params \n",
    "            #fid for pretain is 1 because it's same definition for all the folds.\n",
    "            net_file = baseline_dir + 'API/data/MC_{}/fold{}/ADNI_FF_train_{}_{}.prototxt'.format(mc,fid,hyp,AE_branch)\n",
    "            #model_file = baseline_dir + 'API/data/fold{}/train_snaps/AE_snaps/AE_{}_iter_{}.caffemodel'.format(fid,AE_branch,AE_iter) \n",
    "            model_file = baseline_dir + 'API/data/MC_{}/fold{}/train_snaps/{}_{}_{}_iter_{}.caffemodel'.format(mc,fid,exp_name,hyp,AE_branch,AE_iter) \n",
    "\n",
    "            AE_net = caffe.Net(net_file, model_file, caffe.TEST)\n",
    "            #params_AE = ['encoder1', 'code']\n",
    "            params_AE = params_FF #if you are using pretrained NN\n",
    "\n",
    "            # fc_params = {name: (weights, biases)}\n",
    "            fc_params = {pr: (AE_net.params[pr][0].data, AE_net.params[pr][1].data) for pr in params_AE}\n",
    "\n",
    "            for fc in params_AE:\n",
    "                print 'pretrained {} weights are {} dimensional and biases are {} dimensional'.format(fc, fc_params[fc][0].shape, fc_params[fc][1].shape)\n",
    "\n",
    "            #transplant net parameters\n",
    "            for pr, pr_conv in zip(params_AE, params_FF):\n",
    "                conv_params[pr_conv][0].flat = fc_params[pr][0].flat  # flat unrolls the arrays\n",
    "                conv_params[pr_conv][1][...] = fc_params[pr][1]\n",
    "\n",
    "            save_net = True\n",
    "            if save_net:\n",
    "                net_name = 'API/data/MC_{}/fold{}/pretrained_models/{}_ff_{}_{}_HC_snap_{}_CT_snap_{}_Sup_Concat.caffemodel'\n",
    "                save_path = baseline_dir + net_name.format(mc,fid,cohort,pretrain_hyp,modality,pretrain_snap_HC,pretrain_snap_CT)\n",
    "                print \"Saving net to \" + save_path\n",
    "                pretrain_net.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "CT_data = pickle.load(open('/projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/montage_data/Exp4_ADNI1_ADAS13_NN_CT_2016-03-01-11-18-48.pkl','rb'))\n",
    "CT_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = fold_pred_scores['hyp1_1'][5] #CT_data['predicted_CV_scores'][1]\n",
    "act = fold_act_scores[1] #CT_data['actual_CV_scores'][1]\n",
    "print act\n",
    "#print CT_data['tid_snap_config_dict']\n",
    "print 'Euclidean loss: {}'.format(0.5*mse(pred,act))\n",
    "print stats.pearsonr(pred,act)\n",
    "plt.scatter(pred,act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fold_pred_scores['hyp1_1'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fid = 1\n",
    "exp_name = 'Exp6'\n",
    "preproc = 'no_preproc'\n",
    "train_filename_hdf = baseline_dir + 'API/data/fold{}/inner_train/{}_{}.h5'.format(fid,exp_name,preproc)\n",
    "inner_test_filename_hdf = baseline_dir + 'API/data/fold{}/inner_test/{}_{}.h5'.format(fid,exp_name,preproc)\n",
    "outer_test_filename_hdf = baseline_dir + 'API/data/fold{}/outer_test/{}_{}.h5'.format(fid,exp_name,preproc)\n",
    "train_data = load_data(train_filename_hdf, 'X_R_HC', preproc)\n",
    "inner_test_data = load_data(inner_test_filename_hdf, 'X_R_HC', preproc)\n",
    "outer_test_data = load_data(outer_test_filename_hdf, 'X_R_HC', preproc)\n",
    "train_y = load_data(train_filename_hdf, 'y', preproc)\n",
    "inner_test_y = load_data(inner_test_filename_hdf, 'y', preproc)\n",
    "outer_test_y = load_data(outer_test_filename_hdf, 'y', preproc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print train_data.shape, inner_test_data.shape, outer_test_data.shape\n",
    "print np.mean(np.sum(train_data,axis=1)), np.mean(np.sum(inner_test_data,axis=1)), np.mean(np.sum(outer_test_data,axis=1))\n",
    "print np.mean(train_y), np.mean(inner_test_y), np.mean(outer_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(17358, 16086) (4340, 16086) (71, 16086)\n",
    "3377.85793294 3403.70506912 3427.98591549\n",
    "15.4938933057 15.7380184332 15.7605633803"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CV_data['opt_ADAS']['CV_r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print n_snaps/2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
