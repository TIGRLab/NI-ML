{
 "metadata": {
  "name": "",
  "signature": "sha256:b5d702d8253197f717f664b18c0ac3146eed5c913eddd5ddbf37fd1cd15b3abb"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Basic Imports\n",
      "import numpy as np\n",
      "import h5py as h5\n",
      "from sklearn.externals import joblib\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "from scipy import stats\n",
      "from sklearn.cross_validation import KFold\n",
      "import pickle\n",
      "import re"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#datasets\n",
      "\n",
      "#input data\n",
      "train_val_file = '/projects/nikhil/ADNI_prediction/input_datasets/cli_ct_seg_fused_train_plus_val.pkl'\n",
      "test_file = '/projects/francisco/data/ADNI/cli_ct_seg_fused_test.pkl'\n",
      "\n",
      "#k-fold indices (from a saved file)\n",
      "kf_file = \"/projects/nikhil/ADNI_prediction/input_datasets/cli_ct_train_valid_KFold_idx.pkl\"\n",
      "\n",
      "#save dir for trained model \n",
      "CV_model_dir = '/projects/nikhil/ADNI_prediction/models/CV_pkls/'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Grab CV data with specific feature columes (independent vars) and specific clinical scale (dependent var)\n",
      "def load_CV_data(in_file, kf_file, feature_cols, clinical_scale):\n",
      "\n",
      "    data = pd.read_pickle(in_file)\n",
      "    data_trunc = data[clinical_scale + feature_cols]\n",
      "    # remove nans\n",
      "    data_trunc = data_trunc[np.isfinite(data_trunc[clinical_scale[0]])]\n",
      "    X = np.asarray(data_trunc[feature_cols],dtype=float)\n",
      "    y = np.asarray(data_trunc[clinical_scale[0]],dtype=float)\n",
      "    \n",
      "    kf = pickle.load( open(kf_file, \"rb\" ) )\n",
      "    X_train = []\n",
      "    X_valid = []\n",
      "    y_train = []\n",
      "    y_valid = []\n",
      "    for train, valid in kf:        \n",
      "        X_train.append(X[train])\n",
      "        X_valid.append(X[valid])\n",
      "        y_train.append(y[train])\n",
      "        y_valid.append(y[valid])\n",
      "    \n",
      "    # Return train and validation lists comprising all folds as well as unsplit data\n",
      "    return {'X_train':X_train,'X_valid':X_valid,'y_train':y_train,'y_valid':y_valid,'X':X,'y':y}\n",
      "\n",
      "#Load test data\n",
      "def load_test_data(in_file, feature_cols, clinical_scale):\n",
      "\n",
      "    data = pd.read_pickle(in_file)\n",
      "    data_trunc = data[clinical_scale + feature_cols]\n",
      "    # remove nans\n",
      "    data_trunc = data_trunc[np.isfinite(data_trunc[clinical_scale[0]])]\n",
      "    X = np.asarray(data_trunc[feature_cols],dtype=float)\n",
      "    y = np.asarray(data_trunc[clinical_scale[0]],dtype=float)\n",
      "    return {'X':X, 'y':y}\n",
      "\n",
      "def innerCVLoop(model_clf,hyper_params,fold_X, fold_y,save_model,save_model_path):\n",
      "    clf = grid_search.GridSearchCV(model_clf, hyper_params,cv=3,verbose=0)\n",
      "    clf.fit(fold_X, fold_y)\n",
      "    #Save classifier\n",
      "    if save_model:\n",
      "        save_model(clf,save_model_path)\n",
      "        \n",
      "    return clf\n",
      "\n",
      "def save_classifier(clf,save_model_path):\n",
      "    ts = time.time()\n",
      "    st = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d-%H-%M-%S')\n",
      "    save_model_filename = save_model_path + '_' + st + '.pkl'\n",
      "        \n",
      "    f = open(save_model_filename, 'wb')\n",
      "    pickle.dump(clf, f)\n",
      "    f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 97
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Grab specific columns as features from the original table\n",
      "data = pd.read_pickle(train_val_file)\n",
      "data_cols = data.columns\n",
      "regex=re.compile(\".*(CT_).*\")\n",
      "CT_cols = [m.group(0) for l in data_cols for m in [regex.search(l)] if m] \n",
      "\n",
      "feature_cols = ['L_HC_VOL','R_HC_VOL'] + CT_cols\n",
      "clinical_scale = ['MMSE']\n",
      "\n",
      "cv_data = load_CV_data(train_val_file,kf_file, feature_cols, clinical_scale)\n",
      "test_data = load_test_data(test_file, feature_cols, clinical_scale)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 98
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# K-fold validations (nested)\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import Lasso\n",
      "from sklearn.svm import SVR\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn import grid_search\n",
      "import datetime\n",
      "import time\n",
      "import collections\n",
      "from scipy.stats import mode\n",
      "from sklearn.metrics import mean_squared_error as mse\n",
      "\n",
      "model_list = ['LR', 'LR_L1', 'SVR', 'RFR']\n",
      "model_choice_id = 2\n",
      "model_choice = model_list[model_choice_id]\n",
      "\n",
      "if model_choice == 'LR':\n",
      "    model_clf = LinearRegression()   \n",
      "    inner_loop = False #only needed to optimize hyper-params\n",
      "    feat_imp = False\n",
      "    saved_model_name = 'LR_2015-10-13-16-38-28.pkl'\n",
      "    \n",
      "elif model_choice == 'LR_L1':\n",
      "    model_clf = Lasso()\n",
      "    hyper_params = {'alpha':[0.2, 0.1, 0.05, 0.01]} \n",
      "    inner_loop = True #only needed to optimize hyper-params\n",
      "    feat_imp = False\n",
      "    if clinical_scale[0] == 'ADAS13':\n",
      "        saved_model_name = 'LR_L1_2015-10-13-16-47-35.pkl'\n",
      "    else:\n",
      "        saved_model_name = 'LR_L1_MMSE_2015-10-16-16-27-29.pkl'\n",
      "    \n",
      "elif model_choice == 'SVR':\n",
      "    model_clf = SVR()\n",
      "    hyper_params = {'kernel':('linear', 'rbf'), 'C':[1,2.5,5,7.5,10]}\n",
      "    inner_loop = True #only needed to optimize hyper-params\n",
      "    feat_imp = False\n",
      "    if clinical_scale[0] == 'ADAS13':\n",
      "        saved_model_name = 'SVR_2015-10-14-13-40-45.pkl'\n",
      "    else:\n",
      "        saved_model_name = 'SVR_MMSE_2015-10-16-18-02-11.pkl'\n",
      "    \n",
      "elif model_choice == 'RFR':\n",
      "    model_clf = RandomForestRegressor()\n",
      "    hyper_params = {'n_estimators':[50,100,200,500],'min_samples_split':[1,2,4,8]}\n",
      "    inner_loop = True #only needed to optimize hyper-params\n",
      "    feat_imp = True\n",
      "    if clinical_scale[0] == 'ADAS13':\n",
      "        saved_model_name = 'RFR_2015-10-13-15-15-11.pkl'\n",
      "    else:\n",
      "        saved_model_name = 'RFR_MMSE_2015-10-16-16-22-42.pkl'\n",
      "else:\n",
      "    print \"Unknown model choice\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 124
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "load_model_path = CV_model_dir + saved_model_name\n",
      "\n",
      "# train a new classifer? (if false then load a single pretrained classifier based on most frequent hyperparams found previously\n",
      "# This will NOT load N different classifiers each for outer-CV fold  \n",
      "train_clf = False\n",
      "\n",
      "cv_X_train = cv_data['X_train']\n",
      "cv_y_train = cv_data['y_train']\n",
      "cv_X_valid = cv_data['X_valid']\n",
      "cv_y_valid = cv_data['y_valid']\n",
      "\n",
      "no_of_folds = len(cv_X_train)\n",
      "\n",
      "CV_R2_train=[] #R2 score for each outer fold on train set\n",
      "CV_R2_valid=[] #R2 score for each outer fold on validation set\n",
      "\n",
      "CV_MSE_train=[] #MSE for each outer fold on train set\n",
      "CV_MSE_valid=[] #MSE for each outer fold on validation set\n",
      "\n",
      "save_model = False #do you want to save all classifiers per each fold? \n",
      "if train_clf:\n",
      "    # outer CV loop\n",
      "    hp_dict = collections.defaultdict(list) #store best hyper-parameters for each fold\n",
      "    for i in np.arange(no_of_folds):\n",
      "        fold_X = cv_X_train[i]\n",
      "        fold_y = cv_y_train[i]\n",
      "        \n",
      "        if inner_loop: \n",
      "            save_model_path_fold = save_model_path + '_fold_' + str(i)\n",
      "            clf = innerCVLoop(model_clf,hyper_params,fold_X, fold_y,save_model,save_model_path_fold)\n",
      "            for hp in hyper_params:\n",
      "                hp_dict[hp].append(clf.best_estimator_.get_params()[hp])\n",
      "\n",
      "        else:\n",
      "            clf = model_clf\n",
      "            clf.fit(fold_X,fold_y)\n",
      "        \n",
      "        #CV_score\n",
      "        CV_R2_train.append(clf.score(cv_X_train[i],cv_y_train[i]))\n",
      "        CV_R2_valid.append(clf.score(cv_X_valid[i],cv_y_valid[i]))\n",
      "        \n",
      "        CV_MSE_train.append(mse(clf.predict(cv_X_train[i]),cv_y_train[i]))\n",
      "        CV_MSE_valid.append(mse(clf.predict(cv_X_valid[i]),cv_y_valid[i]))\n",
      "           \n",
      "    #retrain model on the entire train + valid set with most frequent hyper-params during cross-val\n",
      "    if inner_loop:\n",
      "        hp_mode = {}\n",
      "        for hp in hyper_params:\n",
      "            hp_mode[hp] = mode(hp_dict[hp])[0][0]\n",
      "            \n",
      "        print 'most frequent hp:' + str(hp_mode)\n",
      "    \n",
      "else: \n",
      "    #Grabs the best classifer as a result of N-fold nested CV along with the MSE and R2 stats of the outerloop\n",
      "    f = open(load_model_path)\n",
      "    result = pickle.load(f)\n",
      "    test_clf = result['best_clf']\n",
      "    CV_R2_valid = result['CV_R2']\n",
      "    CV_MSE_valid = result['CV_MSE']\n",
      "    f.close()\n",
      "    \n",
      "print 'CV R2 (mean, std_err): ' + '{:04.2f}, {:04.2f}'.format(np.mean(CV_R2_valid),stats.sem(CV_R2_valid))\n",
      "print 'CV MSE (mean, std_err): ' + '{:04.2f}, {:04.2f}'.format(np.mean(CV_MSE_valid),stats.sem(CV_MSE_valid))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CV R2 (mean, std_err): -0.06, 0.02\n",
        "CV MSE (mean, std_err): 7.01, 0.46\n"
       ]
      }
     ],
     "prompt_number": 125
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Evaluate the test set based on most frequnt hyper-params\n",
      "if train_clf:\n",
      "    #test_clf = LinearRegression()  \n",
      "    #test_clf = Lasso(alpha=0.05)    \n",
      "    test_clf = SVR(kernel='linear',C=1)\n",
      "    #test_clf = RandomForestRegressor(n_estimators=500,min_samples_split=1)\n",
      "    test_clf.fit(cv_data['X'],cv_data['y'])\n",
      "\n",
      "    save_model = True\n",
      "    save_model_path = CV_model_dir + model_choice + '_' + clinical_scale[0]\n",
      "    if save_model:\n",
      "        classifier_model_and_stats = {'best_clf':test_clf, 'CV_R2':CV_R2_valid, 'CV_MSE':CV_MSE_valid}\n",
      "        save_classifier(classifier_model_and_stats,save_model_path)\n",
      "\n",
      "pearson_r_train  = stats.pearsonr(test_clf.predict(cv_data['X']),cv_data['y'])\n",
      "R2_train = test_clf.score(cv_data['X'],cv_data['y'])\n",
      "MSE_train = mse(test_clf.predict(cv_data['X']),cv_data['y'])\n",
      "\n",
      "pearson_r_test = stats.pearsonr(test_clf.predict(test_data['X']),test_data['y'])\n",
      "R2_test = test_clf.score(test_data['X'],test_data['y'])\n",
      "MSE_test = mse(test_clf.predict(test_data['X']),test_data['y'])\n",
      "\n",
      "print \"train r: \" + str(pearson_r_train), \"test r: \" + str(pearson_r_test)\n",
      "print \"train R2 score: \" + str(R2_train), \"train MSE: \" + str(MSE_train)\n",
      "print \"test R2 score: \" + str(R2_test), \"test MSE: \" + str(MSE_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "train r: (0.42441445587816001, 4.1149814659810774e-27) test r: (0.20988743481740268, 0.027753994954012567)\n",
        "train R2 score: 0.0934923050095 train MSE: 6.06149674847\n",
        "test R2 score: -0.15357089981 test MSE: 6.80521028094\n"
       ]
      }
     ],
     "prompt_number": 126
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 126
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Compute scores and MSEs\n",
      "\n",
      "y_cv_pred = test_clf.predict(cv_data['X'])\n",
      "y_test_pred = test_clf.predict(test_data['X'])\n",
      "\n",
      "x_data_array = [cv_data['y'],test_data['y']]\n",
      "y_data_array = [y_cv_pred,y_test_pred]\n",
      "lable_array = ['CV train performance','test performance']\n",
      "\n",
      "# only test perf\n",
      "#x_data_array = [test_data['y']]\n",
      "#y_data_array = [y_test_pred]\n",
      "#lable_array = ['test performance']\n",
      "\n",
      "plt.figure()\n",
      "font_small = 8\n",
      "font_med = 16\n",
      "font_large = 24\n",
      "no_of_plots = len(lable_array)\n",
      "plt.style.use('ggplot')\n",
      "plt_col = no_of_plots\n",
      "plt_row = 1\n",
      "\n",
      "for i in np.arange(no_of_plots):\n",
      "    x = x_data_array[i]\n",
      "    y = y_data_array[i]\n",
      "\n",
      "    plt.subplot(plt_row,plt_col,i+1)\n",
      "    plt.scatter(x, y, c='crimson', label=lable_array[i],s=40)\n",
      "    fit = np.polyfit(x,y,1)\n",
      "    fit_fn = np.poly1d(fit) \n",
      "    slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
      "    if p_value < 0.0001:\n",
      "        p_value_sig = '<0.0001'\n",
      "    else:\n",
      "        p_value_sig = str(p_value)\n",
      "        \n",
      "    label_str = 'r-value: {:04.2f}'.format(r_value) + '\\n' + 'p-value: ' + p_value_sig + '\\n' + 'std_err: {:04.2f}'.format(std_err) \n",
      "    # fit_fn is now a function which takes in x and returns an estimate for y\n",
      "    plt.plot(x, fit_fn(x),linewidth=3, label=label_str)\n",
      "    plt.title(model_choice,fontsize=font_large)\n",
      "    plt.xlabel('Actual Score',fontsize=font_large)\n",
      "    plt.ylabel('Predicted Score',fontsize=font_large)            \n",
      "    plt.legend(fontsize=font_med,loc=2)\n",
      "\n",
      "if feat_imp:\n",
      "    plt.figure()\n",
      "    #plt.subplot(plt_row,plt_col,4)\n",
      "    x_pos = np.arange(len(feature_cols))\n",
      "    \n",
      "    if model_choice == 'RFR':\n",
      "        feature_wts = test_clf.feature_importances_\n",
      "    elif model_choice == 'LR_L1':\n",
      "        feature_wts = np.squeeze(test_clf.coef_)\n",
      "    else: \n",
      "        print 'no feature_wt vector found'\n",
      "        \n",
      "    sorted_feat_idx = np.argsort(np.abs(feature_wts))[::-1]        \n",
      "    plt.bar(x_pos,feature_wts[sorted_feat_idx],color='crimson')\n",
      "    plt.ylabel('Feature Importance',fontsize=font_large)\n",
      "    #Sort the feature name list as well \n",
      "    sorted_feature_cols = []\n",
      "    for i,sort_idx in enumerate(sorted_feat_idx):\n",
      "        sorted_feature_cols.append(feature_cols[sort_idx])\n",
      "\n",
      "    plt.xticks(x_pos,sorted_feature_cols,rotation=70,fontsize=font_small)\n",
      "    \n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 127
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 128
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Additional Scripts \n",
      "# Concat of Train + Valid (to generate multi-folds)\n",
      "t_data = pd.read_pickle(train_file)\n",
      "v_data = pd.read_pickle(valid_file)\n",
      "frames = [t_data, v_data]\n",
      "result = pd.concat(frames)\n",
      "result.to_pickle(\"/projects/nikhil/ADNI_prediction/input_datasets/cli_ct_seg_fused_train_plus_val.pkl\")\n",
      "\n",
      "# Generatng K-Folds\n",
      "sampx = 100 #Train + Valid samples\n",
      "foldx = 10   \n",
      "kf = KFold(sampx, n_folds=foldx,shuffle=True)\n",
      "\n",
      "#for train, test in kf:\n",
      "#    print(\"%s %s\" % (train, test))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}