{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prognositc (trajectory prediction) performance of baseline ML models on ADNI2 longitudinal data\n",
    "\n",
    "* **Objectives:** \n",
    "    1. Predict Trajectory classes based on structural features\n",
    "    2. Predict Trajectory classes based on structural features + baseline clinical score + demographics\n",
    "\n",
    "\n",
    "* **Input modalities:**\n",
    "    1. Coritcal thickness (CT)\n",
    "    2. Hippocampal subfield volumes (HC) \n",
    "\n",
    "\n",
    "* **Models:**\n",
    "    1. Logistic regression (Lasso)\n",
    "    2. SVM\n",
    "    3. Random Forest\n",
    "    \n",
    "    \n",
    "* **Code organization:**\n",
    "    1. Stage 1: \n",
    "        1. Import raw data, and setup CV folds based on choice of input features \n",
    "        2. Save this experimental setup to disk\n",
    "        \n",
    "    2. Stage 2:\n",
    "        1. Train and test ML models over k-fold setup (Parallelized implmentation)\n",
    "        2. Plot and save performance results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/nikhil/ADNI_prediction/code/conda_envs/adni-conda/lib/python2.7/site-packages/pandas/computation/__init__.py:19: UserWarning: The installed version of numexpr 2.4.4 is not supported in pandas and will be not be used\n",
      "\n",
      "  UserWarning)\n",
      "/projects/nikhil/ADNI_prediction/code/conda_envs/adni-conda/lib/python2.7/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n",
      "/projects/nikhil/ADNI_prediction/code/conda_envs/adni-conda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Basic Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import pickle\n",
    "import re\n",
    "import collections\n",
    "import tables as tb\n",
    "from math import isnan\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "%matplotlib inline\n",
    "#plt.rcParams['figure.figsize'] = (15, 10)\n",
    "#plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Some Defs\n",
    "def load_data(data_path, input_node, preproc):\n",
    "    data = tb.open_file(data_path, 'r')\n",
    "    X_raw = data.get_node('/' + input_node)[:]\n",
    "    if preproc == 'scale':\n",
    "        X = preprocessing.scale(X_raw)\n",
    "    elif preproc == 'norm_max':\n",
    "        X = preprocessing.normalize(X_raw, norm='max')\n",
    "    elif preproc == 'norm_l2':\n",
    "        X = preprocessing.normalize(X_raw, norm='l2')\n",
    "    else:\n",
    "        X = X_raw\n",
    "    data.close()\n",
    "    return X\n",
    "\n",
    "def pickleIt(my_data,save_path):\n",
    "    f = open(save_path, 'wb')\n",
    "    pickle.dump(my_data, f)\n",
    "    f.close()\n",
    "\n",
    "#Outer Fold Computation (need the imports inside def if you want to parallelize!)\n",
    "def computeOuterFold(train_X, train_y, valid_X, valid_y, model_clf, hyper_params, output_type, model_type):    \n",
    "    import collections\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.linear_model import Lasso\n",
    "    from sklearn.svm import SVR\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn import grid_search\n",
    "    import datetime\n",
    "    import time\n",
    "    import collections\n",
    "    from scipy.stats import mode\n",
    "    from sklearn.metrics import mean_squared_error as mse\n",
    "    from sklearn.metrics import mean_absolute_error as mae\n",
    "    from scipy import stats\n",
    "    import numpy as np\n",
    "    \n",
    "    print 'Starting Outerfold computation'\n",
    "    \n",
    "    hp_dict = collections.defaultdict(list) #store best hyper-parameters for each fold\n",
    "    inner_loop = True\n",
    "    if inner_loop:     \n",
    "        print 'Starting InnerFold computation'        \n",
    "        clf = innerCVLoop(model_clf,hyper_params,train_X, train_y)\n",
    "        for hp in hyper_params:\n",
    "            hp_dict[hp].append(clf.best_estimator_.get_params()[hp])\n",
    "            \n",
    "        print 'Ending InnerFold computation'\n",
    "\n",
    "    else:\n",
    "        clf = model_clf\n",
    "        clf.fit(fold_X,fold_y)\n",
    "    \n",
    "    if output_type == 'regression':\n",
    "        #CV_scores    \n",
    "        r_train = stats.pearsonr(clf.predict(train_X),train_y)\n",
    "        r_valid = stats.pearsonr(clf.predict(valid_X),valid_y)\n",
    "\n",
    "        R2_train = clf.score(train_X,train_y) \n",
    "        R2_valid = clf.score(valid_X,valid_y)\n",
    "\n",
    "        MSE_train = mse(clf.predict(train_X),train_y)\n",
    "        MSE_valid = mse(clf.predict(valid_X),valid_y)\n",
    "\n",
    "        MAE_train = mae(clf.predict(train_X),train_y)\n",
    "        MAE_valid = mae(clf.predict(valid_X),valid_y)\n",
    "        \n",
    "        return_dict = {'r_train':r_train, 'r_valid':r_valid, 'R2_train':R2_train, 'R2_valid':R2_valid,\n",
    "            'MSE_train':MSE_train, 'MSE_valid':MSE_valid, 'MAE_train':MAE_train, 'MAE_valid':MAE_valid,\n",
    "            'hp_dict':hp_dict, 'predicted_fold_score': clf.predict(valid_X), 'actual_fold_scores':valid_y}\n",
    "        \n",
    "    elif output_type == 'classify':\n",
    "        pred_y = clf.predict(valid_X) #Specific label value\n",
    "        pred_y_prob = clf.predict_proba(valid_X) #Label probabilty (used for ROC)\n",
    "\n",
    "        #feature imp (issue with the innerCVLoop)\n",
    "        if model_type == 'RFC':\n",
    "            feat_imp = clf.best_estimator_.feature_importances_\n",
    "        elif model_type == 'LR_L1':\n",
    "            feat_imp = clf.best_estimator_.coef_ \n",
    "        else: \n",
    "            print \"Unknown model for computing feature importance. Setting it to zeros\"\n",
    "            feat_imp = np.zeros(len(pred_y))\n",
    "\n",
    "        print 'Ending OuterFold computation'\n",
    "\n",
    "        return_dict = {'actual_fold_scores':valid_y, 'predicted_fold_prob':pred_y_prob, 'predicted_fold_score': pred_y, \n",
    "                'hp_dict':hp_dict, 'feat_imp': feat_imp}\n",
    "    \n",
    "    else: \n",
    "        print 'unknown output_type'\n",
    "\n",
    "    print 'Ending OuterFold computation'\n",
    "    \n",
    "    return return_dict\n",
    "\n",
    "#Inner Fold Computation (need the imports inside def if you want to parallelize!)\n",
    "def innerCVLoop(model_clf,hyper_params,fold_X, fold_y):\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.linear_model import Lasso\n",
    "    from sklearn.svm import SVR\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn import grid_search\n",
    "    clf = grid_search.GridSearchCV(model_clf, hyper_params,cv=3,verbose=0)\n",
    "    clf.fit(fold_X, fold_y)   \n",
    "    return clf\n",
    "\n",
    "def autolabel(rects,_ax):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        _ax.text(rect.get_x() + rect.get_width()/2., 1.1*height,\n",
    "                '{:03.2f}'.format(height),\n",
    "                ha='center',            # vertical alignment\n",
    "                va='bottom',             # horizontal alignment\n",
    "                fontsize = 35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data imports\n",
    "my_name = 'Exp6_MCI_demograph'\n",
    "cohort = 'ADNI2'\n",
    "clinical_scale = 'ADAS13'\n",
    "exp_name = '{}_{}_{}'.format(my_name,cohort,clinical_scale)\n",
    "\n",
    "baseline_dir = '/projects/nikhil/ADNI_prediction/input_datasets/longitudinal_trajectories/'\n",
    "#in_data_file = 'input_csv/Longitduinal_HC_CT_data.csv'\n",
    "in_data_file = 'input_csv/Longitduinal_HC_CT_data_MCI_traj.csv'\n",
    "in_data = pd.read_csv(baseline_dir + in_data_file)\n",
    "\n",
    "in_data.replace(['Male','Female'],[0,1], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# features / variables\n",
    "clinical_scale = ['ADAS13']\n",
    "hc_feat = ['L_CA1','L_subiculum','L_CA4DG','L_CA2CA3','L_stratum','L_Alv','L_Fimb','L_Fornix','L_Mam',\n",
    "                 'R_CA1','R_subiculum','R_CA4DG','R_CA2CA3','R_stratum','R_Alv','R_Fimb','R_Fornix','R_Mam']\n",
    "ct_feat = ['AAL_1', 'AAL_2', 'AAL_3','AAL_4', 'AAL_5', 'AAL_6', 'AAL_7', 'AAL_8', 'AAL_9', 'AAL_10',\n",
    "                 'AAL_11', 'AAL_12', 'AAL_13', 'AAL_14', 'AAL_15', 'AAL_16', 'AAL_17', 'AAL_18', 'AAL_19', 'AAL_20', \n",
    "                 'AAL_21', 'AAL_22', 'AAL_23', 'AAL_24', 'AAL_25', 'AAL_26', 'AAL_27', 'AAL_28', 'AAL_29', 'AAL_30', \n",
    "                 'AAL_31', 'AAL_32', 'AAL_33', 'AAL_34', 'AAL_35', 'AAL_36', 'AAL_39', 'AAL_40', 'AAL_43', 'AAL_44', \n",
    "                 'AAL_45', 'AAL_46', 'AAL_47', 'AAL_48', 'AAL_49', 'AAL_50', 'AAL_51', 'AAL_52', 'AAL_53', 'AAL_54',\n",
    "                 'AAL_55', 'AAL_56', 'AAL_57', 'AAL_58', 'AAL_59', 'AAL_60', 'AAL_61', 'AAL_62', 'AAL_63', 'AAL_64', \n",
    "                 'AAL_65', 'AAL_66', 'AAL_67', 'AAL_68', 'AAL_69', 'AAL_70', 'AAL_79', 'AAL_80', 'AAL_81', 'AAL_82',\n",
    "                 'AAL_83', 'AAL_84', 'AAL_85', 'AAL_86', 'AAL_87', 'AAL_88', 'AAL_89', 'AAL_90']\n",
    "\n",
    "\n",
    "# Pick input features (modalities)\n",
    "mr_feat = hc_feat + ct_feat + clinical_scale\n",
    "\n",
    "#Pick timepoints for input and output variables\n",
    "timepoint_mr = '_bl'\n",
    "timepoint_cs = '_bl'\n",
    "\n",
    "feat=[]\n",
    "for c, cs in enumerate(clinical_scale):\n",
    "    clinical_scale[c] = cs + timepoint_cs\n",
    "for m, mr in enumerate(mr_feat):\n",
    "    feat.append(mr + timepoint_mr)\n",
    "\n",
    "#additional timpoint for structural features (hc or ct)\n",
    "# timepoint_mr = '_m06'\n",
    "# for m, mr in enumerate(mr_feat):\n",
    "#     feat.append(mr + timepoint_mr)\n",
    "    \n",
    "#add demographics\n",
    "feat.append('AGE')\n",
    "feat.append('APOE4')\n",
    "feat.append('PTGENDER')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:(156, 100), y shape:(156,), dx shape:(156,)\n",
      "# of Class 1 subjects: 81:\n"
     ]
    }
   ],
   "source": [
    "#Trajectory stats\n",
    "traj_threshold = 'Traj'\n",
    "X = np.array(in_data[feat])\n",
    "y = np.squeeze(np.array(in_data[traj_threshold]))\n",
    "#y_dx = np.squeeze(np.array(in_data[['DX_cat'+timepoint_mr]]))\n",
    "y_dx = np.squeeze(np.array(in_data[traj_threshold]))\n",
    "\n",
    "filtered_idx = np.isfinite(y)\n",
    "y = y[filtered_idx]\n",
    "y_dx = y_dx[filtered_idx]\n",
    "X = X[filtered_idx,:]\n",
    "\n",
    "print 'X shape:{}, y shape:{}, dx shape:{}'.format(X.shape, y.shape, y_dx.shape)\n",
    "print '# of Class 1 subjects: {}:'.format(len(y[y==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified KFold\n",
      "DX distribution (AD,CN,LMCI): (8, 9, 0)\n",
      "y_train_mean: 0.517985611511, y_test_mean: 0.529411764706\n",
      "DX distribution (AD,CN,LMCI): (8, 8, 0)\n",
      "y_train_mean: 0.521428571429, y_test_mean: 0.5\n",
      "DX distribution (AD,CN,LMCI): (8, 8, 0)\n",
      "y_train_mean: 0.521428571429, y_test_mean: 0.5\n",
      "DX distribution (AD,CN,LMCI): (8, 8, 0)\n",
      "y_train_mean: 0.521428571429, y_test_mean: 0.5\n",
      "DX distribution (AD,CN,LMCI): (8, 8, 0)\n",
      "y_train_mean: 0.521428571429, y_test_mean: 0.5\n",
      "DX distribution (AD,CN,LMCI): (7, 8, 0)\n",
      "y_train_mean: 0.517730496454, y_test_mean: 0.533333333333\n",
      "DX distribution (AD,CN,LMCI): (7, 8, 0)\n",
      "y_train_mean: 0.517730496454, y_test_mean: 0.533333333333\n",
      "DX distribution (AD,CN,LMCI): (7, 8, 0)\n",
      "y_train_mean: 0.517730496454, y_test_mean: 0.533333333333\n",
      "DX distribution (AD,CN,LMCI): (7, 8, 0)\n",
      "y_train_mean: 0.517730496454, y_test_mean: 0.533333333333\n",
      "DX distribution (AD,CN,LMCI): (7, 8, 0)\n",
      "y_train_mean: 0.517730496454, y_test_mean: 0.533333333333\n",
      "Saving exp_setup to: /projects/nikhil/ADNI_prediction/input_datasets/longitudinal_trajectories/exp_setup/CV_Exp6_MCI_demograph_ADNI2_ADAS13_MR_bl_CS_bl_hclust_Traj.pkl\n"
     ]
    }
   ],
   "source": [
    "# Create folds for CV (default Stratified based on DX)\n",
    "save_experimental_setup = False #Saves X, y, and KF\n",
    "\n",
    "n_folds = 10\n",
    "KF_type = 'stratified' #baseline_dir + 'exp_data/CV_Exp6_ADNI1and2_ADAS13.pkl'  #'path/to/previous/setup' or 'stratified' or 'none'\n",
    "if KF_type == 'none':\n",
    "    print 'KFold'\n",
    "    kf = KFold(len(y), n_folds=10)\n",
    "elif KF_type == 'stratified': \n",
    "    print 'Stratified KFold'\n",
    "    kf = StratifiedKFold(y_dx, n_folds=10)\n",
    "else:\n",
    "    print 'Loading previously saved KF from: {}'.format(KF_type)\n",
    "    old_exp_setup = pickle.load( open(KF_type, \"rb\" ) )\n",
    "    kf = old_exp_setup['kf']\n",
    "    \n",
    "for train_index, test_index in kf:    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    print 'DX distribution (AD,CN,LMCI): {}'.format((np.sum(y_dx[test_index]==0),np.sum(y_dx[test_index]==1),\n",
    "                                              np.sum(y_dx[test_index]==2)))\n",
    "    print 'y_train_mean: {}, y_test_mean: {}'.format(np.mean(y_train),np.mean(y_test))\n",
    "\n",
    "common_keys = in_data[['ImageUID']] #Uniq image ids for mapping subjects\n",
    "\n",
    "save_path = baseline_dir + 'exp_setup/CV_{}_MR{}_CS{}_hclust_{}.pkl'.format(exp_name,timepoint_mr,timepoint_cs,traj_threshold)    \n",
    "print 'Saving exp_setup to: {}'.format(save_path)\n",
    "if save_experimental_setup:    \n",
    "    exp_setup = {'X': X, 'y': y, 'y_dx': y_dx, 'kf':kf,'common_subs':common_keys,'exp_name':exp_name}    \n",
    "    pickleIt(exp_setup, save_path)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# QC plots\n",
    "qc_dict = {}\n",
    "foldx = 0\n",
    "idx = 0\n",
    "for train_index, test_index in kf:        \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "    for i in range(X_train.shape[1]): \n",
    "        if i < 18:\n",
    "            modality = 'hc'\n",
    "        else: \n",
    "            modality = 'ct'\n",
    "            \n",
    "        vol_mean_train = np.mean(X_train[:,i])\n",
    "        corr_train = stats.pearsonr(X_train[:,i],y_train)[0]                \n",
    "        qc_dict[idx]={'structure':mr_feat[i],'subset':'train','vol':vol_mean_train,'r':corr_train,'fold':foldx,'modality':modality}\n",
    "        idx += 1\n",
    "        \n",
    "        vol_mean_test = np.mean(X_test[:,i])\n",
    "        corr_test = stats.pearsonr(X_test[:,i],y_test)[0]        \n",
    "        qc_dict[idx]={'structure':mr_feat[i],'subset':'test','vol':vol_mean_test,'r':corr_test,'fold':foldx,'modality':modality}\n",
    "        idx += 1\n",
    "    \n",
    "    foldx += 1\n",
    "    \n",
    "qc_df = pd.DataFrame.from_dict(qc_dict,orient='index')\n",
    "sns.set_context(\"notebook\", font_scale=1)\n",
    "sns.set_style(\"ticks\")\n",
    "modality = 'hc'\n",
    "measure = 'r'\n",
    "g = sns.factorplot(x='structure', y=measure, hue='subset', col='fold', col_wrap=2, data=qc_df[qc_df.modality==modality], size=5, kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[97, 98]\n"
     ]
    }
   ],
   "source": [
    "a = range(99)\n",
    "b=a[-2:]\n",
    "print b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Stage 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/nikhil/ADNI_prediction/code/conda_envs/adni-conda/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Configs for K-fold validations (nested)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import grid_search\n",
    "import datetime\n",
    "import time\n",
    "import collections\n",
    "from scipy.stats import mode\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from functools import partial #Parallelize!!! \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from scipy import interp\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "import ipyparallel as ipp\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import KFold\n",
    "import pickle\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import ADASYN #For treating class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Pick model with its configs/hyper-paramsd\n",
    "def getModel(model_choice,output_type): \n",
    "    if output_type == 'regression' :\n",
    "        if model_choice == 'LR_L1':\n",
    "            model_clf = Lasso()\n",
    "            hyper_params = {'alpha':[0.1, 0.05, 0.01]} \n",
    "            scale_data = True #Scales HC and CT features    \n",
    "            feat_imp = False   \n",
    "\n",
    "        elif model_choice == 'SVR':\n",
    "            model_clf = SVR()\n",
    "            hyper_params = {'kernel':['linear','rbf'], 'C':[1,10,25]}\n",
    "            scale_data = True #Scales HC and CT features        \n",
    "            feat_imp = False\n",
    "\n",
    "        elif model_choice == 'RFR':\n",
    "            model_clf = RandomForestRegressor(n_jobs=4)\n",
    "            hyper_params = {'n_estimators':[10,50,100,200],'min_samples_split':[2,4,8]}    \n",
    "            scale_data = False    \n",
    "            feat_imp = False   \n",
    "        else:\n",
    "            print \"Unknown model choice\"\n",
    "    \n",
    "    elif output_type =='classify':\n",
    "        if model_choice == 'LR_L1':\n",
    "            model_clf = LogisticRegression(penalty='l1',n_jobs=4,class_weight='balanced')\n",
    "            hyper_params = {'C':[.1,1,10]} \n",
    "            scale_data = True #Scales features (z-score)            \n",
    "            feat_imp = False #The learned weights of each variable\n",
    "\n",
    "        elif model_choice == 'SVC':\n",
    "            model_clf = SVC(class_weight='balanced',probability=True)\n",
    "            hyper_params = {'kernel':['linear','rbf'], 'C':[.1,1,5,10]}\n",
    "            scale_data = True #Scales HC and CT features            \n",
    "            feat_imp = False\n",
    "\n",
    "        elif model_choice == 'RFC':    \n",
    "            model_clf = RandomForestClassifier(n_jobs=8,class_weight='balanced' )\n",
    "            hyper_params = {'n_estimators':[10,50,100,200],'min_samples_split':[2,4,8]}    \n",
    "            scale_data = False            \n",
    "            feat_imp = True   #RF oob based feature importance\n",
    "\n",
    "        else:\n",
    "            print \"Unknown model choice\"\n",
    "    \n",
    "    else: \n",
    "        print 'Unknown output type'\n",
    "\n",
    "    return {'model_clf':model_clf,'hyper_params':hyper_params,'scale_data':scale_data,'feat_imp':feat_imp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modality: CS, model: LR_L1, X shape (156, 3)\n",
      "most frequent hyper-params:{'C': array([10])}\n",
      "CV Acc (mean, std_err): 0.59, 0.04\n",
      "CV AUC (mean, std_err): 0.58, 0.05\n",
      "CV Confusion Matrix (mean): [[ 0.57587302  0.42412698]\n",
      " [ 0.39164502  0.60835498]]\n",
      "\n",
      "Modality: CS, model: SVC, X shape (156, 3)\n",
      "most frequent hyper-params:{'kernel': array(['linear'], \n",
      "      dtype='|S6'), 'C': array([ 0.1])}\n",
      "CV Acc (mean, std_err): 0.60, 0.05\n",
      "CV AUC (mean, std_err): 0.57, 0.05\n",
      "CV Confusion Matrix (mean): [[ 0.56865079  0.43134921]\n",
      " [ 0.38378788  0.61621212]]\n",
      "\n",
      "Modality: CS, model: RFC, X shape (156, 3)\n",
      "most frequent hyper-params:{'n_estimators': array([10]), 'min_samples_split': array([2])}\n",
      "CV Acc (mean, std_err): 0.55, 0.03\n",
      "CV AUC (mean, std_err): 0.58, 0.04\n",
      "CV Confusion Matrix (mean): [[ 0.53273504  0.46726496]\n",
      " [ 0.42358586  0.57641414]]\n",
      "\n",
      "Modality: HC_CT_CS, model: LR_L1, X shape (156, 99)\n",
      "most frequent hyper-params:{'C': array([1])}\n",
      "CV Acc (mean, std_err): 0.58, 0.04\n",
      "CV AUC (mean, std_err): 0.65, 0.04\n",
      "CV Confusion Matrix (mean): [[ 0.57631674  0.42368326]\n",
      " [ 0.40312771  0.59687229]]\n",
      "\n",
      "Modality: HC_CT_CS, model: SVC, X shape (156, 99)\n",
      "most frequent hyper-params:{'kernel': array(['rbf'], \n",
      "      dtype='|S6'), 'C': array([5])}\n",
      "CV Acc (mean, std_err): 0.62, 0.03\n",
      "CV AUC (mean, std_err): 0.68, 0.03\n",
      "CV Confusion Matrix (mean): [[ 0.60105339  0.39894661]\n",
      " [ 0.36164502  0.63835498]]\n",
      "\n",
      "Modality: HC_CT_CS, model: RFC, X shape (156, 99)\n",
      "most frequent hyper-params:{'n_estimators': array([100]), 'min_samples_split': array([8])}\n",
      "CV Acc (mean, std_err): 0.61, 0.03\n",
      "CV AUC (mean, std_err): 0.71, 0.03\n",
      "CV Confusion Matrix (mean): [[ 0.60264069  0.39735931]\n",
      " [ 0.36075397  0.63924603]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/nikhil/ADNI_prediction/code/conda_envs/adni-conda/lib/python2.7/site-packages/scipy/stats/stats.py:250: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  \"values. nan values will be ignored.\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# Train and Test models\n",
    "from functools import partial #Parallelize!!! \n",
    "\n",
    "# Load saved experimental setup\n",
    "exp_name = 'Exp6_MCI_demograph'\n",
    "Clinical_Scale = 'ADAS13'\n",
    "timepoint_mr = 'bl'\n",
    "timepoint_cs = 'bl'\n",
    "resample_train_data = False\n",
    "sampling_tech = 'smote'\n",
    "\n",
    "exp_setup_path = baseline_dir + 'exp_setup/CV_{}_ADNI2_{}_MR_{}_CS_{}_hclust_Traj.pkl'.format(exp_name,Clinical_Scale,timepoint_mr,timepoint_cs)\n",
    "exp_setup = pickle.load( open(exp_setup_path, \"rb\" ) )\n",
    "\n",
    "# Parallization configs for ipython notebook cluster    \n",
    "rc = ipp.Client()\n",
    "dview = rc[:]\n",
    "dview.push(dict(computeOuterFold = computeOuterFold))\n",
    "dview.push(dict(innerCVLoop = innerCVLoop))\n",
    "\n",
    "modalities = ['CS','HC_CT_CS']\n",
    "X_raw = exp_setup['X']\n",
    "y = exp_setup['y']\n",
    "kf = exp_setup['kf']\n",
    "exp_name = exp_setup['exp_name']\n",
    "\n",
    "output_type = 'classify' #needs to be either 'classify' or 'regression'\n",
    "if output_type == 'regression':\n",
    "    model_list = ['LR_L1', 'SVR', 'RFR']\n",
    "elif output_type == 'classify':\n",
    "    model_list = ['LR_L1', 'SVC', 'RFC']\n",
    "else:\n",
    "    print 'unknow output type'\n",
    "\n",
    "save_CV_perf = False \n",
    "\n",
    "hc_offset = 18\n",
    "ct_offset = 96\n",
    "long_offset = 97 #number of total features in each timepoint (18+78+1)\n",
    "#######################\n",
    "use_demograph = True\n",
    "#######################\n",
    "idx = 1\n",
    "df_perf_dict = {}\n",
    "for modality in modalities:    \n",
    "    if modality == 'HC_CT_CS_long':\n",
    "        X_modality = X_raw[:,:2*long_offset]\n",
    "    elif modality == 'HC_CT_CS':\n",
    "        X_modality = X_raw[:,:long_offset]\n",
    "        #X_modality = np.hstack((X_raw[:,:5],X_raw[:,9:14],X_raw[:,18:long_offset])) #exclude white matter\n",
    "    elif modality == 'HC_CT':\n",
    "        X_modality = X_raw[:,:ct_offset]\n",
    "        #X_modality = np.hstack((X_raw[:,:5],X_raw[:,9:14],X_raw[:,18:ct_offset])) #exclude white matter\n",
    "    elif modality == 'HC_CT_long':\n",
    "        X_modality = np.hstack((X_raw[:,:ct_offset],X_raw[:,long_offset:long_offset+ct_offset]))\n",
    "    elif modality == 'HC_CS':\n",
    "        X_modality = np.hstack((X_raw[:,:hc_offset],X_raw[:,ct_offset:long_offset]))\n",
    "    elif modality == 'CT_CS':\n",
    "        X_modality = X_raw[:,hc_offset:long_offset]\n",
    "    elif modality == 'HC_CS_long':\n",
    "        X_modality = np.hstack((X_raw[:,:hc_offset],X_raw[:,ct_offset:long_offset],X_raw[:,long_offset:long_offset+hc_offset],X_raw[:,long_offset+ct_offset:2*long_offset]))\n",
    "    elif modality == 'CT_CS_long':\n",
    "        X_modality = np.hstack((X_raw[:,hc_offset:97],X_raw[:,long_offset+hc_offset:long_offset+97]))\n",
    "    elif modality == 'HC':\n",
    "        X_modality = X_raw[:,:hc_offset]\n",
    "    elif modality == 'CT':\n",
    "        X_modality = X_raw[:,hc_offset:ct_offset]\n",
    "    elif modality == 'CS':\n",
    "        X_modality = X_raw[:,ct_offset:long_offset]\n",
    "    elif modality == 'CS_long':\n",
    "        X_modality = np.hstack((X_raw[:,ct_offset:long_offset],X_raw[:,long_offset+ct_offset:2*long_offset]))\n",
    "    else:\n",
    "        print \"Wrong modality selected...\"\n",
    "    \n",
    "    if modality in ['HC','CT','HC_CT']:\n",
    "        use_demograph = False\n",
    "    if use_demograph:\n",
    "        X_modality = np.hstack((X_modality,X_raw[:,-2:])) #last two variable are age and apoe4\n",
    "\n",
    "    ####################\n",
    "    ## Select a model ##\n",
    "    ####################       \n",
    "    for model_choice in model_list:\n",
    "        model_def = getModel(model_choice,output_type)\n",
    "        model_clf = model_def['model_clf']\n",
    "        hyper_params = model_def['hyper_params']\n",
    "        scale_data = model_def['scale_data']    \n",
    "        feat_imp = model_def['feat_imp']\n",
    "\n",
    "        if scale_data:\n",
    "            X = preprocessing.scale(X_modality)\n",
    "        else:\n",
    "            X = X_modality\n",
    "\n",
    "        print 'Modality: {}, model: {}, X shape {}'.format(modality, model_choice, X.shape)\n",
    "        #Some paths to store models and performance stats\n",
    "        CV_model_dir = baseline_dir + 'output/'\n",
    "        save_model_path = CV_model_dir + exp_name + '_' + model_choice + '_' + modality\n",
    "        save_model = False \n",
    "        \n",
    "        # Create list of all the fold-subsets (needed for parallelization)\n",
    "        X_train = []\n",
    "        X_valid = []\n",
    "        y_train = []\n",
    "        y_valid = []    \n",
    "        for train, valid in kf:\n",
    "            if resample_train_data:             \n",
    "                #resample with tools from: https://github.com/scikit-learn-contrib/imbalanced-learn\n",
    "                if sampling_tech == 'adasyn':                    \n",
    "                    resamp_tech = ADASYN()\n",
    "                elif sampling_tech == 'smote':\n",
    "                    resamp_tech = SMOTE(kind='regular')\n",
    "                else:\n",
    "                    resamp_tech = RandomOverSampler()\n",
    "                \n",
    "                print 'using {} oversampling technique'.format(sampling_tech)                    \n",
    "                X_resampled, y_resampled = resamp_tech.fit_sample(X[train], y[train])\n",
    "                #print 'Original shapes: X{}, y:{}, y==1: {}'.format(X[train].shape, y[train].shape, np.sum(y[train]))\n",
    "                #print 'Resampled shapes: X{}, y:{}, y==1: {}'.format(X_resampled.shape, y_resampled.shape, np.sum(y_resampled))                \n",
    "                X_train.append(X_resampled)\n",
    "                y_train.append(y_resampled)\n",
    "            else:\n",
    "                X_train.append(X[train])\n",
    "                y_train.append(y[train])\n",
    "            \n",
    "            # No need to resample test data\n",
    "            X_valid.append(X[valid])            \n",
    "            y_valid.append(y[valid])\n",
    "\n",
    "        # Compute various statistics on the predicted results acorss 10 Folds    \n",
    "        if output_type == 'regression':\n",
    "            CV_r_train=[] #pearson r score for each outer fold on train set\n",
    "            CV_r_valid=[] #pearson r score for each outer fold on validation set\n",
    "            CV_R2_train=[] #R2 score for each outer fold on train set\n",
    "            CV_R2_valid=[] #R2 score for each outer fold on validation set\n",
    "            CV_MSE_train=[] #MSE for each outer fold on train set\n",
    "            CV_MSE_valid=[] #MSE for each outer fold on validation set    \n",
    "            CV_MAE_train=[] #MSE for each outer fold on train set\n",
    "            CV_MAE_valid=[] #MSE for each outer fold on validation set\n",
    "        elif output_type == 'classify':        \n",
    "            CV_Acc_valid=[] #Acuracy\n",
    "            CV_CM_valid=[] #Confusion matrix\n",
    "            CV_AUC_valid=[] #ROC and AUC                   \n",
    "            CV_feat_imp = []\n",
    "        else: \n",
    "            print 'unknown output type'\n",
    "\n",
    "        predicted_CV_scores = []\n",
    "        actual_CV_scores = []\n",
    "\n",
    "        #Parallelize k-folds\n",
    "        mapfunc = partial(computeOuterFold, model_clf=model_clf, hyper_params=hyper_params, output_type=output_type, model_type=model_choice)\n",
    "        parallel_result = dview.map_sync(mapfunc, X_train, y_train, X_valid, y_valid)    \n",
    "\n",
    "        hp_dict = collections.defaultdict(list)\n",
    "        for p, pr in enumerate(parallel_result):\n",
    "            if output_type == 'regression':\n",
    "                CV_r_train.append(pr['r_train'])\n",
    "                CV_r_valid.append(pr['r_valid'])\n",
    "                CV_R2_train.append(pr['R2_train'])\n",
    "                CV_R2_valid.append(pr['R2_valid'])\n",
    "                CV_MSE_train.append(pr['MSE_train'])\n",
    "                CV_MSE_valid.append(pr['MSE_valid'])\n",
    "                CV_MAE_train.append(pr['MAE_train'])\n",
    "                CV_MAE_valid.append(pr['MAE_valid'])\n",
    "                predicted_CV_scores.append(pr['predicted_fold_score'])\n",
    "                actual_CV_scores.append(pr['actual_fold_scores'])                \n",
    "                    \n",
    "            elif output_type == 'classify':\n",
    "                y_pred_score = pr['predicted_fold_score']\n",
    "                y_pred_prob = pr['predicted_fold_prob']\n",
    "                y_act = pr['actual_fold_scores']\n",
    "                predicted_CV_scores.append(y_pred_score)\n",
    "                actual_CV_scores.append(y_act)        \n",
    "\n",
    "                #Acc    \n",
    "                CV_accuracy = acc(y_pred_score,y_act)\n",
    "                CV_Acc_valid.append(CV_accuracy)                \n",
    "\n",
    "                #AUC                \n",
    "                CV_auc = roc_auc_score(y_act, y_pred_prob[:,1])\n",
    "                CV_AUC_valid.append(CV_auc)\n",
    "\n",
    "                #confusion matrix\n",
    "                cm = confusion_matrix(y_pred_score,y_act)\n",
    "                cm_normalized = cm.astype('float')/cm.sum(axis=1)[:, np.newaxis]\n",
    "                CV_CM_valid.append(cm_normalized)\n",
    "                \n",
    "                df_perf_dict[idx] = {'modality':modality,'model_choice':model_choice,'KF':p+1, 'act_scores':y_act,\n",
    "                                    'pred_scores':y_pred_score,'pred_prob':y_pred_prob, 'Accuracy':CV_accuracy,\n",
    "                                    'AUC':CV_auc,'CM':cm_normalized}\n",
    "                idx+=1\n",
    "                \n",
    "            for hp in hyper_params:\n",
    "                hp_dict[hp].append(pr['hp_dict'][hp])\n",
    "                \n",
    "        #Find out most frequent hyper-params during cross-val    \n",
    "        hp_mode = {}\n",
    "        for hp in hyper_params:\n",
    "            hp_mode[hp] = mode(hp_dict[hp])[0][0]\n",
    "\n",
    "        if output_type == 'regression':\n",
    "            print 'most frequent hp:' + str(hp_mode)\n",
    "            print 'CV r (mean, median, std_err): ' + '{:04.2f},{:04.2f},{:04.2f}'.format(np.mean(zip(*CV_r_valid)[0]),np.median(zip(*CV_r_valid)[0]),stats.sem(zip(*CV_r_valid)[0]))\n",
    "            print 'CV R2 (mean, median, std_err): ' + '{:04.2f},{:04.2f}, {:04.2f}'.format(np.mean(CV_R2_valid),np.median(CV_R2_valid),stats.sem(CV_R2_valid))\n",
    "            print 'CV MSE (mean, median, std_err): ' + '{:04.2f},{:04.2f}, {:04.2f}'.format(np.mean(CV_MSE_valid),np.median(CV_MSE_valid),stats.sem(CV_MSE_valid))\n",
    "            print 'CV MAE (mean, median, std_err): ' + '{:04.2f},{:04.2f}, {:04.2f}'.format(np.mean(CV_MAE_valid),np.median(CV_MAE_valid),stats.sem(CV_MAE_valid))\n",
    "            print ''\n",
    "            \n",
    "        elif output_type == 'classify':\n",
    "            print 'most frequent hyper-params:' + str(hp_mode)\n",
    "            print 'CV Acc (mean, std_err): {:04.2f}, {:04.2f}'.format(np.mean(CV_Acc_valid),stats.sem(CV_Acc_valid))\n",
    "            print 'CV AUC (mean, std_err): {:04.2f}, {:04.2f}'.format(np.mean(CV_AUC_valid),stats.sem(CV_AUC_valid))\n",
    "            print 'CV Confusion Matrix (mean): {}'.format(np.mean(np.array(CV_CM_valid),axis=0))\n",
    "            print ''\n",
    "            plot_name = 'ROC'\n",
    "             \n",
    "#Save df style dictionaly for seaborn plots\n",
    "# df_perf_dict_path = baseline_dir + 'df_perf_dict_{}_{}.pkl'.format(exp_name, Clinical_Scale)                \n",
    "# pickleIt(df_perf_dict,df_perf_dict_path)\n",
    "# print 'saving results at: {}'.format(df_perf_dict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ROC curves\n",
    "\n",
    "#Load perf_data\n",
    "exp_perf_path = baseline_dir + 'df_perf_dict_{}_{}.pkl'.format(exp_name, Clinical_Scale)  \n",
    "exp_perf = pickle.load( open(exp_perf_path, \"rb\" ) )\n",
    "df_perf = pd.DataFrame.from_dict(exp_perf,orient='index')\n",
    "\n",
    "marker_list = ['o','d','s','<','^','>','D','*','H']\n",
    "plt.style.use('seaborn-white')\n",
    "plt.rcParams['figure.figsize'] = (50, 50)\n",
    "\n",
    "mk=0\n",
    "for modality in ['CS','HC_CT_CS']:\n",
    "    for model_choice in ['LR_L1','SVC','RFC']:\n",
    "        df = df_perf[(df_perf.model_choice==model_choice)&(df_perf.modality==modality)]\n",
    "        CV_fpr_tpr = []\n",
    "        CV_fpr_tpr_thrsh = []\n",
    "        for y_act, y_pred_prob in zip(df['act_scores'].values,df['pred_prob'].values):\n",
    "            fpr, tpr, thresholds = roc_curve(y_act, y_pred_prob[:,1]) \n",
    "            CV_fpr_tpr.append((fpr,tpr))        \n",
    "            CV_fpr_tpr_thrsh.append(thresholds)\n",
    "            \n",
    "        mean_tpr = 0.0\n",
    "        mean_fpr = np.linspace(0, 1, 100)\n",
    "        all_tpr = []\n",
    "\n",
    "        for i, (fpr, tpr) in enumerate(CV_fpr_tpr):\n",
    "            mean_tpr += interp(mean_fpr, fpr, tpr)\n",
    "            mean_tpr[0] = 0.0\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        mean_tpr /= len(CV_fpr_tpr)\n",
    "        mean_tpr[-1] = 1.0\n",
    "        mean_auc = auc(mean_fpr, mean_tpr)\n",
    "        \n",
    "        if modality == 'CS':\n",
    "            fig_modality = 'CL Var'\n",
    "        elif modality == 'HC_CT_CS':\n",
    "            fig_modality = 'CL + MR Var'\n",
    "            \n",
    "        with sns.axes_style(\"whitegrid\"):\n",
    "            label_str = '{}, {}, mean ROC (area = {:3.2f})'.format(fig_modality, model_choice, mean_auc)\n",
    "            plt.plot(mean_fpr, mean_tpr, label=label_str, lw=4, marker = marker_list[mk],markersize=20)                    \n",
    "            mk+=1\n",
    "\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate',fontsize = 50)\n",
    "plt.ylabel('True Positive Rate',fontsize = 50)\n",
    "plt.title('Receiver operating characteristic',fontsize = 50)\n",
    "plt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Luck', lw=4)\n",
    "plt.legend(loc=\"lower right\",fontsize = 50)\n",
    "plt.xticks(fontsize = 50)\n",
    "plt.yticks(fontsize = 50)\n",
    "\n",
    "save_figure = True\n",
    "fig_name = 'HBM2017_fig2.png'\n",
    "if save_figure:    \n",
    "    plt.savefig(baseline_dir + fig_name, dpi=1000) \n",
    "    print 'saving fig at: {}'.format(baseline_dir + fig_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/projects/nikhil/ADNI_prediction/input_datasets/longitudinal_trajectories/HBM2017_fig2.png'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_dir + fig_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PTID</th>\n",
       "      <th>ImageUID</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PTGENDER</th>\n",
       "      <th>APOE4</th>\n",
       "      <th>DX_bl</th>\n",
       "      <th>DX_cat_bl</th>\n",
       "      <th>ADAS13_bl</th>\n",
       "      <th>MMSE_bl</th>\n",
       "      <th>...</th>\n",
       "      <th>AAL_88_m06_diff</th>\n",
       "      <th>AAL_88_m12_diff</th>\n",
       "      <th>AAL_88_m24_diff</th>\n",
       "      <th>AAL_89_m06_diff</th>\n",
       "      <th>AAL_89_m12_diff</th>\n",
       "      <th>AAL_89_m24_diff</th>\n",
       "      <th>AAL_90_m06_diff</th>\n",
       "      <th>AAL_90_m12_diff</th>\n",
       "      <th>AAL_90_m24_diff</th>\n",
       "      <th>Traj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>002_S_4229</td>\n",
       "      <td>260229</td>\n",
       "      <td>66.4</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.088440</td>\n",
       "      <td>-0.123422</td>\n",
       "      <td>-0.006649</td>\n",
       "      <td>0.007642</td>\n",
       "      <td>-0.017480</td>\n",
       "      <td>-0.025395</td>\n",
       "      <td>-0.025068</td>\n",
       "      <td>-0.151539</td>\n",
       "      <td>0.104452</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>002_S_4447</td>\n",
       "      <td>280562</td>\n",
       "      <td>67.5</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.332538</td>\n",
       "      <td>-0.367894</td>\n",
       "      <td>0.820834</td>\n",
       "      <td>0.115986</td>\n",
       "      <td>-0.078142</td>\n",
       "      <td>0.169506</td>\n",
       "      <td>-0.261451</td>\n",
       "      <td>-0.222107</td>\n",
       "      <td>0.127221</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>003_S_4354</td>\n",
       "      <td>278119</td>\n",
       "      <td>75.7</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.667623</td>\n",
       "      <td>-0.045083</td>\n",
       "      <td>-0.567945</td>\n",
       "      <td>-0.338529</td>\n",
       "      <td>0.082627</td>\n",
       "      <td>-0.358237</td>\n",
       "      <td>-0.555292</td>\n",
       "      <td>0.027850</td>\n",
       "      <td>-0.677290</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>005_S_4168</td>\n",
       "      <td>254768</td>\n",
       "      <td>82.2</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113999</td>\n",
       "      <td>-0.211851</td>\n",
       "      <td>-0.131536</td>\n",
       "      <td>-0.080441</td>\n",
       "      <td>-0.058579</td>\n",
       "      <td>-0.042889</td>\n",
       "      <td>-0.160080</td>\n",
       "      <td>-0.163682</td>\n",
       "      <td>-0.204514</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>005_S_4185</td>\n",
       "      <td>258625</td>\n",
       "      <td>80.4</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.047390</td>\n",
       "      <td>0.129344</td>\n",
       "      <td>-0.692548</td>\n",
       "      <td>-0.038740</td>\n",
       "      <td>0.055245</td>\n",
       "      <td>-0.237143</td>\n",
       "      <td>0.013180</td>\n",
       "      <td>0.171727</td>\n",
       "      <td>-0.180387</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>006_S_4363</td>\n",
       "      <td>270050</td>\n",
       "      <td>73.5</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.148827</td>\n",
       "      <td>-0.057952</td>\n",
       "      <td>0.130562</td>\n",
       "      <td>-0.021139</td>\n",
       "      <td>-0.019037</td>\n",
       "      <td>-0.023215</td>\n",
       "      <td>-0.139353</td>\n",
       "      <td>-0.053405</td>\n",
       "      <td>0.182538</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>006_S_4679</td>\n",
       "      <td>312648</td>\n",
       "      <td>69.1</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.822328</td>\n",
       "      <td>-2.311256</td>\n",
       "      <td>-0.869241</td>\n",
       "      <td>-0.469665</td>\n",
       "      <td>-2.089346</td>\n",
       "      <td>-0.720852</td>\n",
       "      <td>-0.390735</td>\n",
       "      <td>-2.259789</td>\n",
       "      <td>-0.248947</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>006_S_4713</td>\n",
       "      <td>306760</td>\n",
       "      <td>70.5</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040295</td>\n",
       "      <td>-1.024037</td>\n",
       "      <td>0.075535</td>\n",
       "      <td>0.167552</td>\n",
       "      <td>-0.610306</td>\n",
       "      <td>-0.027262</td>\n",
       "      <td>0.026069</td>\n",
       "      <td>-0.571623</td>\n",
       "      <td>-0.002743</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>007_S_4467</td>\n",
       "      <td>281397</td>\n",
       "      <td>61.9</td>\n",
       "      <td>Female</td>\n",
       "      <td>2.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.168755</td>\n",
       "      <td>-0.070963</td>\n",
       "      <td>-0.215508</td>\n",
       "      <td>0.056800</td>\n",
       "      <td>-0.163394</td>\n",
       "      <td>0.059593</td>\n",
       "      <td>-0.007527</td>\n",
       "      <td>0.140176</td>\n",
       "      <td>-0.058728</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>007_S_4611</td>\n",
       "      <td>295877</td>\n",
       "      <td>66.9</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020921</td>\n",
       "      <td>-0.150246</td>\n",
       "      <td>-0.245842</td>\n",
       "      <td>-0.102141</td>\n",
       "      <td>0.055866</td>\n",
       "      <td>-0.122299</td>\n",
       "      <td>0.002422</td>\n",
       "      <td>-0.110934</td>\n",
       "      <td>-0.149667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>009_S_4324</td>\n",
       "      <td>272728</td>\n",
       "      <td>62.8</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.095876</td>\n",
       "      <td>-0.065199</td>\n",
       "      <td>-0.346321</td>\n",
       "      <td>-0.004772</td>\n",
       "      <td>-0.143616</td>\n",
       "      <td>-0.143637</td>\n",
       "      <td>-0.125594</td>\n",
       "      <td>-0.064253</td>\n",
       "      <td>-0.230851</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>009_S_4359</td>\n",
       "      <td>272772</td>\n",
       "      <td>76.7</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059268</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>-0.557211</td>\n",
       "      <td>-0.042204</td>\n",
       "      <td>0.269080</td>\n",
       "      <td>0.257968</td>\n",
       "      <td>-0.092138</td>\n",
       "      <td>-0.213310</td>\n",
       "      <td>-0.311654</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>009_S_4543</td>\n",
       "      <td>431819</td>\n",
       "      <td>70.1</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002588</td>\n",
       "      <td>-0.121516</td>\n",
       "      <td>-0.209142</td>\n",
       "      <td>-0.046750</td>\n",
       "      <td>0.077438</td>\n",
       "      <td>-0.131701</td>\n",
       "      <td>-0.018287</td>\n",
       "      <td>-0.023869</td>\n",
       "      <td>-0.208692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>009_S_4741</td>\n",
       "      <td>312755</td>\n",
       "      <td>61.6</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007738</td>\n",
       "      <td>-0.056308</td>\n",
       "      <td>-0.021943</td>\n",
       "      <td>0.076390</td>\n",
       "      <td>0.023029</td>\n",
       "      <td>-0.092524</td>\n",
       "      <td>-0.059936</td>\n",
       "      <td>0.090754</td>\n",
       "      <td>-0.002881</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>009_S_5000</td>\n",
       "      <td>349550</td>\n",
       "      <td>76.6</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.362296</td>\n",
       "      <td>0.024582</td>\n",
       "      <td>-0.126864</td>\n",
       "      <td>0.072694</td>\n",
       "      <td>0.042172</td>\n",
       "      <td>-0.216727</td>\n",
       "      <td>0.081060</td>\n",
       "      <td>-0.160347</td>\n",
       "      <td>-0.276185</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>011_S_4547</td>\n",
       "      <td>296413</td>\n",
       "      <td>77.3</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.155741</td>\n",
       "      <td>-0.391682</td>\n",
       "      <td>-0.101247</td>\n",
       "      <td>0.111127</td>\n",
       "      <td>-0.092331</td>\n",
       "      <td>-0.113526</td>\n",
       "      <td>0.018712</td>\n",
       "      <td>-0.278651</td>\n",
       "      <td>-0.146226</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>012_S_4094</td>\n",
       "      <td>296415</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096475</td>\n",
       "      <td>-0.304424</td>\n",
       "      <td>-0.276165</td>\n",
       "      <td>0.041630</td>\n",
       "      <td>-0.103035</td>\n",
       "      <td>-0.060931</td>\n",
       "      <td>-0.100700</td>\n",
       "      <td>-0.148392</td>\n",
       "      <td>-0.115230</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>012_S_4128</td>\n",
       "      <td>250623</td>\n",
       "      <td>72.8</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.273777</td>\n",
       "      <td>-0.005989</td>\n",
       "      <td>-0.011810</td>\n",
       "      <td>-1.260779</td>\n",
       "      <td>0.054190</td>\n",
       "      <td>0.007291</td>\n",
       "      <td>-0.818652</td>\n",
       "      <td>0.016969</td>\n",
       "      <td>0.087648</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>012_S_4188</td>\n",
       "      <td>258662</td>\n",
       "      <td>77.2</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.065395</td>\n",
       "      <td>-0.191733</td>\n",
       "      <td>-0.141505</td>\n",
       "      <td>-0.002458</td>\n",
       "      <td>-0.100809</td>\n",
       "      <td>-0.105816</td>\n",
       "      <td>-0.035000</td>\n",
       "      <td>-0.213100</td>\n",
       "      <td>-0.068933</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>013_S_4268</td>\n",
       "      <td>265254</td>\n",
       "      <td>63.5</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.264317</td>\n",
       "      <td>-0.069187</td>\n",
       "      <td>-0.123754</td>\n",
       "      <td>-0.079144</td>\n",
       "      <td>-0.159242</td>\n",
       "      <td>-0.094389</td>\n",
       "      <td>-0.208002</td>\n",
       "      <td>-0.191978</td>\n",
       "      <td>-0.067146</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>013_S_4395</td>\n",
       "      <td>280662</td>\n",
       "      <td>72.4</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.228732</td>\n",
       "      <td>0.067451</td>\n",
       "      <td>-0.180150</td>\n",
       "      <td>-0.069917</td>\n",
       "      <td>-0.021615</td>\n",
       "      <td>-0.068170</td>\n",
       "      <td>-0.055681</td>\n",
       "      <td>0.060809</td>\n",
       "      <td>-0.131787</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>013_S_4985</td>\n",
       "      <td>352005</td>\n",
       "      <td>78.7</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.273291</td>\n",
       "      <td>0.222906</td>\n",
       "      <td>-0.077640</td>\n",
       "      <td>0.097995</td>\n",
       "      <td>0.154618</td>\n",
       "      <td>-0.101477</td>\n",
       "      <td>0.147837</td>\n",
       "      <td>0.074907</td>\n",
       "      <td>-0.156124</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>014_S_4058</td>\n",
       "      <td>238666</td>\n",
       "      <td>84.6</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062481</td>\n",
       "      <td>-0.232906</td>\n",
       "      <td>-0.042348</td>\n",
       "      <td>0.205615</td>\n",
       "      <td>0.046805</td>\n",
       "      <td>-0.057644</td>\n",
       "      <td>0.059863</td>\n",
       "      <td>0.069584</td>\n",
       "      <td>-0.062864</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>014_S_4263</td>\n",
       "      <td>261065</td>\n",
       "      <td>74.3</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.127492</td>\n",
       "      <td>-0.317745</td>\n",
       "      <td>-0.533885</td>\n",
       "      <td>0.011693</td>\n",
       "      <td>-0.057715</td>\n",
       "      <td>-0.443315</td>\n",
       "      <td>-0.417280</td>\n",
       "      <td>-0.305707</td>\n",
       "      <td>-0.570628</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>016_S_4584</td>\n",
       "      <td>295865</td>\n",
       "      <td>78.3</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.598499</td>\n",
       "      <td>-0.200963</td>\n",
       "      <td>-0.208692</td>\n",
       "      <td>-0.529867</td>\n",
       "      <td>-0.245650</td>\n",
       "      <td>-0.289156</td>\n",
       "      <td>-0.346861</td>\n",
       "      <td>-0.153075</td>\n",
       "      <td>-0.064778</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>016_S_4646</td>\n",
       "      <td>305486</td>\n",
       "      <td>60.8</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075122</td>\n",
       "      <td>0.157059</td>\n",
       "      <td>0.036047</td>\n",
       "      <td>0.001661</td>\n",
       "      <td>0.060841</td>\n",
       "      <td>0.125954</td>\n",
       "      <td>0.032654</td>\n",
       "      <td>0.150475</td>\n",
       "      <td>0.106475</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>016_S_4902</td>\n",
       "      <td>326636</td>\n",
       "      <td>75.3</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023617</td>\n",
       "      <td>-0.031914</td>\n",
       "      <td>-0.207252</td>\n",
       "      <td>-0.185811</td>\n",
       "      <td>0.011978</td>\n",
       "      <td>-0.127018</td>\n",
       "      <td>0.060945</td>\n",
       "      <td>0.003454</td>\n",
       "      <td>-0.045066</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>016_S_5007</td>\n",
       "      <td>350342</td>\n",
       "      <td>71.5</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.210919</td>\n",
       "      <td>-0.082134</td>\n",
       "      <td>-0.064182</td>\n",
       "      <td>-0.333691</td>\n",
       "      <td>0.030019</td>\n",
       "      <td>0.077274</td>\n",
       "      <td>-0.238209</td>\n",
       "      <td>-0.085660</td>\n",
       "      <td>0.067241</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>018_S_4809</td>\n",
       "      <td>312863</td>\n",
       "      <td>78.3</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.198579</td>\n",
       "      <td>-0.174013</td>\n",
       "      <td>-0.035339</td>\n",
       "      <td>-0.068577</td>\n",
       "      <td>0.183634</td>\n",
       "      <td>0.099061</td>\n",
       "      <td>-0.020343</td>\n",
       "      <td>0.189894</td>\n",
       "      <td>0.165991</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>018_S_4868</td>\n",
       "      <td>321264</td>\n",
       "      <td>77.1</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.436386</td>\n",
       "      <td>0.287366</td>\n",
       "      <td>0.123181</td>\n",
       "      <td>0.221850</td>\n",
       "      <td>0.116586</td>\n",
       "      <td>0.060705</td>\n",
       "      <td>0.237169</td>\n",
       "      <td>0.214626</td>\n",
       "      <td>0.070392</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>131</td>\n",
       "      <td>130_S_4542</td>\n",
       "      <td>400998</td>\n",
       "      <td>79.3</td>\n",
       "      <td>Female</td>\n",
       "      <td>2.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.851058</td>\n",
       "      <td>-0.337092</td>\n",
       "      <td>-0.998663</td>\n",
       "      <td>-0.561740</td>\n",
       "      <td>-0.441594</td>\n",
       "      <td>-0.317563</td>\n",
       "      <td>-0.495948</td>\n",
       "      <td>-0.212032</td>\n",
       "      <td>-0.357822</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>132</td>\n",
       "      <td>130_S_4817</td>\n",
       "      <td>322951</td>\n",
       "      <td>60.7</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.155964</td>\n",
       "      <td>-0.142477</td>\n",
       "      <td>0.002974</td>\n",
       "      <td>-0.234865</td>\n",
       "      <td>-0.179121</td>\n",
       "      <td>-0.077412</td>\n",
       "      <td>0.019425</td>\n",
       "      <td>0.060697</td>\n",
       "      <td>0.071026</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>133</td>\n",
       "      <td>130_S_4883</td>\n",
       "      <td>326532</td>\n",
       "      <td>76.1</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096215</td>\n",
       "      <td>-0.136281</td>\n",
       "      <td>-0.047972</td>\n",
       "      <td>-0.033561</td>\n",
       "      <td>-0.060971</td>\n",
       "      <td>-0.159233</td>\n",
       "      <td>0.024273</td>\n",
       "      <td>-0.091906</td>\n",
       "      <td>-0.033803</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>134</td>\n",
       "      <td>130_S_4925</td>\n",
       "      <td>340500</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.277468</td>\n",
       "      <td>-0.153690</td>\n",
       "      <td>-0.386029</td>\n",
       "      <td>-0.065481</td>\n",
       "      <td>-0.249463</td>\n",
       "      <td>-0.237937</td>\n",
       "      <td>-0.057047</td>\n",
       "      <td>-0.104930</td>\n",
       "      <td>-0.160990</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>135</td>\n",
       "      <td>135_S_4281</td>\n",
       "      <td>263683</td>\n",
       "      <td>77.5</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155042</td>\n",
       "      <td>0.046515</td>\n",
       "      <td>0.049295</td>\n",
       "      <td>0.191167</td>\n",
       "      <td>0.209817</td>\n",
       "      <td>-0.131327</td>\n",
       "      <td>0.034009</td>\n",
       "      <td>0.004686</td>\n",
       "      <td>-0.008155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>136</td>\n",
       "      <td>135_S_4309</td>\n",
       "      <td>263754</td>\n",
       "      <td>68.2</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165322</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.370424</td>\n",
       "      <td>0.108338</td>\n",
       "      <td>0.156039</td>\n",
       "      <td>-0.075062</td>\n",
       "      <td>-0.160759</td>\n",
       "      <td>0.092144</td>\n",
       "      <td>-0.239637</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>137</td>\n",
       "      <td>135_S_4356</td>\n",
       "      <td>267753</td>\n",
       "      <td>68.1</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028114</td>\n",
       "      <td>-0.101985</td>\n",
       "      <td>-0.103607</td>\n",
       "      <td>-0.162015</td>\n",
       "      <td>-0.056095</td>\n",
       "      <td>-0.107245</td>\n",
       "      <td>0.072058</td>\n",
       "      <td>0.069375</td>\n",
       "      <td>-0.043130</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>138</td>\n",
       "      <td>135_S_4406</td>\n",
       "      <td>272692</td>\n",
       "      <td>78.9</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.123100</td>\n",
       "      <td>-0.238807</td>\n",
       "      <td>-0.296688</td>\n",
       "      <td>-0.003749</td>\n",
       "      <td>-0.227658</td>\n",
       "      <td>-0.202392</td>\n",
       "      <td>-0.158695</td>\n",
       "      <td>-0.325919</td>\n",
       "      <td>-0.467141</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>139</td>\n",
       "      <td>135_S_4489</td>\n",
       "      <td>283942</td>\n",
       "      <td>74.2</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032996</td>\n",
       "      <td>-0.121268</td>\n",
       "      <td>0.075766</td>\n",
       "      <td>0.007779</td>\n",
       "      <td>-0.026226</td>\n",
       "      <td>0.028081</td>\n",
       "      <td>-0.041579</td>\n",
       "      <td>-0.440406</td>\n",
       "      <td>-0.147373</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>140</td>\n",
       "      <td>135_S_4689</td>\n",
       "      <td>305422</td>\n",
       "      <td>69.6</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.343596</td>\n",
       "      <td>-0.201823</td>\n",
       "      <td>-0.639450</td>\n",
       "      <td>-0.156872</td>\n",
       "      <td>-0.203703</td>\n",
       "      <td>-0.513517</td>\n",
       "      <td>-0.023889</td>\n",
       "      <td>0.013692</td>\n",
       "      <td>-0.363371</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>141</td>\n",
       "      <td>135_S_4722</td>\n",
       "      <td>305615</td>\n",
       "      <td>68.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054366</td>\n",
       "      <td>0.160332</td>\n",
       "      <td>0.121767</td>\n",
       "      <td>-0.003423</td>\n",
       "      <td>-0.036489</td>\n",
       "      <td>0.054331</td>\n",
       "      <td>0.122061</td>\n",
       "      <td>0.266548</td>\n",
       "      <td>0.211287</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>142</td>\n",
       "      <td>135_S_4723</td>\n",
       "      <td>305621</td>\n",
       "      <td>69.4</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075173</td>\n",
       "      <td>0.024588</td>\n",
       "      <td>-0.124859</td>\n",
       "      <td>-0.080281</td>\n",
       "      <td>-0.071220</td>\n",
       "      <td>-0.069296</td>\n",
       "      <td>0.001925</td>\n",
       "      <td>-0.023373</td>\n",
       "      <td>0.042714</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>143</td>\n",
       "      <td>137_S_4299</td>\n",
       "      <td>265267</td>\n",
       "      <td>76.8</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084084</td>\n",
       "      <td>-0.095216</td>\n",
       "      <td>0.101723</td>\n",
       "      <td>-0.283337</td>\n",
       "      <td>-0.125020</td>\n",
       "      <td>-0.270917</td>\n",
       "      <td>-0.053693</td>\n",
       "      <td>-0.159868</td>\n",
       "      <td>-0.088614</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>144</td>\n",
       "      <td>137_S_4331</td>\n",
       "      <td>267777</td>\n",
       "      <td>75.3</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102064</td>\n",
       "      <td>-0.181461</td>\n",
       "      <td>0.072487</td>\n",
       "      <td>-0.154442</td>\n",
       "      <td>-0.077668</td>\n",
       "      <td>0.003890</td>\n",
       "      <td>-0.085646</td>\n",
       "      <td>-0.189873</td>\n",
       "      <td>0.060150</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>145</td>\n",
       "      <td>137_S_4351</td>\n",
       "      <td>270058</td>\n",
       "      <td>67.8</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.185196</td>\n",
       "      <td>-0.350955</td>\n",
       "      <td>-0.168437</td>\n",
       "      <td>-0.145486</td>\n",
       "      <td>-0.154266</td>\n",
       "      <td>-0.064218</td>\n",
       "      <td>-0.056616</td>\n",
       "      <td>-0.101178</td>\n",
       "      <td>-0.034875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>146</td>\n",
       "      <td>137_S_4536</td>\n",
       "      <td>288887</td>\n",
       "      <td>77.9</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.410848</td>\n",
       "      <td>-0.204302</td>\n",
       "      <td>-0.350608</td>\n",
       "      <td>-0.089817</td>\n",
       "      <td>-0.280873</td>\n",
       "      <td>-0.216273</td>\n",
       "      <td>-0.219125</td>\n",
       "      <td>-0.249525</td>\n",
       "      <td>-0.213409</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>147</td>\n",
       "      <td>137_S_4596</td>\n",
       "      <td>291882</td>\n",
       "      <td>65.7</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055335</td>\n",
       "      <td>-0.449083</td>\n",
       "      <td>-0.149954</td>\n",
       "      <td>-0.103981</td>\n",
       "      <td>-0.547430</td>\n",
       "      <td>-0.274024</td>\n",
       "      <td>-0.198452</td>\n",
       "      <td>-0.556379</td>\n",
       "      <td>-0.406804</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>148</td>\n",
       "      <td>137_S_4623</td>\n",
       "      <td>296410</td>\n",
       "      <td>61.1</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.200070</td>\n",
       "      <td>-0.017889</td>\n",
       "      <td>-0.161747</td>\n",
       "      <td>-0.067669</td>\n",
       "      <td>0.037956</td>\n",
       "      <td>-0.015358</td>\n",
       "      <td>-0.071168</td>\n",
       "      <td>0.128468</td>\n",
       "      <td>0.040604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>149</td>\n",
       "      <td>137_S_4631</td>\n",
       "      <td>305433</td>\n",
       "      <td>69.5</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116711</td>\n",
       "      <td>0.254803</td>\n",
       "      <td>0.286081</td>\n",
       "      <td>-0.113950</td>\n",
       "      <td>-0.201096</td>\n",
       "      <td>0.028892</td>\n",
       "      <td>0.079035</td>\n",
       "      <td>0.207688</td>\n",
       "      <td>0.124575</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>150</td>\n",
       "      <td>137_S_4815</td>\n",
       "      <td>326526</td>\n",
       "      <td>69.8</td>\n",
       "      <td>Female</td>\n",
       "      <td>2.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.349554</td>\n",
       "      <td>-0.758737</td>\n",
       "      <td>-0.315638</td>\n",
       "      <td>-0.238709</td>\n",
       "      <td>-0.609005</td>\n",
       "      <td>-0.347115</td>\n",
       "      <td>-0.325357</td>\n",
       "      <td>-0.584391</td>\n",
       "      <td>-0.340316</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>151</td>\n",
       "      <td>137_S_4816</td>\n",
       "      <td>326584</td>\n",
       "      <td>74.2</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010950</td>\n",
       "      <td>0.071001</td>\n",
       "      <td>-0.234227</td>\n",
       "      <td>-0.097949</td>\n",
       "      <td>-0.273179</td>\n",
       "      <td>-0.255460</td>\n",
       "      <td>-0.246968</td>\n",
       "      <td>-0.089621</td>\n",
       "      <td>-0.030220</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>152</td>\n",
       "      <td>141_S_4160</td>\n",
       "      <td>258664</td>\n",
       "      <td>74.1</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.348553</td>\n",
       "      <td>0.111403</td>\n",
       "      <td>0.214767</td>\n",
       "      <td>0.017621</td>\n",
       "      <td>0.039354</td>\n",
       "      <td>-0.047190</td>\n",
       "      <td>0.274631</td>\n",
       "      <td>0.162098</td>\n",
       "      <td>0.187007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>153</td>\n",
       "      <td>141_S_4232</td>\n",
       "      <td>260223</td>\n",
       "      <td>74.2</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.190656</td>\n",
       "      <td>-0.062595</td>\n",
       "      <td>0.082050</td>\n",
       "      <td>-0.082673</td>\n",
       "      <td>-0.104379</td>\n",
       "      <td>-0.001293</td>\n",
       "      <td>-0.058205</td>\n",
       "      <td>0.022429</td>\n",
       "      <td>0.094980</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>154</td>\n",
       "      <td>153_S_4077</td>\n",
       "      <td>296357</td>\n",
       "      <td>75.4</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.550301</td>\n",
       "      <td>0.400959</td>\n",
       "      <td>0.588368</td>\n",
       "      <td>0.017715</td>\n",
       "      <td>0.134144</td>\n",
       "      <td>0.153363</td>\n",
       "      <td>0.247897</td>\n",
       "      <td>0.108529</td>\n",
       "      <td>0.187109</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>155</td>\n",
       "      <td>153_S_4133</td>\n",
       "      <td>248654</td>\n",
       "      <td>79.7</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.260532</td>\n",
       "      <td>-0.157611</td>\n",
       "      <td>0.417727</td>\n",
       "      <td>0.078615</td>\n",
       "      <td>-0.077147</td>\n",
       "      <td>0.034312</td>\n",
       "      <td>0.213594</td>\n",
       "      <td>0.141920</td>\n",
       "      <td>0.227800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>156</td>\n",
       "      <td>153_S_4159</td>\n",
       "      <td>254764</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.183790</td>\n",
       "      <td>-0.347656</td>\n",
       "      <td>0.097138</td>\n",
       "      <td>-0.140070</td>\n",
       "      <td>-0.143446</td>\n",
       "      <td>0.190272</td>\n",
       "      <td>-0.022201</td>\n",
       "      <td>-0.112980</td>\n",
       "      <td>0.092261</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>157</td>\n",
       "      <td>153_S_4621</td>\n",
       "      <td>295881</td>\n",
       "      <td>69.9</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.127091</td>\n",
       "      <td>0.299433</td>\n",
       "      <td>-0.131411</td>\n",
       "      <td>-0.051024</td>\n",
       "      <td>0.163617</td>\n",
       "      <td>0.075067</td>\n",
       "      <td>-0.164590</td>\n",
       "      <td>-0.106263</td>\n",
       "      <td>-0.060367</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>158</td>\n",
       "      <td>153_S_4838</td>\n",
       "      <td>323002</td>\n",
       "      <td>75.6</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085445</td>\n",
       "      <td>-0.006690</td>\n",
       "      <td>0.150758</td>\n",
       "      <td>0.105369</td>\n",
       "      <td>-0.054925</td>\n",
       "      <td>-0.008777</td>\n",
       "      <td>-0.093904</td>\n",
       "      <td>-0.053935</td>\n",
       "      <td>0.006951</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>159</td>\n",
       "      <td>941_S_4036</td>\n",
       "      <td>236982</td>\n",
       "      <td>74.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.104093</td>\n",
       "      <td>-0.762600</td>\n",
       "      <td>-0.648112</td>\n",
       "      <td>-0.039606</td>\n",
       "      <td>-0.176907</td>\n",
       "      <td>-0.118139</td>\n",
       "      <td>-0.005009</td>\n",
       "      <td>-0.339412</td>\n",
       "      <td>-0.107979</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>160</td>\n",
       "      <td>941_S_4187</td>\n",
       "      <td>258653</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.141179</td>\n",
       "      <td>0.024379</td>\n",
       "      <td>0.005326</td>\n",
       "      <td>-0.120888</td>\n",
       "      <td>-0.025751</td>\n",
       "      <td>0.039749</td>\n",
       "      <td>-0.155020</td>\n",
       "      <td>-0.019589</td>\n",
       "      <td>-0.055933</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows  728 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0        PTID  ImageUID   AGE PTGENDER  APOE4 DX_bl  DX_cat_bl  \\\n",
       "0             0  002_S_4229    260229  66.4     Male    0.0   MCI        1.0   \n",
       "1             1  002_S_4447    280562  67.5   Female    1.0   MCI        1.0   \n",
       "2             2  003_S_4354    278119  75.7     Male    0.0   MCI        1.0   \n",
       "3             3  005_S_4168    254768  82.2     Male    1.0   MCI        1.0   \n",
       "4             4  005_S_4185    258625  80.4     Male    0.0   MCI        1.0   \n",
       "5             5  006_S_4363    270050  73.5   Female    0.0   MCI        1.0   \n",
       "6             6  006_S_4679    312648  69.1     Male    1.0   MCI        1.0   \n",
       "7             7  006_S_4713    306760  70.5     Male    1.0   MCI        1.0   \n",
       "8             8  007_S_4467    281397  61.9   Female    2.0   MCI        1.0   \n",
       "9             9  007_S_4611    295877  66.9     Male    1.0   MCI        1.0   \n",
       "10           10  009_S_4324    272728  62.8   Female    1.0   MCI        1.0   \n",
       "11           11  009_S_4359    272772  76.7     Male    1.0   MCI        1.0   \n",
       "12           12  009_S_4543    431819  70.1   Female    0.0   MCI        1.0   \n",
       "13           13  009_S_4741    312755  61.6     Male    0.0   MCI        1.0   \n",
       "14           14  009_S_5000    349550  76.6     Male    1.0   MCI        1.0   \n",
       "15           15  011_S_4547    296413  77.3     Male    0.0   MCI        1.0   \n",
       "16           16  012_S_4094    296415  60.0   Female    0.0   MCI        1.0   \n",
       "17           17  012_S_4128    250623  72.8   Female    1.0   MCI        1.0   \n",
       "18           18  012_S_4188    258662  77.2     Male    1.0   MCI        1.0   \n",
       "19           19  013_S_4268    265254  63.5   Female    0.0   MCI        1.0   \n",
       "20           20  013_S_4395    280662  72.4   Female    0.0   MCI        1.0   \n",
       "21           21  013_S_4985    352005  78.7   Female    1.0   MCI        1.0   \n",
       "22           22  014_S_4058    238666  84.6   Female    1.0   MCI        1.0   \n",
       "23           23  014_S_4263    261065  74.3     Male    1.0   MCI        1.0   \n",
       "24           24  016_S_4584    295865  78.3   Female    1.0   MCI        1.0   \n",
       "25           25  016_S_4646    305486  60.8   Female    1.0   MCI        1.0   \n",
       "26           26  016_S_4902    326636  75.3   Female    1.0   MCI        1.0   \n",
       "27           27  016_S_5007    350342  71.5     Male    0.0   MCI        1.0   \n",
       "28           28  018_S_4809    312863  78.3     Male    1.0   MCI        1.0   \n",
       "29           29  018_S_4868    321264  77.1     Male    2.0   MCI        1.0   \n",
       "..          ...         ...       ...   ...      ...    ...   ...        ...   \n",
       "126         131  130_S_4542    400998  79.3   Female    2.0   MCI        1.0   \n",
       "127         132  130_S_4817    322951  60.7     Male    2.0   MCI        1.0   \n",
       "128         133  130_S_4883    326532  76.1   Female    0.0   MCI        1.0   \n",
       "129         134  130_S_4925    340500  75.0     Male    0.0   MCI        1.0   \n",
       "130         135  135_S_4281    263683  77.5   Female    0.0   MCI        1.0   \n",
       "131         136  135_S_4309    263754  68.2     Male    1.0   MCI        1.0   \n",
       "132         137  135_S_4356    267753  68.1     Male    0.0   MCI        1.0   \n",
       "133         138  135_S_4406    272692  78.9     Male    0.0   MCI        1.0   \n",
       "134         139  135_S_4489    283942  74.2     Male    0.0   MCI        1.0   \n",
       "135         140  135_S_4689    305422  69.6     Male    2.0   MCI        1.0   \n",
       "136         141  135_S_4722    305615  68.0   Female    0.0   MCI        1.0   \n",
       "137         142  135_S_4723    305621  69.4   Female    0.0   MCI        1.0   \n",
       "138         143  137_S_4299    265267  76.8   Female    0.0   MCI        1.0   \n",
       "139         144  137_S_4331    267777  75.3   Female    1.0   MCI        1.0   \n",
       "140         145  137_S_4351    270058  67.8   Female    1.0   MCI        1.0   \n",
       "141         146  137_S_4536    288887  77.9   Female    0.0   MCI        1.0   \n",
       "142         147  137_S_4596    291882  65.7     Male    0.0   MCI        1.0   \n",
       "143         148  137_S_4623    296410  61.1   Female    1.0   MCI        1.0   \n",
       "144         149  137_S_4631    305433  69.5     Male    0.0   MCI        1.0   \n",
       "145         150  137_S_4815    326526  69.8   Female    2.0   MCI        1.0   \n",
       "146         151  137_S_4816    326584  74.2     Male    2.0   MCI        1.0   \n",
       "147         152  141_S_4160    258664  74.1     Male    0.0   MCI        1.0   \n",
       "148         153  141_S_4232    260223  74.2     Male    0.0   MCI        1.0   \n",
       "149         154  153_S_4077    296357  75.4     Male    0.0   MCI        1.0   \n",
       "150         155  153_S_4133    248654  79.7     Male    1.0   MCI        1.0   \n",
       "151         156  153_S_4159    254764  71.0   Female    0.0   MCI        1.0   \n",
       "152         157  153_S_4621    295881  69.9     Male    0.0   MCI        1.0   \n",
       "153         158  153_S_4838    323002  75.6     Male    0.0   MCI        1.0   \n",
       "154         159  941_S_4036    236982  74.0     Male    0.0   MCI        1.0   \n",
       "155         160  941_S_4187    258653  62.0     Male    0.0   MCI        1.0   \n",
       "\n",
       "     ADAS13_bl  MMSE_bl  ...   AAL_88_m06_diff  AAL_88_m12_diff  \\\n",
       "0         11.0     29.0  ...         -0.088440        -0.123422   \n",
       "1          7.0     27.0  ...         -0.332538        -0.367894   \n",
       "2         20.0     29.0  ...         -0.667623        -0.045083   \n",
       "3         11.0     29.0  ...         -0.113999        -0.211851   \n",
       "4         12.0     28.0  ...         -0.047390         0.129344   \n",
       "5         21.0     26.0  ...         -0.148827        -0.057952   \n",
       "6         19.0     28.0  ...         -0.822328        -2.311256   \n",
       "7         14.0     30.0  ...         -0.040295        -1.024037   \n",
       "8         18.0     27.0  ...         -0.168755        -0.070963   \n",
       "9         11.0     25.0  ...          0.020921        -0.150246   \n",
       "10        20.0     27.0  ...         -0.095876        -0.065199   \n",
       "11        14.0     30.0  ...          0.059268         0.032609   \n",
       "12        17.0     29.0  ...         -0.002588        -0.121516   \n",
       "13        18.0     29.0  ...         -0.007738        -0.056308   \n",
       "14        21.0     26.0  ...          0.362296         0.024582   \n",
       "15        13.0     30.0  ...         -0.155741        -0.391682   \n",
       "16        22.0     26.0  ...         -0.096475        -0.304424   \n",
       "17        12.0     24.0  ...         -1.273777        -0.005989   \n",
       "18        27.0     28.0  ...         -0.065395        -0.191733   \n",
       "19        12.0     29.0  ...         -0.264317        -0.069187   \n",
       "20        12.0     26.0  ...         -0.228732         0.067451   \n",
       "21        19.0     26.0  ...          0.273291         0.222906   \n",
       "22        27.0     29.0  ...          0.062481        -0.232906   \n",
       "23        20.0     27.0  ...         -0.127492        -0.317745   \n",
       "24        13.0     27.0  ...         -0.598499        -0.200963   \n",
       "25        24.0     30.0  ...          0.075122         0.157059   \n",
       "26        30.0     25.0  ...          0.023617        -0.031914   \n",
       "27        16.0     27.0  ...         -0.210919        -0.082134   \n",
       "28        22.0     24.0  ...         -0.198579        -0.174013   \n",
       "29        18.0     27.0  ...          0.436386         0.287366   \n",
       "..         ...      ...  ...               ...              ...   \n",
       "126       34.0     25.0  ...         -0.851058        -0.337092   \n",
       "127       13.0     30.0  ...         -0.155964        -0.142477   \n",
       "128        7.0     29.0  ...         -0.096215        -0.136281   \n",
       "129       26.0     27.0  ...         -0.277468        -0.153690   \n",
       "130       12.0     27.0  ...          0.155042         0.046515   \n",
       "131       12.0     27.0  ...          0.165322         0.004455   \n",
       "132        7.0     28.0  ...         -0.028114        -0.101985   \n",
       "133       16.0     29.0  ...         -0.123100        -0.238807   \n",
       "134       15.0     30.0  ...         -0.032996        -0.121268   \n",
       "135       24.0     29.0  ...         -0.343596        -0.201823   \n",
       "136        8.0     28.0  ...          0.054366         0.160332   \n",
       "137        9.0     30.0  ...         -0.075173         0.024588   \n",
       "138        8.0     25.0  ...          0.084084        -0.095216   \n",
       "139        8.0     29.0  ...          0.102064        -0.181461   \n",
       "140       17.0     29.0  ...         -0.185196        -0.350955   \n",
       "141       16.0     28.0  ...         -0.410848        -0.204302   \n",
       "142       19.0     29.0  ...         -0.055335        -0.449083   \n",
       "143       16.0     30.0  ...         -0.200070        -0.017889   \n",
       "144       12.0     28.0  ...          0.116711         0.254803   \n",
       "145       26.0     24.0  ...         -0.349554        -0.758737   \n",
       "146       16.0     29.0  ...          0.010950         0.071001   \n",
       "147       14.0     25.0  ...          0.348553         0.111403   \n",
       "148        9.0     29.0  ...         -0.190656        -0.062595   \n",
       "149       23.0     28.0  ...          0.550301         0.400959   \n",
       "150       10.0     27.0  ...          0.260532        -0.157611   \n",
       "151       16.0     30.0  ...         -0.183790        -0.347656   \n",
       "152       14.0     28.0  ...         -0.127091         0.299433   \n",
       "153       25.0     26.0  ...         -0.085445        -0.006690   \n",
       "154        9.0     29.0  ...         -0.104093        -0.762600   \n",
       "155       17.0     29.0  ...         -0.141179         0.024379   \n",
       "\n",
       "     AAL_88_m24_diff  AAL_89_m06_diff  AAL_89_m12_diff  AAL_89_m24_diff  \\\n",
       "0          -0.006649         0.007642        -0.017480        -0.025395   \n",
       "1           0.820834         0.115986        -0.078142         0.169506   \n",
       "2          -0.567945        -0.338529         0.082627        -0.358237   \n",
       "3          -0.131536        -0.080441        -0.058579        -0.042889   \n",
       "4          -0.692548        -0.038740         0.055245        -0.237143   \n",
       "5           0.130562        -0.021139        -0.019037        -0.023215   \n",
       "6          -0.869241        -0.469665        -2.089346        -0.720852   \n",
       "7           0.075535         0.167552        -0.610306        -0.027262   \n",
       "8          -0.215508         0.056800        -0.163394         0.059593   \n",
       "9          -0.245842        -0.102141         0.055866        -0.122299   \n",
       "10         -0.346321        -0.004772        -0.143616        -0.143637   \n",
       "11         -0.557211        -0.042204         0.269080         0.257968   \n",
       "12         -0.209142        -0.046750         0.077438        -0.131701   \n",
       "13         -0.021943         0.076390         0.023029        -0.092524   \n",
       "14         -0.126864         0.072694         0.042172        -0.216727   \n",
       "15         -0.101247         0.111127        -0.092331        -0.113526   \n",
       "16         -0.276165         0.041630        -0.103035        -0.060931   \n",
       "17         -0.011810        -1.260779         0.054190         0.007291   \n",
       "18         -0.141505        -0.002458        -0.100809        -0.105816   \n",
       "19         -0.123754        -0.079144        -0.159242        -0.094389   \n",
       "20         -0.180150        -0.069917        -0.021615        -0.068170   \n",
       "21         -0.077640         0.097995         0.154618        -0.101477   \n",
       "22         -0.042348         0.205615         0.046805        -0.057644   \n",
       "23         -0.533885         0.011693        -0.057715        -0.443315   \n",
       "24         -0.208692        -0.529867        -0.245650        -0.289156   \n",
       "25          0.036047         0.001661         0.060841         0.125954   \n",
       "26         -0.207252        -0.185811         0.011978        -0.127018   \n",
       "27         -0.064182        -0.333691         0.030019         0.077274   \n",
       "28         -0.035339        -0.068577         0.183634         0.099061   \n",
       "29          0.123181         0.221850         0.116586         0.060705   \n",
       "..               ...              ...              ...              ...   \n",
       "126        -0.998663        -0.561740        -0.441594        -0.317563   \n",
       "127         0.002974        -0.234865        -0.179121        -0.077412   \n",
       "128        -0.047972        -0.033561        -0.060971        -0.159233   \n",
       "129        -0.386029        -0.065481        -0.249463        -0.237937   \n",
       "130         0.049295         0.191167         0.209817        -0.131327   \n",
       "131        -0.370424         0.108338         0.156039        -0.075062   \n",
       "132        -0.103607        -0.162015        -0.056095        -0.107245   \n",
       "133        -0.296688        -0.003749        -0.227658        -0.202392   \n",
       "134         0.075766         0.007779        -0.026226         0.028081   \n",
       "135        -0.639450        -0.156872        -0.203703        -0.513517   \n",
       "136         0.121767        -0.003423        -0.036489         0.054331   \n",
       "137        -0.124859        -0.080281        -0.071220        -0.069296   \n",
       "138         0.101723        -0.283337        -0.125020        -0.270917   \n",
       "139         0.072487        -0.154442        -0.077668         0.003890   \n",
       "140        -0.168437        -0.145486        -0.154266        -0.064218   \n",
       "141        -0.350608        -0.089817        -0.280873        -0.216273   \n",
       "142        -0.149954        -0.103981        -0.547430        -0.274024   \n",
       "143        -0.161747        -0.067669         0.037956        -0.015358   \n",
       "144         0.286081        -0.113950        -0.201096         0.028892   \n",
       "145        -0.315638        -0.238709        -0.609005        -0.347115   \n",
       "146        -0.234227        -0.097949        -0.273179        -0.255460   \n",
       "147         0.214767         0.017621         0.039354        -0.047190   \n",
       "148         0.082050        -0.082673        -0.104379        -0.001293   \n",
       "149         0.588368         0.017715         0.134144         0.153363   \n",
       "150         0.417727         0.078615        -0.077147         0.034312   \n",
       "151         0.097138        -0.140070        -0.143446         0.190272   \n",
       "152        -0.131411        -0.051024         0.163617         0.075067   \n",
       "153         0.150758         0.105369        -0.054925        -0.008777   \n",
       "154        -0.648112        -0.039606        -0.176907        -0.118139   \n",
       "155         0.005326        -0.120888        -0.025751         0.039749   \n",
       "\n",
       "     AAL_90_m06_diff  AAL_90_m12_diff  AAL_90_m24_diff  Traj  \n",
       "0          -0.025068        -0.151539         0.104452     0  \n",
       "1          -0.261451        -0.222107         0.127221     1  \n",
       "2          -0.555292         0.027850        -0.677290     1  \n",
       "3          -0.160080        -0.163682        -0.204514     1  \n",
       "4           0.013180         0.171727        -0.180387     1  \n",
       "5          -0.139353        -0.053405         0.182538     0  \n",
       "6          -0.390735        -2.259789        -0.248947     0  \n",
       "7           0.026069        -0.571623        -0.002743     1  \n",
       "8          -0.007527         0.140176        -0.058728     1  \n",
       "9           0.002422        -0.110934        -0.149667     1  \n",
       "10         -0.125594        -0.064253        -0.230851     0  \n",
       "11         -0.092138        -0.213310        -0.311654     0  \n",
       "12         -0.018287        -0.023869        -0.208692     1  \n",
       "13         -0.059936         0.090754        -0.002881     0  \n",
       "14          0.081060        -0.160347        -0.276185     1  \n",
       "15          0.018712        -0.278651        -0.146226     0  \n",
       "16         -0.100700        -0.148392        -0.115230     1  \n",
       "17         -0.818652         0.016969         0.087648     1  \n",
       "18         -0.035000        -0.213100        -0.068933     1  \n",
       "19         -0.208002        -0.191978        -0.067146     1  \n",
       "20         -0.055681         0.060809        -0.131787     1  \n",
       "21          0.147837         0.074907        -0.156124     0  \n",
       "22          0.059863         0.069584        -0.062864     0  \n",
       "23         -0.417280        -0.305707        -0.570628     0  \n",
       "24         -0.346861        -0.153075        -0.064778     0  \n",
       "25          0.032654         0.150475         0.106475     1  \n",
       "26          0.060945         0.003454        -0.045066     0  \n",
       "27         -0.238209        -0.085660         0.067241     0  \n",
       "28         -0.020343         0.189894         0.165991     0  \n",
       "29          0.237169         0.214626         0.070392     0  \n",
       "..               ...              ...              ...   ...  \n",
       "126        -0.495948        -0.212032        -0.357822     0  \n",
       "127         0.019425         0.060697         0.071026     0  \n",
       "128         0.024273        -0.091906        -0.033803     0  \n",
       "129        -0.057047        -0.104930        -0.160990     0  \n",
       "130         0.034009         0.004686        -0.008155     0  \n",
       "131        -0.160759         0.092144        -0.239637     1  \n",
       "132         0.072058         0.069375        -0.043130     1  \n",
       "133        -0.158695        -0.325919        -0.467141     0  \n",
       "134        -0.041579        -0.440406        -0.147373     1  \n",
       "135        -0.023889         0.013692        -0.363371     0  \n",
       "136         0.122061         0.266548         0.211287     1  \n",
       "137         0.001925        -0.023373         0.042714     1  \n",
       "138        -0.053693        -0.159868        -0.088614     0  \n",
       "139        -0.085646        -0.189873         0.060150     0  \n",
       "140        -0.056616        -0.101178        -0.034875     1  \n",
       "141        -0.219125        -0.249525        -0.213409     1  \n",
       "142        -0.198452        -0.556379        -0.406804     0  \n",
       "143        -0.071168         0.128468         0.040604     1  \n",
       "144         0.079035         0.207688         0.124575     1  \n",
       "145        -0.325357        -0.584391        -0.340316     0  \n",
       "146        -0.246968        -0.089621        -0.030220     0  \n",
       "147         0.274631         0.162098         0.187007     1  \n",
       "148        -0.058205         0.022429         0.094980     0  \n",
       "149         0.247897         0.108529         0.187109     1  \n",
       "150         0.213594         0.141920         0.227800     0  \n",
       "151        -0.022201        -0.112980         0.092261     1  \n",
       "152        -0.164590        -0.106263        -0.060367     1  \n",
       "153        -0.093904        -0.053935         0.006951     1  \n",
       "154        -0.005009        -0.339412        -0.107979     0  \n",
       "155        -0.155020        -0.019589        -0.055933     1  \n",
       "\n",
       "[156 rows x 728 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
