{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Basic Imports\n",
    "import numpy as np\n",
    "import h5py as h5\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import pickle\n",
    "import re\n",
    "import collections\n",
    "import tables as tb\n",
    "from math import isnan\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data imports\n",
    "my_name = 'Exp5'\n",
    "cohort = 'ADNI2'\n",
    "clinical_scale = 'ADAS13'\n",
    "exp_name = '{}_{}_{}'.format(my_name,cohort,clinical_scale)\n",
    "atlas = 'AAL'\n",
    "\n",
    "baseline_dir = '/projects/nikhil/ADNI_prediction/input_datasets/'\n",
    "HC_L_data_path = baseline_dir + 'HC/subject_HC_vol_dictionary_{}_left_{}.pkl'.format(cohort,my_name)\n",
    "HC_R_data_path = baseline_dir + 'HC/subject_HC_vol_dictionary_{}_right_{}.pkl'.format(cohort,my_name)\n",
    "CT_data_path = baseline_dir + 'CT/civet_out/{}_subject_ROI_CT_dict_{}.pkl'.format(cohort,atlas)\n",
    "CT_unique_ROIs_path = baseline_dir + 'CT/civet_out/ADNI_unique_ROIs_{}.pkl'.format(atlas)\n",
    "sub_CS_data_path = baseline_dir + 'CS/{}_BL_PTID_ADAS13_dict.pkl'.format(cohort)\n",
    "sub_DX_data_path = baseline_dir + 'CS/{}_BL_PTID_DX_bl_dict.pkl'.format(cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common HC keys: 635\n",
      "HC_L_keys: 635, HC_R_keys: 635, CT_keys: 763\n"
     ]
    }
   ],
   "source": [
    "#Fused labels and volumes\n",
    "sub_HC_L_dict = pickle.load( open(HC_L_data_path, \"rb\" ) )\n",
    "sub_HC_R_dict = pickle.load( open(HC_R_data_path, \"rb\" ) )\n",
    "\n",
    "HC_L_total_vol_dict = {}\n",
    "HC_R_total_vol_dict = {}\n",
    "\n",
    "HC_common_keys = set(sub_HC_L_dict.keys()) & set(sub_HC_R_dict.keys())\n",
    "print 'Common HC keys: {}'.format(len(HC_common_keys))\n",
    "for key in HC_common_keys:\n",
    "    fused_vol = stats.mode(sub_HC_L_dict[key],axis=0)[0] #Left HC\n",
    "    HC_L_total_vol_dict[key] = np.sum(fused_vol)\n",
    "    fused_vol = stats.mode(sub_HC_R_dict[key],axis=0)[0] #Right HC\n",
    "    HC_R_total_vol_dict[key] = np.sum(fused_vol)\n",
    "    \n",
    "#Mean CT values for AAL\n",
    "sub_CT_dict = pickle.load( open(CT_data_path, \"rb\" ) )\n",
    "unique_ROIs = pickle.load( open(CT_unique_ROIs_path, \"rb\" ) )\n",
    "#unique_ROIs = sub_CT_dict['137_S_0459'][0].keys()\n",
    "CT_mean_dict = {}\n",
    "for key in sub_CT_dict.keys():\n",
    "    CT_roi_dict = sub_CT_dict[key][0]\n",
    "    mean_CT_list = []\n",
    "    for roi in unique_ROIs:\n",
    "        #ignore roi list (mainly the background ones...)\n",
    "        if not roi in [0]:\n",
    "            mean_CT_list.append(np.mean(CT_roi_dict[roi]))\n",
    "                \n",
    "    CT_mean_dict[key] = mean_CT_list\n",
    "    \n",
    "print 'HC_L_keys: {}, HC_R_keys: {}, CT_keys: {}'.format(len(HC_L_total_vol_dict), len(HC_R_total_vol_dict), len(CT_mean_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "688\n"
     ]
    }
   ],
   "source": [
    "#Dump the unique ordered list of CT ROIs that is consistent across ADNI1 and 2. \n",
    "sub_CT_dict = pickle.load( open(CT_data_path, \"rb\" ) )\n",
    "unique_ROIs = sub_CT_dict['137_S_0459'][0].keys()\n",
    "print len(unique_ROIs)\n",
    "pickleIt(unique_ROIs,baseline_dir + 'CT/civet_out/ADNI_unique_ROIs_{}.pkl'.format(atlas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of common keys across modalities: 587\n",
      "No Dx found for 036_S_4740\n",
      "X shape: (587, 80), y shape: (587,)\n"
     ]
    }
   ],
   "source": [
    "# ADAS score dict\n",
    "sub_CS_dict = pickle.load( open(sub_CS_data_path, \"rb\" ) )\n",
    "sub_CS_dict_clean = filter(lambda k: not isnan(sub_CS_dict[k]), sub_CS_dict) #remove NaNs\n",
    "sub_CS_dict_clean = {k: sub_CS_dict[k] for k in sub_CS_dict if not isnan(sub_CS_dict[k])}\n",
    "\n",
    "#Dx score dict (for stratified k-fold)\n",
    "sub_DX_dict = pickle.load( open(sub_DX_data_path, \"rb\" ) )\n",
    "#sub_DX_dict_clean = filter(lambda k: not isnan(sub_DX_dict[k]), sub_DX_dict) #remove NaNs\n",
    "#sub_DX_dict_clean = {k: sub_DX_dict[k] for k in sub_DX_dict if not isnan(sub_DX_dict[k])}\n",
    "\n",
    "common_keys = list(set(HC_L_total_vol_dict.keys()) & set(CT_mean_dict.keys()) & set(sub_CS_dict_clean.keys()))\n",
    "print '# of common keys across modalities: {}'.format(len(common_keys))\n",
    "X = []\n",
    "y = []\n",
    "y_dx = [] #Used for creating balanced k-folds\n",
    "for key in common_keys:\n",
    "    X.append(np.array([HC_L_total_vol_dict[key]] + [HC_R_total_vol_dict[key]] + CT_mean_dict[key]))\n",
    "    y.append(sub_CS_dict_clean[key])\n",
    "    if key in sub_DX_dict:\n",
    "        if sub_DX_dict[key] in ['EMCI','LMCI']:\n",
    "            y_dx.append('MCI')\n",
    "        elif sub_DX_dict[key] in ['CN','SMC']:   \n",
    "            y_dx.append('CN')\n",
    "        elif sub_DX_dict[key] in ['AD']:  \n",
    "            y_dx.append('AD')\n",
    "        else:\n",
    "            print \"Unknown Dx\"\n",
    "    else:\n",
    "        print \"No Dx found for {}\".format(key)\n",
    "        y_dx.append('CN') #Two subjects without Dx \n",
    "    \n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print 'X shape: {}, y shape: {}'.format(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADNI2\n"
     ]
    }
   ],
   "source": [
    "#X_adni1 = X\n",
    "#y_adni1 = y\n",
    "#X_comb = np.vstack((X_adni1,X))\n",
    "#y_comb = np.concatenate((y_adni1,y))\n",
    "print cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = X_comb\n",
    "y = y_comb\n",
    "cohort = 'ADNI1and2'\n",
    "exp_name = '{}_{}_{}'.format(my_name,cohort,clinical_scale)\n",
    "print X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified KFold\n",
      "DX distribution (AD,CN,LMCI): (11, 22, 27)\n",
      "y_train_mean: 15.6015180266, y_test_mean: 16.15\n",
      "DX distribution (AD,CN,LMCI): (11, 22, 27)\n",
      "y_train_mean: 15.6622390892, y_test_mean: 15.6166666667\n",
      "DX distribution (AD,CN,LMCI): (11, 22, 27)\n",
      "y_train_mean: 15.7855787476, y_test_mean: 14.5333333333\n",
      "DX distribution (AD,CN,LMCI): (10, 22, 27)\n",
      "y_train_mean: 15.6742424242, y_test_mean: 15.5084745763\n",
      "DX distribution (AD,CN,LMCI): (10, 22, 27)\n",
      "y_train_mean: 15.553030303, y_test_mean: 16.593220339\n",
      "DX distribution (AD,CN,LMCI): (10, 22, 26)\n",
      "y_train_mean: 15.7372400756, y_test_mean: 14.9310344828\n",
      "DX distribution (AD,CN,LMCI): (10, 22, 26)\n",
      "y_train_mean: 15.5387523629, y_test_mean: 16.7413793103\n",
      "DX distribution (AD,CN,LMCI): (10, 22, 26)\n",
      "y_train_mean: 15.763705104, y_test_mean: 14.6896551724\n",
      "DX distribution (AD,CN,LMCI): (10, 22, 26)\n",
      "y_train_mean: 15.584120983, y_test_mean: 16.3275862069\n",
      "DX distribution (AD,CN,LMCI): (10, 21, 26)\n",
      "y_train_mean: 15.6754716981, y_test_mean: 15.4912280702\n"
     ]
    }
   ],
   "source": [
    "# Create folds for CV (default Stratified based on DX)\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "#Encode Dx labels to integers map: {AD:0,CN:1,LMCI:2}\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_dx)\n",
    "y_dx_int = le.transform(y_dx) \n",
    "\n",
    "stratified_KF = True #Something is wrong with ADNI2 dx data... \n",
    "if not stratified_KF:\n",
    "    print 'KFold'\n",
    "    kf = KFold(len(y), n_folds=10)\n",
    "else: \n",
    "    print 'Stratified KFold'\n",
    "    kf = StratifiedKFold(y_dx_int, n_folds=10)\n",
    "    \n",
    "for train_index, test_index in kf:    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    print 'DX distribution (AD,CN,LMCI): {}'.format((np.sum(y_dx_int[test_index]==0),np.sum(y_dx_int[test_index]==1),\n",
    "                                              np.sum(y_dx_int[test_index]==2)))\n",
    "    print 'y_train_mean: {}, y_test_mean: {}'.format(np.mean(y_train),np.mean(y_test))\n",
    "    \n",
    "save_experimental_setup = True  #Saves X, y, and KF\n",
    "if save_experimental_setup:\n",
    "    save_path = '/projects/nikhil/ADNI_prediction/input_datasets/exp_data/CV_{}.pkl'.format(exp_name)\n",
    "    exp_setup = {'X': X, 'y': y, 'kf':kf,'common_subs':common_keys,'exp_name':exp_name}\n",
    "    pickleIt(exp_setup, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(587, 80)\n",
      "L_HC corr: -0.176136615797, R_HC_corr: -0.185519104097\n",
      "HC Correlation in each fold\n",
      "1\n",
      "test L_HC vol, std, corr: 3179.48333333, 429.520992567, -0.18862891692\n",
      "test R_HC vol, std, corr: 3162.91666667, 563.610955999, -0.148095470363\n",
      "train L_HC vol, std, corr: 3250.24667932, 392.024691192, -0.174318685642\n",
      "train R_HC vol, std, corr: 3287.92979127, 404.158709696, -0.192219753441\n",
      "2\n",
      "test L_HC vol, std, corr: 3256.41666667, 380.239411059, -0.383067139628\n",
      "test R_HC vol, std, corr: 3307.51666667, 379.886934568, -0.479399607488\n",
      "train L_HC vol, std, corr: 3241.48766603, 398.391542337, -0.153158123008\n",
      "train R_HC vol, std, corr: 3271.46679317, 429.586238355, -0.155446448138\n",
      "3\n",
      "test L_HC vol, std, corr: 3219.05, 427.451378327, -0.0555386118249\n",
      "test R_HC vol, std, corr: 3261.18333333, 417.979724056, -0.153752536955\n",
      "train L_HC vol, std, corr: 3245.74193548, 392.841313674, -0.190191860273\n",
      "train R_HC vol, std, corr: 3276.74193548, 425.666689731, -0.189319970904\n",
      "4\n",
      "test L_HC vol, std, corr: 3303.30508475, 337.832033997, -0.119925583755\n",
      "test R_HC vol, std, corr: 3303.01694915, 377.347768903, -0.0417063065302\n",
      "train L_HC vol, std, corr: 3236.27651515, 402.073300147, -0.18172102963\n",
      "train R_HC vol, std, corr: 3272.03787879, 429.789622696, -0.19991316482\n",
      "5\n",
      "test L_HC vol, std, corr: 3284.93220339, 352.822895237, -0.295220838458\n",
      "test R_HC vol, std, corr: 3318.47457627, 342.560614749, -0.372181929372\n",
      "train L_HC vol, std, corr: 3238.32954545, 400.923060562, -0.165700539946\n",
      "train R_HC vol, std, corr: 3270.31060606, 432.875093654, -0.170419860919\n",
      "6\n",
      "test L_HC vol, std, corr: 3314.89655172, 341.703828688, -0.140142815621\n",
      "test R_HC vol, std, corr: 3386.5, 339.582565756, -0.237213424786\n",
      "train L_HC vol, std, corr: 3235.13232514, 401.3809874, -0.178650515188\n",
      "train R_HC vol, std, corr: 3262.94328922, 431.503754523, -0.179981686559\n",
      "7\n",
      "test L_HC vol, std, corr: 3283.25862069, 275.567724972, 0.0167935705213\n",
      "test R_HC vol, std, corr: 3300.74137931, 308.957399158, -0.0648132232385\n",
      "train L_HC vol, std, corr: 3238.60113422, 407.448478284, -0.194277803556\n",
      "train R_HC vol, std, corr: 3272.34593573, 435.662587079, -0.197659666686\n",
      "8\n",
      "test L_HC vol, std, corr: 3154.24137931, 384.604916422, -0.342935487462\n",
      "test R_HC vol, std, corr: 3177.36206897, 411.843404215, -0.375004651604\n",
      "train L_HC vol, std, corr: 3252.74669187, 396.686574379, -0.162918126743\n",
      "train R_HC vol, std, corr: 3285.87334594, 424.955446379, -0.170202445431\n",
      "9\n",
      "test L_HC vol, std, corr: 3208.06896552, 518.749586192, -0.0431652089823\n",
      "test R_HC vol, std, corr: 3226.86206897, 558.675602878, 0.035552849803\n",
      "train L_HC vol, std, corr: 3246.84499055, 380.636486378, -0.197683683159\n",
      "train R_HC vol, std, corr: 3280.44612476, 407.237845707, -0.221488751403\n",
      "10\n",
      "test L_HC vol, std, corr: 3227.0, 432.035086294, -0.27471550689\n",
      "test R_HC vol, std, corr: 3309.54385965, 414.471469408, -0.220014824624\n",
      "train L_HC vol, std, corr: 3244.73584906, 392.559763552, -0.164101376484\n",
      "train R_HC vol, std, corr: 3271.45283019, 425.855869233, -0.181710173199\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Container object of 80 artists>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEPCAYAAAAXq1CWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIAiCECUUoAiCIAhRQgGKIAiCECX/H54sWn/w2/fAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f37bee9e510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# QC plots\n",
    "n_feat = X.shape[1]\n",
    "print X.shape\n",
    "\n",
    "feat_corr  = []\n",
    "for col in np.arange(n_feat):\n",
    "    feat_corr.append(stats.pearsonr(X[:,col],y)[0])\n",
    "\n",
    "print 'L_HC corr: {}, R_HC_corr: {}'.format(feat_corr[0],feat_corr[1]) \n",
    "print 'HC Correlation in each fold'\n",
    "fid = 1\n",
    "for train_index, test_index in kf:    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    train_L_HC_vol_mean = np.mean(X_train[:,0])\n",
    "    train_L_HC_vol_std = np.std(X_train[:,0])\n",
    "    train_R_HC_vol_mean = np.mean(X_train[:,1])\n",
    "    train_R_HC_vol_std = np.std(X_train[:,1])\n",
    "    \n",
    "    test_L_HC_vol_mean = np.mean(X_test[:,0])\n",
    "    test_L_HC_vol_std = np.std(X_test[:,0])\n",
    "    test_R_HC_vol_mean = np.mean(X_test[:,1])\n",
    "    test_R_HC_vol_std = np.std(X_test[:,1])\n",
    "    \n",
    "    train_L_HC_corr = stats.pearsonr(X_train[:,0],y_train)[0]\n",
    "    train_R_HC_corr = stats.pearsonr(X_train[:,1],y_train)[0]\n",
    "    test_L_HC_corr = stats.pearsonr(X_test[:,0],y_test)[0]\n",
    "    test_R_HC_corr = stats.pearsonr(X_test[:,1],y_test)[0]\n",
    "    print fid\n",
    "    fid+=1\n",
    "    print 'test L_HC vol, std, corr: {}, {}, {}'.format(test_L_HC_vol_mean,test_L_HC_vol_std,test_L_HC_corr)\n",
    "    print 'test R_HC vol, std, corr: {}, {}, {}'.format(test_R_HC_vol_mean,test_R_HC_vol_std,test_R_HC_corr)\n",
    "    print 'train L_HC vol, std, corr: {}, {}, {}'.format(train_L_HC_vol_mean,train_L_HC_vol_std,train_L_HC_corr)\n",
    "    print 'train R_HC vol, std, corr: {}, {}, {}'.format(train_R_HC_vol_mean,train_R_HC_vol_std,train_R_HC_corr)\n",
    "\n",
    "alpha = 0.5\n",
    "plt.figure()\n",
    "plt.subplot(2,2,1)\n",
    "plt.title('HC_L total volume')\n",
    "plt.hist(X[y_dx_int==0,0],bins=100,alpha=alpha,label='AD')\n",
    "plt.hist(X[y_dx_int==1,0],bins=100,alpha=alpha,label='CN')\n",
    "plt.hist(X[y_dx_int==2,0],bins=100,alpha=alpha,label='MCI')\n",
    "plt.legend()\n",
    "plt.subplot(2,2,2)\n",
    "plt.title('HC_R total volume')\n",
    "plt.hist(X[y_dx_int==0,1],bins=100,alpha=alpha,label='AD')\n",
    "plt.hist(X[y_dx_int==1,1],bins=100,alpha=alpha,label='CN')\n",
    "plt.hist(X[y_dx_int==2,1],bins=100,alpha=alpha,label='MCI')\n",
    "plt.legend()\n",
    "plt.subplot(2,2,3)\n",
    "plt.title('CT mean per ROI')\n",
    "plt.bar(np.arange(n_feat-2),np.mean(X[:,2:],axis=0))\n",
    "plt.subplot(2,2,4)\n",
    "plt.title('Correlation with CS for each feature')\n",
    "plt.bar(np.arange(n_feat),feat_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Configs for K-fold validations (nested)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import grid_search\n",
    "import datetime\n",
    "import time\n",
    "import collections\n",
    "from scipy.stats import mode\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import ipyparallel as ipp\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import KFold\n",
    "import pickle\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Pick model with its configs/hyper-params\n",
    "model_list = ['LR_L1', 'SVR', 'RFR']\n",
    "model_choice_id = 2\n",
    "model_choice = model_list[model_choice_id]\n",
    "modality = 'HC_CT'\n",
    "\n",
    "if model_choice == 'LR_L1':\n",
    "    model_clf = Lasso()\n",
    "    hyper_params = {'alpha':[0.2, 0.1, 0.05, 0.01]} \n",
    "    scale_data = True #Scales HC and CT features\n",
    "    inner_loop = True #only needed to optimize hyper-params\n",
    "    feat_imp = True    \n",
    "        \n",
    "elif model_choice == 'SVR':\n",
    "    model_clf = SVR()\n",
    "    hyper_params = {'kernel':['linear','rbf'], 'C':[1,10,25]}\n",
    "    scale_data = True #Scales HC and CT features\n",
    "    inner_loop = True #only needed to optimize hyper-params\n",
    "    feat_imp = True\n",
    "           \n",
    "elif model_choice == 'RFR':\n",
    "    model_clf = RandomForestRegressor(n_jobs=6)\n",
    "    hyper_params = {'n_estimators':[10,50,100,200],'min_samples_split':[2,4,8]}\n",
    "    #hyper_params = {'min_samples_split':[2,4,8,16]}\n",
    "    scale_data = False\n",
    "    inner_loop = True #only needed to optimize hyper-params\n",
    "    feat_imp = True   \n",
    "    \n",
    "else:\n",
    "    print \"Unknown model choice\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape (587, 80)\n",
      "most frequent hp:{'n_estimators': array([100]), 'min_samples_split': array([2])}\n",
      "CV r (mean, median, std_err): 0.57,0.58,0.03\n",
      "CV R2 (mean, median, std_err): 0.32,0.31, 0.03\n",
      "CV MSE (mean, median, std_err): 66.61,67.49, 4.94\n"
     ]
    }
   ],
   "source": [
    "# Train and Test models\n",
    "from functools import partial #Parallelize!!! \n",
    "\n",
    "# Load save experimental setup\n",
    "cohort = 'ADNI2'\n",
    "exp_setup_path = '/projects/nikhil/ADNI_prediction/input_datasets/exp_data/CV_Exp5_{}_ADAS13.pkl'.format(cohort)\n",
    "exp_setup = pickle.load( open(exp_setup_path, \"rb\" ) )\n",
    "\n",
    "X_raw = exp_setup['X']\n",
    "\n",
    "if modality == 'HC_CT':\n",
    "    X_modality = X_raw\n",
    "elif modality == 'HC':\n",
    "    X_modality = X_raw[:,:2]\n",
    "elif modality == 'CT':\n",
    "    X_modality = X_raw[:,2:]\n",
    "else:\n",
    "    print \"Wrong modality selected...\"\n",
    "    \n",
    "if scale_data:\n",
    "    X = preprocessing.scale(X_modality)\n",
    "else:\n",
    "    X = X_modality\n",
    "\n",
    "print 'X shape {}'.format(X.shape)\n",
    "\n",
    "y = exp_setup['y']\n",
    "kf = exp_setup['kf']\n",
    "exp_name = exp_setup['exp_name']\n",
    "\n",
    "#Some paths to store models and performance stats\n",
    "CV_model_dir = '/projects/nikhil/ADNI_prediction/input_datasets/exp_data/output/'\n",
    "saved_model_name =''\n",
    "save_model_path = CV_model_dir + exp_name + '_' + model_choice\n",
    "load_model_path = CV_model_dir + saved_model_name\n",
    "\n",
    "# train a new classifer? Or load a single pretrained classifier based on most frequent hyperparams found previously?\n",
    "# This will NOT load K different classifiers each for outer-CV fold  \n",
    "train_clf = True\n",
    "save_model = False #do you really want to save all classifiers per each fold? (default false) \n",
    "\n",
    "if train_clf:\n",
    "    # Create list of all the fold-subsets (needed for parallelization)\n",
    "    X_train = []\n",
    "    X_valid = []\n",
    "    y_train = []\n",
    "    y_valid = []    \n",
    "    for train, valid in kf:        \n",
    "        X_train.append(X[train])\n",
    "        X_valid.append(X[valid])\n",
    "        y_train.append(y[train])\n",
    "        y_valid.append(y[valid])\n",
    "\n",
    "    CV_r_train=[] #pearson r score for each outer fold on train set\n",
    "    CV_r_valid=[] #pearson r score for each outer fold on validation set\n",
    "\n",
    "    CV_R2_train=[] #R2 score for each outer fold on train set\n",
    "    CV_R2_valid=[] #R2 score for each outer fold on validation set\n",
    "\n",
    "    CV_MSE_train=[] #MSE for each outer fold on train set\n",
    "    CV_MSE_valid=[] #MSE for each outer fold on validation set\n",
    "    \n",
    "    predicted_CV_scores = []\n",
    "    actual_CV_scores = []\n",
    "    \n",
    "    # Parallization configs for ipython notebook cluster    \n",
    "    rc = ipp.Client()\n",
    "    dview = rc[:]\n",
    "    dview.push(dict(computeOuterFold = computeOuterFold))\n",
    "    dview.push(dict(innerCVLoop = innerCVLoop))\n",
    "    mapfunc = partial(computeOuterFold, model_clf=model_clf, hyper_params=hyper_params, inner_loop=inner_loop, \n",
    "                  save_model=save_model, save_model_path=save_model_path)\n",
    "    parallel_result = dview.map_sync(mapfunc, X_train, y_train, X_valid, y_valid)    \n",
    "    \n",
    "    hp_dict = collections.defaultdict(list)\n",
    "    for pr in parallel_result:\n",
    "        CV_r_train.append(pr['r_train'])\n",
    "        CV_r_valid.append(pr['r_valid'])\n",
    "        CV_R2_train.append(pr['R2_train'])\n",
    "        CV_R2_valid.append(pr['R2_valid'])\n",
    "        CV_MSE_train.append(pr['MSE_train'])\n",
    "        CV_MSE_valid.append(pr['MSE_valid'])\n",
    "        predicted_CV_scores.append(pr['predicted_fold_score'])\n",
    "        actual_CV_scores.append(pr['actual_fold_scores'])\n",
    "        \n",
    "        for hp in hyper_params:\n",
    "            hp_dict[hp].append(pr['hp_dict'][hp])\n",
    "            \n",
    "    #Find out most frequent hyper-params during cross-val    \n",
    "    hp_mode = {}\n",
    "    for hp in hyper_params:\n",
    "        hp_mode[hp] = mode(hp_dict[hp])[0][0]\n",
    "\n",
    "    print 'most frequent hp:' + str(hp_mode)\n",
    "    \n",
    "else: \n",
    "    #Grabs the best classifer as a result of N-fold nested CV along with the MSE and R2 stats of the outerloop\n",
    "    print \"Loading previously saved model: \"\n",
    "    f = open(load_model_path)\n",
    "    result = pickle.load(f)\n",
    "    test_clf = result['best_clf']\n",
    "    CV_r_valid = result['CV_r']\n",
    "    CV_R2_valid = result['CV_R2']\n",
    "    CV_MSE_valid = result['CV_MSE']\n",
    "    f.close()\n",
    "\n",
    "print 'CV r (mean, median, std_err): ' + '{:04.2f},{:04.2f},{:04.2f}'.format(np.mean(zip(*CV_r_valid)[0]),np.median(zip(*CV_r_valid)[0]),stats.sem(zip(*CV_r_valid)[0]))\n",
    "print 'CV R2 (mean, median, std_err): ' + '{:04.2f},{:04.2f}, {:04.2f}'.format(np.mean(CV_R2_valid),np.median(CV_R2_valid),stats.sem(CV_R2_valid))\n",
    "print 'CV MSE (mean, median, std_err): ' + '{:04.2f},{:04.2f}, {:04.2f}'.format(np.mean(CV_MSE_valid),np.median(CV_MSE_valid),stats.sem(CV_MSE_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check feature importance (QC for HC importance)\n",
    "# for fid in np.arange(10):\n",
    "#     model_clf.fit(X_train[fid],y_train[fid])\n",
    "#     feat_imp = model_clf.feature_importances_\n",
    "#     print \n",
    "#     print 'fid: {} r: {}'.format(fid, zip(*CV_r_valid)[0][fid])\n",
    "#     print feat_imp[70:], np.argsort(feat_imp)[70:]\n",
    "print zip(*CV_r_valid)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Baseline LR\n",
    "(0.67967240054210754, 0.56879797495184137, 0.5988231662490886, 0.49284028165514948, 0.44557890444609999, \n",
    " 0.47786003640429192, 0.46596289072680858, 0.57504122653514778, 0.50115343570863291, 0.39597569280487466)\n",
    "\n",
    "Baseline SVM\n",
    "(0.62237892217611546, 0.57901237913619108, 0.5995505148783985, 0.63809749144729178, 0.50999802815791628, \n",
    " 0.41846572003796645, 0.51909135695525321, 0.53601265150967115, 0.62202899109905141, 0.46246681135277817)\n",
    "\n",
    "Baseline RF\n",
    "(0.63730326194822251, 0.5480008167500251, 0.5979178178622252, 0.6345268923559243, 0.50666992310274372, \n",
    " 0.42995872752093789, 0.51865025005439525, 0.54964129730024791, 0.62336378651955171, 0.48022963536921681)\n",
    "\n",
    "Benchmark: \n",
    "    \n",
    "X shape (680, 80)\n",
    "most frequent hp:{'n_estimators': array([200]), 'min_samples_split': array([8])}\n",
    "CV r (mean, median, std_err): 0.55,0.55,0.02\n",
    "CV R2 (mean, median, std_err): 0.30,0.28, 0.02\n",
    "CV MSE (mean, median, std_err): 56.87,50.27, 4.55\n",
    "\n",
    "#LR_L1\n",
    "---Pilot------\n",
    "most frequent hp:{'alpha': array([ 0.2])}\n",
    "CV r (mean, median, std_err): 0.55,0.57,0.02\n",
    "CV R2 (mean, median, std_err): 0.29,0.29, 0.03\n",
    "CV MSE (mean, median, std_err): 57.22,52.11, 4.19        \n",
    "    \n",
    "---Exp3------\n",
    "CT: X shape (716, 78)\n",
    "most frequent hp:{'alpha': array([ 0.2])}\n",
    "CV r (mean, median, std_err): 0.57,0.55,0.02\n",
    "CV R2 (mean, median, std_err): 0.31,0.29, 0.02\n",
    "CV MSE (mean, median, std_err): 57.78,54.68, 3.50\n",
    "    \n",
    "HC_CT: X shape (716, 80)\n",
    "most frequent hp:{'alpha': array([ 0.2])}\n",
    "CV r (mean, median, std_err): 0.57,0.56,0.02\n",
    "CV R2 (mean, median, std_err): 0.31,0.30, 0.02\n",
    "CV MSE (mean, median, std_err): 57.27,54.46, 3.47\n",
    "\n",
    "\n",
    "#SVM\n",
    "---Pilot------\n",
    "most frequent hp:{'kernel': array(['rbf'], \n",
    "      dtype='|S3'), 'C': array([10])}\n",
    "CV r (mean, median, std_err): 0.53,0.51,0.03\n",
    "CV R2 (mean, median, std_err): 0.26,0.23, 0.04\n",
    "CV MSE (mean, median, std_err): 59.88,55.64, 5.08\n",
    "#RF\n",
    "---Pilot------\n",
    "most frequent hp:{'n_estimators': array([100]), 'min_samples_split': array([4])}\n",
    "CV r (mean, median, std_err): 0.56,0.58,0.02\n",
    "CV R2 (mean, median, std_err): 0.30,0.31, 0.03\n",
    "CV MSE (mean, median, std_err): 57.05,51.99, 4.91\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute single model from the most frequent hyper-params (for across dataset testing)\n",
    "\n",
    "#test_clf = Lasso(alpha=0.2)    \n",
    "#test_clf = SVR(kernel='rbf',C=25)\n",
    "test_clf = RandomForestRegressor(n_estimators=200,min_samples_split=4,n_jobs=4)\n",
    "\n",
    "save_CV_perf = True    \n",
    "if save_CV_perf:\n",
    "    ts = time.time()\n",
    "    st = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d-%H-%M-%S')\n",
    "    save_model_filename = save_model_path + '_' + modality + '_' + st + '.pkl'\n",
    "    classifier_model_and_stats = {'best_clf':test_clf, 'CV_R2':CV_R2_valid, 'CV_MSE':CV_MSE_valid, 'CV_r': CV_r_valid,\n",
    "                                 'predicted_CV_scores':predicted_CV_scores,'actual_CV_scores':actual_CV_scores}\n",
    "    pickleIt(classifier_model_and_stats,save_model_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting stuff...\n",
    "boxplot_config_r = collections.defaultdict(list)\n",
    "boxplot_config_R2 = collections.defaultdict(list)\n",
    "boxplot_config_MSE = collections.defaultdict(list)\n",
    "boxplots_dir = '/projects/nikhil/ADNI_prediction/input_datasets/exp_data/output/'\n",
    "scale = 'ADAS13'\n",
    "if scale == 'ADAS13':\n",
    "    baseline_models = {'LR_HC*':'Exp4_ADNI1_ADAS13_LR_L1_HC_2016-02-29-15-16-45.pkl',\n",
    "                       'LR_CT*':'Exp4_ADNI1_ADAS13_LR_L1_CT_2016-02-29-15-17-13.pkl',\n",
    "                       'LR_HC_CT*': 'Exp4_ADNI1_ADAS13_LR_L1_HC_CT_2016-02-29-15-17-50.pkl',\n",
    "                       'SVR_HC*':'Exp4_ADNI1_ADAS13_SVR_HC_2016-02-29-15-11-52.pkl',\n",
    "                       'SVR_CT*':'Exp4_ADNI1_ADAS13_SVR_CT_2016-02-29-15-14-09.pkl',\n",
    "                       'SVR_HC_CT*':'Exp4_ADNI1_ADAS13_SVR_HC_CT_2016-02-29-15-16-22.pkl', \n",
    "                       'RFR_HC':'Exp4_ADNI1_ADAS13_RFR_HC_2016-02-29-15-19-26.pkl',\n",
    "                       'RFR_CT':'Exp4_ADNI1_ADAS13_RFR_CT_2016-02-29-15-21-25.pkl',\n",
    "                       'RFR_HC_CT':'Exp4_ADNI1_ADAS13_RFR_HC_CT_2016-02-29-15-24-23.pkl'}\n",
    "if scale == 'MMSE':\n",
    "    baseline_models = {'LR_L1*': 'LR_L1_MMSE_2015-12-29-16-41-41.pkl',\n",
    "                    'SVR*':'RFR_MMSE_2015-12-29-17-35-51.pkl', \n",
    "                    'RFR':'SVR_MMSE_2015-12-29-17-40-24.pkl'}\n",
    "\n",
    "# Not plotted:\n",
    "# 'LR_L1': 'LR_L1_ADAS13_2015-11-06-12-25-21.pkl'\n",
    "# 'LR_L1_infl':'LR_L1_ADAS13_inflated_train_parallel_2015-11-27-15-05-17.pkl'\n",
    "r_means =  collections.defaultdict(list)    \n",
    "r_medians =  collections.defaultdict(list)    \n",
    "r_sems =  collections.defaultdict(list)\n",
    "mse_means =  collections.defaultdict(list)        \n",
    "mse_medians =  collections.defaultdict(list)        \n",
    "mse_sems =  collections.defaultdict(list)\n",
    "predicted_CV_scores = collections.defaultdict(list) \n",
    "actual_CV_scores = collections.defaultdict(list)\n",
    "keys_used = []\n",
    "for key,val in baseline_models.iteritems():\n",
    "    pkl_file = open(boxplots_dir + val, 'rb')\n",
    "    saved_data = pickle.load(pkl_file)\n",
    "    pkl_file.close()            \n",
    "    boxplot_config_r[key].append(zip(*saved_data['CV_r'])[0])\n",
    "    boxplot_config_MSE[key].append(saved_data['CV_MSE'])\n",
    "    print 'key: {}, mean: {}, median: {}, std: {}'.format(key,np.mean(zip(*saved_data['CV_r'])[0]),\n",
    "                                              np.median(zip(*saved_data['CV_r'])[0]),\n",
    "                                              np.std(zip(*saved_data['CV_r'])[0]))\n",
    "    r_means[key].append(np.mean(zip(*saved_data['CV_r'])[0]))\n",
    "    r_medians[key].append(np.median(zip(*saved_data['CV_r'])[0]))\n",
    "    r_sems[key].append(stats.sem(zip(*saved_data['CV_r'])[0]))        \n",
    "\n",
    "    mse_means[key].append(np.mean(saved_data['CV_MSE']))\n",
    "    mse_sems[key].append(stats.sem(saved_data['CV_MSE']))        \n",
    "    if key in ['LR_HC_CT*','SVR_HC_CT*','RFR_HC_CT']:\n",
    "        predicted_CV_scores[key].append(saved_data['predicted_CV_scores'])\n",
    "        actual_CV_scores[key].append(saved_data['actual_CV_scores'])\n",
    "\n",
    "# Since ANN model perfs are saved differently :-/\n",
    "boxplots_dir = '/projects/nikhil/ADNI_prediction/input_datasets/exp_data/NN/montage_data/'\n",
    "ANN_models ={'CT':'Exp4_ADNI1_ADAS13_NN_CT_2016-03-03-21-54-55.pkl',\n",
    "             'HC':'Exp4_ADNI1_ADAS13_NN_HC_2016-03-04-00-24-38.pkl',\n",
    "             'HC_CT':'Exp4_ADNI1_ADAS13_NN_HC_CT_2016-03-03-14-34-34.pkl'}\n",
    "\n",
    "for key,val in ANN_models.iteritems():\n",
    "    pkl_file = open(boxplots_dir + val, 'rb')\n",
    "    saved_data = pickle.load(pkl_file)               \n",
    "    boxplot_config_r['ANN_'+key].append(saved_data['CV_r'])\n",
    "    boxplot_config_MSE['ANN_'+key].append(saved_data['CV_MSE'])\n",
    "    pkl_file.close()\n",
    "    print 'key: {}, mean: {}, median: {}, std: {}'.format(key,np.mean(saved_data['CV_r']),\n",
    "                                              np.median(saved_data['CV_r']),\n",
    "                                              np.std(saved_data['CV_r']))\n",
    "    r_means['ANN_'+key].append(np.mean(saved_data['CV_r']))\n",
    "    r_sems['ANN_'+key].append(stats.sem(saved_data['CV_r']))\n",
    "\n",
    "    mse_means['ANN_'+key].append(np.mean(saved_data['CV_MSE']))\n",
    "    mse_sems['ANN_'+key].append(stats.sem(saved_data['CV_MSE']))\n",
    "    if key == 'HC_CT':\n",
    "        predicted_CV_scores['ANN_' + key].append(saved_data['predicted_CV_scores'])\n",
    "        actual_CV_scores['ANN_' + key].append(saved_data['actual_CV_scores'])\n",
    "\n",
    "print zip(r_means, r_sems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot foldwise results\n",
    "plt.rcParams['figure.figsize'] = (20, 10)\n",
    "fids = np.arange(1,11,1)\n",
    "print boxplot_config_r.keys()\n",
    "for key in boxplot_config_r.keys():\n",
    "    if key in ['ANN_CT','ANN_HC','ANN_HC_CT']:\n",
    "        custom_marker = 'd'    \n",
    "    else:\n",
    "        custom_marker = 'o'\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.plot(fids,boxplot_config_r[key][0],linestyle='None',marker=custom_marker,label=key)\n",
    "    plt.legend(bbox_to_anchor=[0.5, -0.1], loc='center', ncol=6)    \n",
    "    plt.xlim(0,11)\n",
    "\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(fids,boxplot_config_MSE[key][0],linestyle='None',marker=custom_marker,label=key)\n",
    "    plt.legend(bbox_to_anchor=[0.5, -0.1], loc='center', ncol=6)\n",
    "    plt.xlim(0,11)\n",
    "\n",
    "\n",
    "modality = 'ANN_HC_CT'\n",
    "    \n",
    "print 'corr: {}:{}'.format(modality,boxplot_config_r[modality][0][4:8])\n",
    "print 'MSE: {}:{}'.format(modality,boxplot_config_MSE[modality][0][4:8])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Boxplots for CV statistics (r, mse, R2)\n",
    "stat_measure_list = [boxplot_config_r,boxplot_config_MSE] #boxplot_config_MSE\n",
    "stat_measure_names = ['Pearson r', 'RMSE'] #'MSE'\n",
    "from matplotlib.artist import setp\n",
    "font_small = 25\n",
    "font_med = 30\n",
    "font_large = 40\n",
    "plt.rcParams['figure.figsize'] = (40, 40)\n",
    "#custom_cols = ['LR_L1*','LR_L1_infl*', 'SVR*', 'SVR_infl*', 'RFR', 'RFR_infl','ANN_HC_CT']\n",
    "custom_cols = ['LR_HC*','LR_CT*','LR_HC_CT*','SVR_HC*','SVR_CT*','SVR_HC_CT*','RFR_HC','RFR_CT','RFR_HC_CT',\n",
    "               'ANN_HC','ANN_CT','ANN_HC_CT']\n",
    "boxplot = False\n",
    "errorbarplot = True\n",
    "scatterplot = True\n",
    "\n",
    "my_colors = ['steelblue', 'olivedrab', 'cadetblue', 'salmon']\n",
    "#plt.figure()\n",
    "ax1 = plt.subplot2grid((6,2), (0,0), colspan=2,rowspan=2)\n",
    "ax2 = plt.subplot2grid((6,2), (2,0), colspan=2,rowspan=2)\n",
    "ax3 = plt.subplot2grid((6,2), (4,0))\n",
    "ax4 = plt.subplot2grid((6,2), (4,1))\n",
    "ax5 = plt.subplot2grid((6,2), (5,0))\n",
    "ax6 = plt.subplot2grid((6,2), (5,1))\n",
    "\n",
    "ax_list = [ax1,ax2,ax3,ax4,ax5,ax6]\n",
    "\n",
    "if errorbarplot:\n",
    "    custom_r_means = []    \n",
    "    custom_r_sems = []    \n",
    "    custom_mse_means = []\n",
    "    custom_mse_sems = []\n",
    "    for c, col in enumerate(custom_cols):\n",
    "        custom_r_means.append(r_means[col][0])        \n",
    "        custom_r_sems.append(r_sems[col][0])\n",
    "        custom_mse_means.append(mse_means[col][0])        \n",
    "        custom_mse_sems.append(mse_sems[col][0])\n",
    "        \n",
    "    x_r = np.array([0,1,2,4,5,6,8,9,10,12,13,14])  # padding to better appearance \n",
    "    x_mse = x_r \n",
    "    #plt.bar(x, np.array(custom_r_means), yerr=np.array(custom_r_sems))\n",
    "    width = 0.25                    # bar width\n",
    "\n",
    "    #fig, ax = plt.subplots()\n",
    "    plot_corr = True\n",
    "    if plot_corr: \n",
    "\n",
    "        rects1 = ax1.bar(x_r[:3], custom_r_means[:3],                  # data\n",
    "                        width,                          # bar width\n",
    "                        color=my_colors[0],        # bar colour\n",
    "                        yerr=custom_r_sems[:3],               # data for error bars\n",
    "                        error_kw={'ecolor':'darkslategrey',    # error-bars colour\n",
    "                                 'linewidth':4},       # error-bar width\n",
    "                        label = 'Linear Regression')\n",
    "\n",
    "        rects2 = ax1.bar(x_r[3:6], custom_r_means[3:6],                  # data\n",
    "                        width,                          # bar width\n",
    "                        color=my_colors[1],        # bar colour\n",
    "                        yerr=custom_r_sems[3:6],               # data for error bars\n",
    "                        error_kw={'ecolor':'darkslategrey',    # error-bars colour\n",
    "                                 'linewidth':4},\n",
    "                        label = 'Support Vector Regression')\n",
    "\n",
    "        rects3 = ax1.bar(x_r[6:9], custom_r_means[6:9],                  # data\n",
    "                        width,                          # bar width\n",
    "                        color=my_colors[2],        # bar colour\n",
    "                        yerr=custom_r_sems[6:9],               # data for error bars\n",
    "                        error_kw={'ecolor':'darkslategrey',    # error-bars colour\n",
    "                                 'linewidth':4},\n",
    "                         label = 'Random Forest')\n",
    "\n",
    "        rects4 = ax1.bar(x_r[9:], custom_r_means[9:],                  # data\n",
    "                        width,                          # bar width\n",
    "                        color=my_colors[3],        # bar colour\n",
    "                        yerr=custom_r_sems[9:],               # data for error bars\n",
    "                        error_kw={'ecolor':'darkslategrey',    # error-bars colour\n",
    "                                 'linewidth':4},\n",
    "                        label = 'Artificial Neural Network')\n",
    "        autolabel(rects1,ax1)\n",
    "        autolabel(rects2,ax1)\n",
    "        autolabel(rects3,ax1)\n",
    "        autolabel(rects4,ax1)\n",
    "        #Plot annotations \n",
    "        ax1.set_ylabel('Correlation',fontsize=font_large)\n",
    "        ax1.set_xlim(-0.5,max(x_r)+1)\n",
    "        ax1.set_ylim(0,1)\n",
    "        ax1.set_xticks(x_r)\n",
    "        ax1.set_xticklabels(custom_cols)\n",
    "        ax1.tick_params(labelsize=font_small)\n",
    "        #ax1.set_yticks(fontsize=font_med)\n",
    "        ax1.legend(fontsize=font_med, loc=2)\n",
    "    \n",
    "    plot_mse = True\n",
    "    if plot_mse: \n",
    "        rects5 = ax2.bar(x_mse[:3], custom_mse_means[:3],                  # data\n",
    "                        width,                          # bar width\n",
    "                        color=my_colors[0],        # bar colour\n",
    "                        yerr=custom_mse_sems[:3],               # data for error bars\n",
    "                        error_kw={'ecolor':'darkslategrey',    # error-bars colour\n",
    "                                 'linewidth':4})\n",
    "\n",
    "        rects6 = ax2.bar(x_mse[3:6], custom_mse_means[3:6],                  # data\n",
    "                        width,                          # bar width\n",
    "                        color=my_colors[1],        # bar colour\n",
    "                        yerr=custom_mse_sems[3:6],               # data for error bars\n",
    "                        error_kw={'ecolor':'darkslategrey',    # error-bars colour\n",
    "                                 'linewidth':4})\n",
    "\n",
    "        rects7 = ax2.bar(x_mse[6:9], custom_mse_means[6:9],                  # data\n",
    "                        width,                          # bar width\n",
    "                        color=my_colors[2],        # bar colour\n",
    "                        yerr=custom_mse_sems[6:9],               # data for error bars\n",
    "                        error_kw={'ecolor':'darkslategrey',    # error-bars colour\n",
    "                                 'linewidth':4})\n",
    "\n",
    "        rects8 = ax2.bar(x_mse[9:], custom_mse_means[9:],                  # data\n",
    "                        width,                          # bar width\n",
    "                        color=my_colors[3],        # bar colour\n",
    "                        yerr=custom_mse_sems[9:],               # data for error bars\n",
    "                        error_kw={'ecolor':'darkslategrey',    # error-bars colour\n",
    "                                 'linewidth':4})\n",
    "        autolabel(rects5,ax2)\n",
    "        autolabel(rects6,ax2)\n",
    "        autolabel(rects7,ax2)\n",
    "        autolabel(rects8,ax2)\n",
    "\n",
    "        #Plot annotations \n",
    "        ax2.set_ylabel('MSE',fontsize=font_large)\n",
    "        ax2.set_xlim(-0.5,max(x_r)+1)\n",
    "        ax2.set_ylim(0,100)\n",
    "        ax2.set_xticks(x_r)\n",
    "        ax2.set_xticklabels(custom_cols)\n",
    "        ax2.tick_params(labelsize=font_small)\n",
    "        #ax1.set_yticks(fontsize=font_med)\n",
    "        ax2.legend(fontsize=font_med, loc=2)\n",
    "    \n",
    "if scatterplot:\n",
    "    #plt.figure()\n",
    "    \n",
    "    for k, key in enumerate(['LR_HC_CT*','SVR_HC_CT*', 'RFR_HC_CT', 'ANN_HC_CT']):\n",
    "        x = np.hstack(actual_CV_scores[key][0])\n",
    "        y = np.hstack(predicted_CV_scores[key][0])\n",
    "        ax_offset = 2\n",
    "        #plt.subplot(2,2,k+1)\n",
    "        ax_list[k+ax_offset].scatter(x, y, c=my_colors[k], s=40)\n",
    "        fit = np.polyfit(x,y,1)\n",
    "        fit_fn = np.poly1d(fit) \n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
    "        if p_value < 0.0001:\n",
    "            p_value_sig = '<0.0001'\n",
    "        else:\n",
    "            p_value_sig = str(p_value)\n",
    "\n",
    "        #Plot annotations\n",
    "        label_str = 'model: {}'.format(key) + '\\n' + 'r-value: {:04.2f}'.format(r_value) + '\\n' + 'p-value: ' + p_value_sig + '\\n' + 'std_err: {:04.2f}'.format(std_err) \n",
    "        # fit_fn is now a function which takes in x and returns an estimate for y\n",
    "        ax_list[k+ax_offset].plot(x, fit_fn(x),linewidth=3, c=my_colors[k], label=label_str)\n",
    "        #plt.title(model_choice,fontsize=font_large)\n",
    "        ax_list[k+ax_offset].set_ylim(0,40)\n",
    "        ax_list[k+ax_offset].set_xlabel('Actual Score',fontsize=font_large)\n",
    "        ax_list[k+ax_offset].set_ylabel('Predicted Score',fontsize=font_large)            \n",
    "        ax_list[k+ax_offset].legend(fontsize=font_small,loc=2)\n",
    "        ax_list[k+ax_offset].tick_params(labelsize=font_med)\n",
    "\n",
    "#Save figure\n",
    "save_fig = False\n",
    "if save_fig:\n",
    "    box_fig = plt.gcf()\n",
    "    box_fig.savefig('{}Exp4_ADNI1_ADAS13_PerfPlots.png'.format(boxplots_dir), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Some Defs\n",
    "def pickleIt(my_data,save_path):\n",
    "    f = open(save_path, 'wb')\n",
    "    pickle.dump(my_data, f)\n",
    "    f.close()\n",
    "\n",
    "#Outer Fold Computation (need the imports inside def if you want to parallelize!)\n",
    "def computeOuterFold(train_X, train_y, valid_X, valid_y, model_clf, hyper_params, inner_loop, save_model, save_model_path):\n",
    "    import collections\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.linear_model import Lasso\n",
    "    from sklearn.svm import SVR\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn import grid_search\n",
    "    import datetime\n",
    "    import time\n",
    "    import collections\n",
    "    from scipy.stats import mode\n",
    "    from sklearn.metrics import mean_squared_error as mse\n",
    "    from scipy import stats\n",
    "    \n",
    "    print 'Starting Outerfold computation'\n",
    "    \n",
    "    hp_dict = collections.defaultdict(list) #store best hyper-parameters for each fold\n",
    "    \n",
    "    if inner_loop:     \n",
    "        print 'Starting InnerFold computation'\n",
    "        save_model_path_fold = save_model_path + '_fold_' \n",
    "        clf = innerCVLoop(model_clf,hyper_params,train_X, train_y,save_model,save_model_path_fold)\n",
    "        for hp in hyper_params:\n",
    "            hp_dict[hp].append(clf.best_estimator_.get_params()[hp])\n",
    "            \n",
    "        print 'Ending InnerFold computation'\n",
    "\n",
    "    else:\n",
    "        clf = model_clf\n",
    "        clf.fit(fold_X,fold_y)\n",
    "        \n",
    "    #CV_scores    \n",
    "    r_train = stats.pearsonr(clf.predict(train_X),train_y)\n",
    "    r_valid = stats.pearsonr(clf.predict(valid_X),valid_y)\n",
    "        \n",
    "    R2_train = clf.score(train_X,train_y) \n",
    "    R2_valid = clf.score(valid_X,valid_y)\n",
    "        \n",
    "    MSE_train = mse(clf.predict(train_X),train_y)\n",
    "    MSE_valid = mse(clf.predict(valid_X),valid_y)\n",
    "    \n",
    "    print 'Ending OuterFold computation'\n",
    "    \n",
    "    return {'r_train':r_train, 'r_valid':r_valid, 'R2_train':R2_train, 'R2_valid':R2_valid,\n",
    "            'MSE_train':MSE_train, 'MSE_valid':MSE_valid, 'hp_dict':hp_dict, \n",
    "            'predicted_fold_score': clf.predict(valid_X), 'actual_fold_scores':valid_y}\n",
    "\n",
    "#Inner Fold Computation (need the imports inside def if you want to parallelize!)\n",
    "def innerCVLoop(model_clf,hyper_params,fold_X, fold_y,save_model,save_model_path):\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.linear_model import Lasso\n",
    "    from sklearn.svm import SVR\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn import grid_search\n",
    "    clf = grid_search.GridSearchCV(model_clf, hyper_params,cv=3,verbose=0)\n",
    "    clf.fit(fold_X, fold_y)\n",
    "    #Save classifier\n",
    "    if save_model:\n",
    "        save_model(clf,save_model_path)\n",
    "        \n",
    "    return clf\n",
    "\n",
    "def autolabel(rects,_ax):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        _ax.text(rect.get_x() + rect.get_width()/2., 1.05*height,\n",
    "                '{:03.2f}'.format(height),\n",
    "                ha='center',            # vertical alignment\n",
    "                va='bottom',             # horizontal alignment\n",
    "                fontsize = 25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matches = [x for x in y_dx if x == 'No_DX']\n",
    "print matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CS_vals = sub_CS_dict_clean.values()\n",
    "plt.hist(CS_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cohort = 'ADNI2'\n",
    "exp_setup_path = '/projects/nikhil/ADNI_prediction/input_datasets/exp_data/CV_Exp5_{}_ADAS13.pkl'.format(cohort)\n",
    "exp_setup = pickle.load( open(exp_setup_path, \"rb\" ) )\n",
    "kf = exp_setup['kf']\n",
    "adni2_sub_list = exp_setup['common_subs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "777 587\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "common_keys = list(set(adni1_sub_list) & set(adni2_sub_list))\n",
    "print len(adni1_sub_list), len(adni2_sub_list)\n",
    "print common_keys\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
