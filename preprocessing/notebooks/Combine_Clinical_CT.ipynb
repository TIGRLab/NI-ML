{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py as h5\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "combined_path = '/projects/jp/adni-autoencoder/combined.h5'\n",
    "cortical_path = '/projects/nikhil/ADNI_prediction/input_datasets/CT/scans_AAL.csv'\n",
    "clinical_path = '/projects/francisco/data/ADNI/ADNI_Merge_filter.csv'\n",
    "fuse_path = '/projects/nikhil/miccai/input_data_comb/data_t300_adcn.h5'\n",
    "fused_segmentations_path = '/projects/francisco/data/ADNI/ordered_fused_ad_cn_mci_{}.h5'\n",
    "\n",
    "# ID patterns\n",
    "id_participant = re.compile(r\"\"\"\n",
    " (?<=ADNI_)      # Match the first string after ADNI_\n",
    " (.*?)          # Lazy quantifier so it only grabs the first immediate match.\n",
    " (?=_MR)        # End at the _MR\n",
    "\"\"\", re.VERBOSE)\n",
    "\n",
    "id_image = re.compile('(?<=S)\\d+_(.*?)(?=_)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49752\n"
     ]
    }
   ],
   "source": [
    "# Concatenate all the filenames\n",
    "filenames = set([])\n",
    "combined = h5.File(combined_path, 'r')\n",
    "\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    filenames = filenames.union(combined['l_{}_files'.format(split)])\n",
    "print len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "698 unique mappings found\n"
     ]
    }
   ],
   "source": [
    "# part > img id lookup\n",
    "participants = {}\n",
    "for f in filenames:\n",
    "    try:\n",
    "        id = re.search(id_participant, f).group(0)\n",
    "        img = re.search(id_image, f).group(1)\n",
    "        participants[id] = img\n",
    "    except:\n",
    "        print f\n",
    "print '{} unique mappings found'.format(len(participants.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "698 unique mappings found\n"
     ]
    }
   ],
   "source": [
    "# img id > part lookup\n",
    "images = {}\n",
    "for f in filenames:\n",
    "    try:\n",
    "        id = re.search(id_participant, f).group(0)\n",
    "        img = re.search(id_image, f).group(1)\n",
    "        images[img] = id\n",
    "    except:\n",
    "        print f\n",
    "print '{} unique mappings found'.format(len(images.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "\n",
    "# Load clinical and cortical datasets\n",
    "clinical = pd.read_csv(clinical_path)\n",
    "cortical = pd.read_csv(cortical_path)\n",
    "\n",
    "# Filter ADNI1 Baseline subjects \n",
    "baseline_adni_1 = clinical[(clinical.ORIGPROT =='ADNI1') & (clinical.COLPROT=='ADNI1') & (clinical.VISCODE == 'bl')]\n",
    "\n",
    "# Filter for subjects whom we have CT measurements for\n",
    "baseline_adni_1 = baseline_adni_1.loc[baseline_adni_1['PTID'].isin(participants)]\n",
    "img_id_col = [participants[id] for id in baseline_adni_1.PTID if id in participants.keys()]\n",
    "\n",
    "# Add image id to clinical table:\n",
    "baseline_adni_1.insert(2,'IID', img_id_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Rename the cortical variables\n",
    "new_cols = ['CT_{}'.format(col) for col in cortical.columns]\n",
    "cortical.columns = new_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas import merge\n",
    "\n",
    "# Rename ID to IID in cortical df\n",
    "cortical.rename(columns={'CT_ID':'IID'}, inplace=True)\n",
    "\n",
    "# Merge these suckas:\n",
    "merged = merge(baseline_adni_1, cortical, on=['IID'])\n",
    "\n",
    "# Save\n",
    "merged.to_csv('/projects/francisco/data/ADNI/ct_clinical.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'RID', u'PTID', u'IID', u'VISCODE', u'COLPROT', u'ORIGPROT', u'DX_bl',\n",
      "       u'AGE', u'PTGENDER', u'ADAS11', u'ADAS13', u'MMSE', u'ADAS11_bl',\n",
      "       u'ADAS13_bl', u'MMSE_bl', u'CT_REC.L', u'CT_OLF.L', u'CT_ORBsup.L',\n",
      "       u'CT_ORBsupmed.L', u'CT_ORBmid.L', u'CT_ORBinf.L', u'CT_SFGdor.L',\n",
      "       u'CT_MFG.L', u'CT_IFGoperc.L', u'CT_IFGtriang.L', u'CT_SFGmed.L',\n",
      "       u'CT_SMA.L', u'CT_PCL.L', u'CT_PreCG.L', u'CT_ROL.L', u'CT_PoCG.L',\n",
      "       u'CT_SPG.L', u'CT_IPL.L', u'CT_SMG.L', u'CT_ANG.L', u'CT_PCUN.L',\n",
      "       u'CT_SOG.L', u'CT_MOG.L', u'CT_IOG.L', u'CT_CAL.L', u'CT_CUN.L',\n",
      "       u'CT_LING.L', u'CT_FFG.L', u'CT_HES.L', u'CT_STG.L', u'CT_MTG.L',\n",
      "       u'CT_ITG.L', u'CT_TPOsup.L', u'CT_TPOmid.L', u'CT_ACG.L', u'CT_DCG.L',\n",
      "       u'CT_PCG.L', u'CT_REC.R', u'CT_OLF.R', u'CT_ORBsup.R',\n",
      "       u'CT_ORBsupmed.R', u'CT_ORBmid.R', u'CT_ORBinf.R', u'CT_SFGdor.R',\n",
      "       u'CT_MFG.R', u'CT_IFGoperc.R', u'CT_IFGtriang.R', u'CT_SFGmed.R',\n",
      "       u'CT_SMA.R', u'CT_PCL.R', u'CT_PreCG.R', u'CT_ROL.R', u'CT_PoCG.R',\n",
      "       u'CT_SPG.R', u'CT_IPL.R', u'CT_SMG.R', u'CT_ANG.R', u'CT_PCUN.R',\n",
      "       u'CT_SOG.R', u'CT_MOG.R', u'CT_IOG.R', u'CT_CAL.R', u'CT_CUN.R',\n",
      "       u'CT_LING.R', u'CT_FFG.R', u'CT_HES.R', u'CT_STG.R', u'CT_MTG.R',\n",
      "       u'CT_ITG.R', u'CT_TPOsup.R', u'CT_TPOmid.R', u'CT_ACG.R', u'CT_DCG.R',\n",
      "       u'CT_PCG.R'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "698 fused ids found in total\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import scipy.stats as stats\n",
    "import h5py as h5\n",
    "\n",
    "input_data = h5.File(fuse_path, 'r')\n",
    "fuse_ids = {}\n",
    "\n",
    "# Find the ids for each of the fused splits:\n",
    "for split in ['train', 'test', 'valid']:\n",
    "    files = input_data['l_{}_files'.format(split)][:]\n",
    "    subject_idx=[]\n",
    "\n",
    "    #find volume indices for each unique subject\n",
    "    seen = set([])\n",
    "    for i, f in enumerate(files):\n",
    "        subject_id = re.search(id_participant, f).group(0)\n",
    "        if subject_id not in seen:\n",
    "            subject_idx.append(subject_id)\n",
    "            seen.add(subject_id)\n",
    "\n",
    "    # Reduce to unique set of ids:\n",
    "    fuse_ids[split] = subject_idx\n",
    "    \n",
    "total = np.sum([len(ids) for ids in fuse_ids.values()])\n",
    "print '{} fused ids found in total'.format(total)\n",
    "input_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "test\n",
      "valid\n"
     ]
    }
   ],
   "source": [
    "index = list(fuse_ids['train']) + list(fuse_ids['valid']) + list(fuse_ids['test'])\n",
    "segmatrix = np.array([],)\n",
    "splits = []\n",
    "for split in ['train', 'test', 'valid']:\n",
    "    print split\n",
    "    fdata = h5.File(fused_segmentations_path.format(split), 'r')\n",
    "    r = fdata['r_hc_features_fused'][:]\n",
    "    l = fdata['l_hc_features_fused'][:]\n",
    "    l_vol = np.sum(l,axis=1).reshape(-1,1)\n",
    "    r_vol = np.sum(r,axis=1).reshape(-1,1)\n",
    "    lr = np.concatenate([l_vol, r_vol,l,r],axis=1)\n",
    "    segmatrix = np.vstack([segmatrix, lr]) if segmatrix.size else lr\n",
    "    # Add a column to keep track of which data split each participant is in:\n",
    "    splits.extend([split for x in range(lr.shape[0])])\n",
    "\n",
    "hc_col_names = ['L_HC_VOL', 'R_HC_VOL']\n",
    "hc_col_names.extend(['L_HC_{}'.format(x) for x in range(l.shape[1])])\n",
    "hc_col_names.extend(['R_HC_{}'.format(x) for x in range(r.shape[1])])\n",
    "\n",
    "segmentations = pd.DataFrame(segmatrix, columns=hc_col_names)\n",
    "segmentations.insert(0,'PTID', index)\n",
    "segmentations.insert(1,'SPLIT', splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'PTID', u'SPLIT', u'L_HC_VOL', u'R_HC_VOL', u'L_HC_0', u'L_HC_1',\n",
      "       u'L_HC_2', u'L_HC_3', u'L_HC_4', u'L_HC_5', \n",
      "       ...\n",
      "       u'R_HC_10509', u'R_HC_10510', u'R_HC_10511', u'R_HC_10512',\n",
      "       u'R_HC_10513', u'R_HC_10514', u'R_HC_10515', u'R_HC_10516',\n",
      "       u'R_HC_10517', u'R_HC_10518'],\n",
      "      dtype='object', length=21950)\n",
      "1550702.0\n",
      "1527313.0\n"
     ]
    }
   ],
   "source": [
    "print segmentations.columns\n",
    "print np.sum(segmentations['L_HC_VOL'])\n",
    "print np.sum(segmentations['R_HC_VOL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Merge these to the other guy\n",
    "# Merge these suckas:        bsel = SelectKBest(f_regression, k=k)\n",
    "\n",
    "combined = merge(merged, segmentations, on=['PTID'], sort=False)\n",
    "\n",
    "# Move the SPLIT column to the somewhere near the front:\n",
    "split_col = combined['SPLIT']\n",
    "combined.drop(labels=['SPLIT'], axis=1, inplace = True)\n",
    "combined.insert(3, 'SPLIT', split_col)\n",
    "\n",
    "# Save\n",
    "combined.to_pickle('/projects/francisco/data/ADNI/master_fused.pkl')\n",
    "combined.to_csv('/projects/francisco/data/ADNI/master_fused.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/francisco/miniconda/envs/nn/lib/python2.7/site-packages/IPython/kernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/projects/francisco/miniconda/envs/nn/lib/python2.7/site-packages/IPython/kernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/projects/francisco/miniconda/envs/nn/lib/python2.7/site-packages/IPython/kernel/__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(490, 22029)\n",
      "(110, 22029)\n",
      "(98, 22029)\n"
     ]
    }
   ],
   "source": [
    "useful_vars = '^DX_bl|^ADAS|^MMSE|^CT_|^L_HC|^R_HC'\n",
    "\n",
    "# Extract all the useful features and save to training, validation, and test files\n",
    "for split in ['train', 'test', 'valid']:\n",
    "    current_split = combined[(combined.SPLIT ==  split)]\n",
    "    useful = current_split.filter(regex=useful_vars)\n",
    "    c = useful['DX_bl']\n",
    "    c[c=='AD'] = 0\n",
    "    c[c=='CN'] = 1\n",
    "    c[c=='LMCI'] = 2\n",
    "    useful.to_pickle('/projects/francisco/data/ADNI/cli_ct_seg_fused_{}.pkl'.format(split))\n",
    "    print useful.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(698, 22038)\n",
      "Index([u'RID', u'PTID', u'IID', u'SPLIT', u'VISCODE', u'COLPROT', u'ORIGPROT',\n",
      "       u'DX_bl', u'AGE', u'PTGENDER', \n",
      "       ...\n",
      "       u'R_HC_10509', u'R_HC_10510', u'R_HC_10511', u'R_HC_10512',\n",
      "       u'R_HC_10513', u'R_HC_10514', u'R_HC_10515', u'R_HC_10516',\n",
      "       u'R_HC_10517', u'R_HC_10518'],\n",
      "      dtype='object', length=22038)\n",
      "RID                      295\n",
      "PTID              002_S_0295\n",
      "IID                  I118671\n",
      "SPLIT                  train\n",
      "VISCODE                   bl\n",
      "COLPROT                ADNI1\n",
      "ORIGPROT               ADNI1\n",
      "DX_bl                     CN\n",
      "AGE                     84.8\n",
      "PTGENDER                Male\n",
      "ADAS11                     3\n",
      "ADAS13                     4\n",
      "MMSE                      28\n",
      "ADAS11_bl                  3\n",
      "ADAS13_bl                  4\n",
      "MMSE_bl                   28\n",
      "CT_REC.L            3.307916\n",
      "CT_OLF.L            3.399054\n",
      "CT_ORBsup.L          3.49189\n",
      "CT_ORBsupmed.L      3.596402\n",
      "CT_ORBmid.L         3.564972\n",
      "CT_ORBinf.L         3.547402\n",
      "CT_SFGdor.L         3.184414\n",
      "CT_MFG.L             3.21152\n",
      "CT_IFGoperc.L       3.483411\n",
      "CT_IFGtriang.L      3.376174\n",
      "CT_SFGmed.L         3.657116\n",
      "CT_SMA.L            3.482757\n",
      "CT_PCL.L            2.785969\n",
      "CT_PreCG.L          2.739375\n",
      "                     ...    \n",
      "R_HC_10489                 0\n",
      "R_HC_10490                 0\n",
      "R_HC_10491                 0\n",
      "R_HC_10492                 0\n",
      "R_HC_10493                 0\n",
      "R_HC_10494                 0\n",
      "R_HC_10495                 0\n",
      "R_HC_10496                 0\n",
      "R_HC_10497                 0\n",
      "R_HC_10498                 0\n",
      "R_HC_10499                 0\n",
      "R_HC_10500                 0\n",
      "R_HC_10501                 0\n",
      "R_HC_10502                 0\n",
      "R_HC_10503                 0\n",
      "R_HC_10504                 0\n",
      "R_HC_10505                 0\n",
      "R_HC_10506                 0\n",
      "R_HC_10507                 0\n",
      "R_HC_10508                 0\n",
      "R_HC_10509                 0\n",
      "R_HC_10510                 0\n",
      "R_HC_10511                 0\n",
      "R_HC_10512                 0\n",
      "R_HC_10513                 0\n",
      "R_HC_10514                 0\n",
      "R_HC_10515                 0\n",
      "R_HC_10516                 0\n",
      "R_HC_10517                 0\n",
      "R_HC_10518                 0\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print combined.shape\n",
    "print combined.columns\n",
    "print combined.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
